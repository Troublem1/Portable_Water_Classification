{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "003PW.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gEghjHd1eKqf",
        "Fj9OZvR_e-qA"
      ],
      "mount_file_id": "1tO5h4PW4tjT7Z7Q14_BE_mtmA5EkYpcG",
      "authorship_tag": "ABX9TyMGEForWQ09aAMr25/1q72o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Troublem1/Portable_Water_Classification/blob/main/003PW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBnkaTRRYMV9"
      },
      "source": [
        "!pip install -q -r /content/drive/MyDrive/workSpace/Potable_Water/configs/PW_requirements.txt\n",
        "# !pip install -q optuna==2.9.1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kljeXvdYMvA"
      },
      "source": [
        "from omegaconf import OmegaConf\n",
        "from zindi.user import Zindian\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import shutil\n",
        "\n",
        "import catboost as cb\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import auc,roc_auc_score, log_loss, f1_score\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import time\n",
        "# import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtQwqd5TYNAE"
      },
      "source": [
        "os.makedirs('/content/drive/MyDrive/workSpace/Potable_Water/configs/' , exist_ok=True )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6TgK3EFYNTl"
      },
      "source": [
        "params = {'defaults':{'seed_value':2021, 'nKfold':10},\n",
        "'dir': {'model_name':'001',\n",
        "        'data_path':'/content/drive/MyDrive/workSpace/Potable_Water/data/',\n",
        "        'train_file':'/content/drive/MyDrive/workSpace/Potable_Water/data/Train.csv' ,\n",
        "        'test_file':'/content/drive/MyDrive/workSpace/Potable_Water/data/Test.csv' ,\n",
        "        'submit_file':'/content/drive/MyDrive/workSpace/Potable_Water/data/SampleSubmission.csv',\n",
        "        'model_path':'/content/drive/MyDrive/workSpace/Potable_Water/models/',\n",
        "        'checkpoints_path':'/content/drive/MyDrive/workSpace/Potable_Water/checkpoints/',\n",
        "        'predictions_path':'/content/drive/MyDrive/workSpace/Potable_Water/submissions/'},\n",
        "\n",
        "# 'preprocessing':{'remove_traindf_cols':['user_id','CHURN'], \n",
        "#                'remove_testdf_cols':['user_id'],'cat_cols_remove':'user_id',\n",
        "#                'feature_cols':['FREQUENCE_RECH','DATA_VOLUME', 'TIGO', 'FREQ_TOP_PACK', 'ARPU_SEGMENT', 'ORANGE', \n",
        "#                                'ON_NET', 'REVENUE', 'MONTANT', 'REGULARITY', 'FREQUENCE', 'ZONE2', 'ZONE1'],\n",
        "#                'category_cols':['REGION', 'TENURE', 'MRG', 'TOP_PACK'],\n",
        "#                'target_col':'CHURN'},\n",
        "          \n",
        "  'model':{'boosting_type': 'gbdt','path_smooth':0.3 ,'min_data_in_leaf':1000,\n",
        "          #  'class_weights':'balanced',\n",
        "          #  'is_unbalance':True,\n",
        "          #  'num_class':1,\n",
        "           'learning_rate':0.2,'num_leaves':30 ,'objective': 'binary','metric': 'auc','max_depth':20,\n",
        "                'cat_smooth':20,'n_estimators': 98,'colsample_bytree' : 1 ,'deterministic':True,\n",
        "                # 'categorical_feature':['REGION', 'TENURE', 'MRG', 'TOP_PACK'],\n",
        "                'seed': 2021,'silent':False,'num_iterations':900 ,'reg_lambda':2,'reg_alpha':2}}\n",
        "\n",
        "if '001PW.yaml' in os.listdir('/content/drive/MyDrive/workSpace/Potable_Water/configs/'):\n",
        "  config_ = OmegaConf.load('/content/drive/MyDrive/workSpace/Potable_Water/configs/001PW.yaml')\n",
        "else:\n",
        "  OmegaConf.save(config=params, f='/content/drive/MyDrive/workSpace/Potable_Water/configs/001PW.yaml')\n",
        "  config_ = OmegaConf.load('/content/drive/MyDrive/workSpace/Potable_Water/configs/001PW.yaml')\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzc8_UzFbTbx",
        "outputId": "5faddf49-aff7-46c9-8d95-7ce5449ce869"
      },
      "source": [
        "print(OmegaConf.to_yaml(config_.dir))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name: '001'\n",
            "data_path: /content/drive/MyDrive/workSpace/Potable_Water/data/\n",
            "train_file: /content/drive/MyDrive/workSpace/Potable_Water/data/Train.csv\n",
            "test_file: /content/drive/MyDrive/workSpace/Potable_Water/data/Test.csv\n",
            "submit_file: /content/drive/MyDrive/workSpace/Potable_Water/data/SampleSubmission.csv\n",
            "model_path: /content/drive/MyDrive/workSpace/Potable_Water/models/\n",
            "checkpoints_path: /content/drive/MyDrive/workSpace/Potable_Water/checkpoints/\n",
            "predictions_path: /content/drive/MyDrive/workSpace/Potable_Water/submissions/\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7uLzHNWbTXv"
      },
      "source": [
        "os.makedirs(config_.dir.model_path , exist_ok=True )\n",
        "os.makedirs(config_.dir.predictions_path, exist_ok=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mszIbQArbX04"
      },
      "source": [
        "# # create a user object\n",
        "# my_username = \"ZzyZx\"\n",
        "# user = Zindian(username = my_username)\n",
        "\n",
        "# # Select a Zindi challenge\n",
        "# user.select_a_challenge()  #current index 5\n",
        "# user.which_challenge\n",
        "\n",
        "# # Download the dataset of the selected challenge for the sfc select 2\n",
        "# user.download_dataset(destination=config_.dir.data_path)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHBWH4pzbXsL",
        "outputId": "5c4157a3-1cf5-4ea6-a72f-36b790d71284"
      },
      "source": [
        "print(OmegaConf.to_yaml(config_.defaults))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed_value: 2021\n",
            "nKfold: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxm810t9cPc4"
      },
      "source": [
        "# Setting SEED to Reproduce Same Results even with \"GPU\"\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(config_.defaults.seed_value)\n",
        "import random\n",
        "random.seed(config_.defaults.seed_value)\n",
        "import numpy as np\n",
        "np.random.seed(config_.defaults.seed_value)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW21CbOzcR98",
        "outputId": "1e95f31b-0a6c-4f8e-8431-7d5472241795"
      },
      "source": [
        "print(OmegaConf.to_yaml(config_.dir))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name: '001'\n",
            "data_path: /content/drive/MyDrive/workSpace/Potable_Water/data/\n",
            "train_file: /content/drive/MyDrive/workSpace/Potable_Water/data/Train.csv\n",
            "test_file: /content/drive/MyDrive/workSpace/Potable_Water/data/Test.csv\n",
            "submit_file: /content/drive/MyDrive/workSpace/Potable_Water/data/SampleSubmission.csv\n",
            "model_path: /content/drive/MyDrive/workSpace/Potable_Water/models/\n",
            "checkpoints_path: /content/drive/MyDrive/workSpace/Potable_Water/checkpoints/\n",
            "predictions_path: /content/drive/MyDrive/workSpace/Potable_Water/submissions/\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suxmPZdEcVLH"
      },
      "source": [
        "train_df = pd.read_csv(config_.dir.train_file)\n",
        "test_df = pd.read_csv(config_.dir.test_file)\n",
        "sub_df = pd.read_csv(config_.dir.submit_file)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "plE5-Jk7cZc7",
        "outputId": "9355b329-8bb7-4365-b86e-3bb7f69ac793"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>region_area_</th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>region_area_1</td>\n",
              "      <td>3.716080</td>\n",
              "      <td>180.196811</td>\n",
              "      <td>18630.362669</td>\n",
              "      <td>6.330435</td>\n",
              "      <td>NaN</td>\n",
              "      <td>602.990359</td>\n",
              "      <td>15.285013</td>\n",
              "      <td>56.444076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>region_area_100</td>\n",
              "      <td>4.270716</td>\n",
              "      <td>217.611599</td>\n",
              "      <td>24405.555346</td>\n",
              "      <td>7.086700</td>\n",
              "      <td>297.951852</td>\n",
              "      <td>359.623910</td>\n",
              "      <td>13.583526</td>\n",
              "      <td>54.589840</td>\n",
              "      <td>3.763906</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>region_area_1000</td>\n",
              "      <td>6.648849</td>\n",
              "      <td>232.462013</td>\n",
              "      <td>30733.808648</td>\n",
              "      <td>5.656462</td>\n",
              "      <td>344.670335</td>\n",
              "      <td>267.809179</td>\n",
              "      <td>17.863444</td>\n",
              "      <td>35.411181</td>\n",
              "      <td>4.827527</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>region_area_1001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>261.753637</td>\n",
              "      <td>21174.713291</td>\n",
              "      <td>7.314074</td>\n",
              "      <td>NaN</td>\n",
              "      <td>582.848407</td>\n",
              "      <td>15.215849</td>\n",
              "      <td>90.367455</td>\n",
              "      <td>4.217553</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>region_area_1002</td>\n",
              "      <td>9.323584</td>\n",
              "      <td>263.484560</td>\n",
              "      <td>15751.480111</td>\n",
              "      <td>5.196259</td>\n",
              "      <td>297.593625</td>\n",
              "      <td>409.878704</td>\n",
              "      <td>10.727265</td>\n",
              "      <td>74.669285</td>\n",
              "      <td>3.006650</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       region_area_        ph  ...  Turbidity  Potability\n",
              "0     region_area_1  3.716080  ...   4.500656           0\n",
              "1   region_area_100  4.270716  ...   3.763906           0\n",
              "2  region_area_1000  6.648849  ...   4.827527           0\n",
              "3  region_area_1001       NaN  ...   4.217553           0\n",
              "4  region_area_1002  9.323584  ...   3.006650           0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "jstW_W6uhbDV",
        "outputId": "0ae6be9c-a398-4c68-8f18-05b88c6fc625"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>region_area_</th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>region_area_0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>255.664346</td>\n",
              "      <td>20791.623791</td>\n",
              "      <td>6.995401</td>\n",
              "      <td>369.261555</td>\n",
              "      <td>574.413654</td>\n",
              "      <td>10.484783</td>\n",
              "      <td>87.105970</td>\n",
              "      <td>2.963135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>region_area_10</td>\n",
              "      <td>7.360640</td>\n",
              "      <td>216.294688</td>\n",
              "      <td>32452.919220</td>\n",
              "      <td>7.245890</td>\n",
              "      <td>327.369467</td>\n",
              "      <td>435.488419</td>\n",
              "      <td>15.691810</td>\n",
              "      <td>78.855016</td>\n",
              "      <td>3.662292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>region_area_1006</td>\n",
              "      <td>7.230845</td>\n",
              "      <td>228.348694</td>\n",
              "      <td>17864.994196</td>\n",
              "      <td>5.513418</td>\n",
              "      <td>344.338446</td>\n",
              "      <td>377.794992</td>\n",
              "      <td>20.017950</td>\n",
              "      <td>59.418053</td>\n",
              "      <td>5.622018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>region_area_1010</td>\n",
              "      <td>4.797460</td>\n",
              "      <td>241.089018</td>\n",
              "      <td>21280.551369</td>\n",
              "      <td>5.883692</td>\n",
              "      <td>327.539307</td>\n",
              "      <td>367.541193</td>\n",
              "      <td>11.818821</td>\n",
              "      <td>63.978068</td>\n",
              "      <td>4.038503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>region_area_1011</td>\n",
              "      <td>9.319176</td>\n",
              "      <td>250.107456</td>\n",
              "      <td>14294.545161</td>\n",
              "      <td>7.480130</td>\n",
              "      <td>366.796865</td>\n",
              "      <td>348.546450</td>\n",
              "      <td>15.320293</td>\n",
              "      <td>63.506468</td>\n",
              "      <td>4.129230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       region_area_        ph  ...  Trihalomethanes  Turbidity\n",
              "0     region_area_0       NaN  ...        87.105970   2.963135\n",
              "1    region_area_10  7.360640  ...        78.855016   3.662292\n",
              "2  region_area_1006  7.230845  ...        59.418053   5.622018\n",
              "3  region_area_1010  4.797460  ...        63.978068   4.038503\n",
              "4  region_area_1011  9.319176  ...        63.506468   4.129230\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "WOsEvt1miBEp",
        "outputId": "10d08e09-1b62-45b8-e269-163549ce8401"
      },
      "source": [
        "sub_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>region_area_</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>region_area_0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>region_area_10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>region_area_1006</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>region_area_1010</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>region_area_1011</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       region_area_  Potability\n",
              "0     region_area_0           1\n",
              "1    region_area_10           1\n",
              "2  region_area_1006           1\n",
              "3  region_area_1010           1\n",
              "4  region_area_1011           1"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-BEg0ghccEl"
      },
      "source": [
        "# #check distribution of customer in each country across location_type and bank_account columns\n",
        "# pd.crosstab(train_df.REGION,train_df.CHURN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZX7q4AUdDJ6"
      },
      "source": [
        "Variable Descriptions\n",
        "\n",
        "- pH value: PH is an important parameter in evaluating the acid–base balance of water. It is also the indicator of acidic or alkaline condition of water status. WHO has recommended a maximum permissible limit of pH from 6.5 to 8.5. The current investigation ranges were 6.52–6.83 which are in the range of WHO standards.\n",
        "- Hardness: Hardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels. The length of time water is in contact with hardness producing material helps determine how much hardness there is in raw water. Hardness was originally defined as the capacity of water to precipitate soap caused by Calcium and Magnesium.\n",
        "- Solids (Total dissolved solids - TDS): Water has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, chlorides, magnesium, sulfates etc. These minerals produced an unwanted taste and diluted color in the appearance of water. This is the important parameter for the use of water. The water with high TDS value indicates that water is highly mineralized. The desired limit for TDS is 500 mg/l and maximum limit is 1000 mg/l which is prescribed for drinking purposes.\n",
        "- Chloramines: Chlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per liter (mg/L or 4 parts per million (ppm)) are considered safe in drinking water.\n",
        "- Sulfate: Sulfates are naturally occurring substances that are found in minerals, soil, and rocks. They are present in ambient air, groundwater, plants, and food. The principal commercial use of sulfate is in the chemical industry. Sulfate concentration in seawater is about 2,700 milligrams per liter (mg/L). It ranges from 3 to 30 mg/L in most freshwater supplies, although much higher concentrations (1000 mg/L) are found in some geographic locations.\n",
        "- Conductivity: Pure water is not a good conductor of electric current rather it's a good insulator. Increase in ions concentration enhances the electrical conductivity of water. Generally, the amount of dissolved solids in water determines the electrical conductivity. Electrical conductivity (EC) actually measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceed 400 μS/cm.\n",
        "- Organic_carbon: Total Organic Carbon (TOC) in source waters comes from decaying natural organic matter (NOM) as well as synthetic sources. TOC is a measure of the total amount of carbon in organic compounds in pure water. According to the US EPA < 2 mg/L as TOC in treated / drinking water, and < 4 mg/Lit in source water which is used for treatment.\n",
        "- Trihalomethanes: THMs are chemicals which may be found in water treated with chlorine. The concentration of THMs in drinking water varies according to the level of organic material in the water, the amount of chlorine required to treat the water, and the temperature of the water that is being treated. THM levels up to 80 ppm is considered safe in drinking water.\n",
        "- Turbidity: The turbidity of water depends on the quantity of solid matter present in the suspended state. It is a measure of light emitting properties of water and the test is used to indicate the quality of waste discharge with respect to colloidal matter. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.\n",
        "- Potability: Indicates if water is safe for human consumption where 1 means Potable and 0 means Not potable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD3CbCwYi7nP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEnZ52-Bi_Gf"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEghjHd1eKqf"
      },
      "source": [
        "### MY GBM BASELINES "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvCoG2UX_zyA"
      },
      "source": [
        "- XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgl7_H_LdWdF"
      },
      "source": [
        "# # Baseline\n",
        "# \"\"\"XGBOOST on GPU\"\"\"\n",
        "# from sklearn.model_selection import KFold\n",
        "# import xgboost as xgb\n",
        "# # from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "# y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "# test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "# test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "# kf = KFold(n_splits = 5,shuffle=True,random_state=2021)\n",
        "# feats = pd.DataFrame({'features': X.columns}) \n",
        "# xgb_predictions = []\n",
        "# cv_score_ = 0\n",
        "# oof_preds = np.zeros((X.shape[0],))\n",
        "\n",
        "\n",
        "# for i,(tr_index,test_index) in enumerate(kf.split(X,y)):\n",
        "#     #   print()\n",
        "#     print(f'######### FOLD {i+1} / {kf.n_splits} ')\n",
        "  \n",
        "#     X_train,y_train = X.iloc[tr_index,:],y[tr_index]\n",
        "#     X_test,y_test = X.iloc[test_index,:],y[test_index]\n",
        "#       # merror or mlogloss\n",
        "#     gbm = xgb.XGBClassifier(eval_metric = 'logloss',\n",
        "#                             # objective='multi:softprob',#tree_method='gpu_hist',\n",
        "#                               grow_policy='lossguide', \n",
        "#                               # gpu_id=0, \n",
        "#                             n_estimators = 300, scale_pos_weight=30,\n",
        "#                               learning_rate = 0.03, random_state = 2021, colsample_bytree=1 ,reg_alpha=1, reg_lambda=1)\n",
        "\n",
        "#     gbm.fit(X_train,y_train,eval_set = [(X_test, y_test)],early_stopping_rounds  = 50, verbose=200)\n",
        "\n",
        "#     cv_score_ += f1_score(y_test, gbm.predict(X_test)) / kf.n_splits\n",
        "#     oof_preds[test_index] = gbm.predict_proba(X_test)[:,1]\n",
        "\n",
        "#     preds = gbm.predict_proba(test_new[X_train.columns] , gbm.best_iteration)[:,1]\n",
        "#     xgb_predictions.append(preds)\n",
        "\n",
        "#     feats[f'Fold {i}'] = gbm.feature_importances_\n",
        "\n",
        "# feats['Importances'] = feats.mean(axis=1)\n",
        "# print( ' CV F1_SCORE : ',cv_score_)\n",
        "# # preds_xgb = np.average(gbm_predictions, axis=0)\n",
        "# # print(preds_xgb.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRqFC1-2eF53"
      },
      "source": [
        "# xgbpreds_mean = np.mean(xgb_predictions, axis=0)# mean of all the predictions\n",
        "# final = [] #list to store the final results \n",
        "# for x in xgbpreds_mean:\n",
        "#     if x >= 0.51:\n",
        "#         final.append(1)\n",
        "#     else:\n",
        "#         final.append(0)\n",
        "# submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "# submit['Potability'] = final\n",
        "# submit[['region_area_','Potability']].to_csv('000xgbbaseline.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXhZm_epl34I"
      },
      "source": [
        "# submit[['region_area_','Potability']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU8K3fy4eGkV"
      },
      "source": [
        "# seed = 2021 # seed\n",
        "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed) # for cross validation\n",
        "# sklearnscores = []\n",
        "# # torchscores = []\n",
        "# catpreds= []\n",
        "\n",
        "\n",
        "# np.random.seed(2021)\n",
        "# seeds = np.random.randint(low=1, high=3000, size=5)\n",
        "\n",
        "# X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "# y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "# test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "# test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "# #creating a for loop for the stratified k fold\n",
        "# i = 0\n",
        "# for train, test in skf.split(X, y):\n",
        "#     x_train, x_test, y_train, y_test = X.iloc[train], X.iloc[test], y.iloc[train], y.iloc[test]# spliting the data\n",
        "\n",
        "\n",
        "#     estimator = cb.CatBoostClassifier(iterations=10000,                     #has_time=True ,bootstrap_type='No',random_strength=0,\n",
        "#                                    learning_rate=0.08,\n",
        "#                                   #  objective='MultiClass',\n",
        "#                                   use_best_model=True,\n",
        "#                                    reg_lambda=1,\n",
        "#                                    random_seed=seed,         #depth=3,border_count=32, l2_leaf_reg=3,\n",
        "#                                   #  task_type='GPU',\n",
        "#                                   #  loss_function='MultiClass',\n",
        "#                                   early_stopping_rounds=50)\n",
        "\n",
        "#     # estimator = CatBoostClassifier(**params)\n",
        "#     # parameters for the algorithm this was done by manual tuning\n",
        "\n",
        "#     estimator.fit( x_train, y_train, eval_set = (x_test,y_test),verbose=100 ,early_stopping_rounds=50)# fitting on train data\n",
        "    \n",
        "#     print('Number of splits trained {} '.format(i+1))\n",
        "#     score1 =  f1_score(y_test, gbm.predict(x_test))  # checking the cross_entropy loss\n",
        "\n",
        "#     # score2 = torchLoss(estimator.predict_proba(x_test) , y_test)\n",
        "#     # cm = ConfusionMatrix(actual_vector=np.array(y_test), predict_vector=estimator.predict(x_test))\n",
        "#     # plt.show(cm.print_matrix())\n",
        "#     print('f1_score score: {}'.format(score1))\n",
        "\n",
        "#     catpred = estimator.predict_proba(test_new)[:,1] # making prediction probabities\n",
        "#     sklearnscores.append(score1)\n",
        "#     # torchscores.append(score2)\n",
        "\n",
        "#     catpreds.append(catpred)\n",
        "#     i += 1\n",
        "# print('mean f1_scores: {} '.format(np.mean(sklearnscores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrc5qcjpg8OB"
      },
      "source": [
        "# catpreds_mean = np.mean(catpreds, axis=0)# mean of all the predictions\n",
        "# final = [] #list to store the final results \n",
        "# for x in catpreds_mean:\n",
        "#     if x >= 0.51:\n",
        "#         final.append(1)\n",
        "#     else:\n",
        "#         final.append(0)\n",
        "# submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "# submit['Potability'] = final\n",
        "# submit[['region_area_','Potability']].to_csv('000catbaseline.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mokOz9LpB22-"
      },
      "source": [
        "# submit[['region_area_','Potability']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1km702Lexk2"
      },
      "source": [
        "LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nctlU_cteUNd"
      },
      "source": [
        "# since = time.time()\n",
        "# skf = StratifiedKFold(n_splits=config_.defaults.nKfold, shuffle=True, random_state=config_.defaults.seed_value) # for cross validation\n",
        "# sklearnscores = []\n",
        "# lgbmpreds= []\n",
        "\n",
        "# np.random.seed(config_.defaults.seed_value)\n",
        "# seeds = np.random.randint(low=1, high=3000, size=10)\n",
        "\n",
        "# X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "# y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "# test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "# test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "# #creating a for loop for the stratified k fold\n",
        "# i = 0\n",
        "# for train, test in skf.split(X, y):\n",
        "#     print(f'########### Fold {i+1} / {skf.n_splits} ')\n",
        "    \n",
        "#     x_train, x_test, y_train, y_test = X.iloc[train], X.iloc[test], y.iloc[train], y.iloc[test]# spliting the data\n",
        "    \n",
        "#     estimator = lgb.LGBMClassifier( boosting_type='gbdt', num_leaves=30,scale_pos_weight=2, num_class =1,\n",
        "#                                max_depth=- 1, learning_rate=0.08, n_estimators=800, subsample_for_bin=300000,\n",
        "#                                deterministic=True,objective='binary', class_weight=None, min_split_gain=0.0,\n",
        "#                                min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, \n",
        "#                                colsample_bytree=1.0, reg_alpha=1, reg_lambda=1, random_state=seeds[i], n_jobs=- 1,\n",
        "#                                silent=True, device_type='CPU',importance_type='split')\n",
        "\n",
        "# #     estimator = LGBMClassifier(**config_.model,random_state=seeds[i])\n",
        "# # early_stopping_rounds=50, \n",
        "#     estimator.fit( x_train, y_train, eval_set = (x_test,y_test),eval_metric = 'binary_error',  verbose=100, early_stopping_rounds=50 )# fitting on train data\n",
        "\n",
        "#     score1 = f1_score(y_test, estimator.predict(x_test)) # checking the cross_entropy loss\n",
        "#     print('f1 score: {}'.format(score1))\n",
        "\n",
        "#     pred = estimator.predict_proba(test_new)[:,1] # making prediction probabities\n",
        "#     sklearnscores.append(score1)\n",
        "\n",
        "#     lgbmpreds.append(pred)\n",
        "#     i += 1\n",
        "\n",
        "# print('mean f1_scores from sklearn: {}'.format(np.mean(sklearnscores)))\n",
        "\n",
        "# time_elapsed = time.time() - since\n",
        "# print(f'Pre-process the data: {time_elapsed // 60} m {time_elapsed % 60} s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A9gD4OogxEb"
      },
      "source": [
        "# lgbmpreds_mean = np.mean(lgbmpreds, axis=0)# mean of all the predictions\n",
        "# final = [] #list to store the final results \n",
        "# for x in lgbmpreds_mean:\n",
        "#     if x >= 0.51:\n",
        "#         final.append(1)\n",
        "#     else:\n",
        "#         final.append(0)\n",
        "# submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "# submit['Potability'] = final\n",
        "# submit[['region_area_','Potability']].to_csv('000lgbmbaseline.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj9OZvR_e-qA"
      },
      "source": [
        "### XVII BASELINE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPvnV0_Se9Hy"
      },
      "source": [
        "# #Here the cross validation by using the StratifiedKfold used to split the data into train,test and validation and repeatedly and Using the LGBMClassifier as Algorithm for building the model \n",
        "# skf =StratifiedKFold(n_splits=10, shuffle=True,random_state=2021) # for cross validation by StratifiedKfold\n",
        "# scores = [] #list to store the sores obtained in training the model \n",
        "# preds= [] #list to store the predictions \n",
        "\n",
        "# X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "# y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "# test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "# test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "# #creating a for loop for the stratified k fold to perform the cross validation \n",
        "# i = 1\n",
        "# for train, test in skf.split(X, y):\n",
        "#     x_train, x_test= X.iloc[train], X.iloc[test] #spliting the data for x \n",
        "#     y_train, y_test = y.iloc[train],y.iloc[test] #spliting the data for y \n",
        "#     model = lgb.LGBMClassifier(learning_rate=0.08, n_estimators = 96,cat_smooth=10,metrics='binary_error',\n",
        "#                                scale_pos_weight= 3.6,max_depth=16, seed =2021,\n",
        "#                                num_leaves=49,reg_lambda=0.3) #Creating the model and tuning it with the different parameter \n",
        "#     model.fit(x_train, y_train)# fitting  the model on train data\n",
        "#     print(i,'Split Trained') #print the splits that trained \n",
        "#     score = f1_score(y_test,model.predict(x_test)) # checking the accuracy of the model \n",
        "#     pred = model.predict_proba(test_new)[:,1] # making prediction\n",
        "#     scores.append(score)\n",
        "#     preds.append(pred)\n",
        "#     i += 1\n",
        "# print('Total Mean Score Obtained :',np.mean(scores))\n",
        "\n",
        "# preds_mean = np.mean(preds, axis=0)# mean of all the predictions\n",
        "# final = [] #list to store the final results \n",
        "# for x in preds_mean:\n",
        "#     if x >= 0.51:\n",
        "#         final.append(1)\n",
        "#     else:\n",
        "#         final.append(0)\n",
        "\n",
        "# submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "# submit['Potability'] = final\n",
        "# submit[['region_area_','Potability']].to_csv('000xviibaseline.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9sZ19sV5lmW"
      },
      "source": [
        "# 0.5389573339467848 # LB: 0.56"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP-ZnsD44V1Q"
      },
      "source": [
        "# OPTUNA TRIAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSG-Al7Tw1kT"
      },
      "source": [
        "# # create trial function\n",
        "# OPTUNA_OPTIMIZATION = True\n",
        "\n",
        "# def objective(trial):\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=1)\n",
        "    \n",
        "# #  boosting_type='gbdt', =30,scale_pos_weight=1,  =9,\n",
        "# #    max_depth=-1, learning_rate=0.08, n_estimators=2000, subsample_for_bin=300000,\n",
        "# #   deterministic=True,objective='logloss', class_weight=None, min_split_gain=0.0,\n",
        "# #   min_child_weight=0.001, min_child_samples=20, =0.80, subsample_freq=20, \n",
        "# #   colsample_bytree=0.30, reg_alpha=1, reg_lambda=1, random_state=seeds[i], n_jobs=- 1,\n",
        "# #    silent=True, =\n",
        "#     params = {\n",
        "#         'n_estimators':trial.suggest_int(\"n_estimators\", 90, 700),\n",
        "#         # 'objective': trial.suggest_categorical('objective', ['binary','cross_entropy']),\n",
        "#         'importance_type':trial.suggest_categorical('importance_type', ['gain','split']),\n",
        "#         'num_leaves':trial.suggest_int('num_leaves', 10, 100),\n",
        "#         'learning_rate' : trial.suggest_uniform('learning_rate',0.02,1),\n",
        "#         'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "#         'reg_alpha': trial.suggest_uniform('reg_alpha',1e-5,100),\n",
        "#         'colsample_bytree': trial.suggest_uniform('colsample_bytree',0.1,1),\n",
        "#         'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 3, 20),\n",
        "#         'max_depth': trial.suggest_int('depth',1,15),\n",
        "#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',20,300),\n",
        "# #         'bagging_freq': trial.suggest_int('bagging_freq',0,10),\n",
        "#         'subsample': trial.suggest_uniform('subsample', 0.1, 1),\n",
        "#         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1),\n",
        "#         'min_sum_hessian_in_leaf': trial.suggest_uniform('min_sum_hessian_in_leaf', 1e-3, 1),\n",
        "# #         'max_bin': trial.suggest_int('max_bin',100,500),\n",
        "#         'random_state': 2021, \n",
        "#         'num_class':  1, \n",
        "#         # \"device\": \"gpu\",\n",
        "#         # \"gpu_platform_id\": 0,\n",
        "#         # \"gpu_device_id\": 0,\n",
        "# #         'verbose': False,\n",
        "# #         'task_type' : 'GPU',\n",
        "# #         'devices' : '0'\n",
        "#     }\n",
        "    \n",
        "#     # if params['bootstrap_type'] == 'Bayesian':\n",
        "#     #     params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
        "#     # elif params['bootstrap_type'] == 'Bernoulli':\n",
        "#     #     params['subsample'] = trial.suggest_float('subsample', 0.1, 1)\n",
        "    \n",
        "#     model = lgb.LGBMClassifier(**params)\n",
        "#     model.fit(\n",
        "#         X_train, y_train,\n",
        "#         eval_set = (X_test,y_test),\n",
        "#         early_stopping_rounds=200,verbose=200 \n",
        "# #         use_best_model=True\n",
        "#     )\n",
        "\n",
        "#     # # validation AUC prediction\n",
        "#     # y_hat = model.predict_proba(X_test)[:,1]\n",
        "#     # fpr, tpr, _ = roc_curve(y_test, y_hat)\n",
        "#     # score = auc(fpr, tpr)\n",
        "    \n",
        "\n",
        "#     # validation log loss prediction\n",
        "#     # y_hat = model.predict_proba(X_test)\n",
        "#     # score = log_loss(y_test, y_hat)\n",
        "    \n",
        "#     # validation F1 predictions\n",
        "#     y_hat = model.predict(X_test)\n",
        "#     score = f1_score(y_test, y_hat)\n",
        "    \n",
        "#     return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYKGSJWEw7oI"
      },
      "source": [
        "# X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "# y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obTYz_hMzCuB",
        "outputId": "d20826f2-9c80-436a-ea08-50417b2656ee"
      },
      "source": [
        "# #create optuna study\n",
        "# study = optuna.create_study(\n",
        "#     direction='maximize',\n",
        "#     study_name='LGBMClf'\n",
        "# )\n",
        "\n",
        "# study.optimize(\n",
        "#     objective, \n",
        "#     n_trials=300\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:36,975]\u001b[0m A new study created in memory with name: LGBMClf\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,050]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 444, 'importance_type': 'split', 'num_leaves': 58, 'learning_rate': 0.590368855420905, 'reg_lambda': 10.791273756853146, 'reg_alpha': 37.3363318607632, 'colsample_bytree': 0.8871093424675291, 'scale_pos_weight': 9.224693284041201, 'depth': 4, 'min_data_in_leaf': 109, 'subsample': 0.8523402501226346, 'bagging_fraction': 0.6331754267919684, 'min_sum_hessian_in_leaf': 0.22223963966012944}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,111]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 368, 'importance_type': 'split', 'num_leaves': 32, 'learning_rate': 0.6437316684321902, 'reg_lambda': 55.17740066049302, 'reg_alpha': 29.940546916039143, 'colsample_bytree': 0.7298965781873297, 'scale_pos_weight': 5.074531600595723, 'depth': 10, 'min_data_in_leaf': 235, 'subsample': 0.8467422988990422, 'bagging_fraction': 0.22026853999108487, 'min_sum_hessian_in_leaf': 0.10225776149212226}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,177]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'n_estimators': 366, 'importance_type': 'split', 'num_leaves': 89, 'learning_rate': 0.37501110784652036, 'reg_lambda': 76.15625020317846, 'reg_alpha': 18.28498781245354, 'colsample_bytree': 0.6221657302290227, 'scale_pos_weight': 10.817859196033119, 'depth': 7, 'min_data_in_leaf': 204, 'subsample': 0.18700090520356671, 'bagging_fraction': 0.6503269099186086, 'min_sum_hessian_in_leaf': 0.20378541353545637}. Best is trial 0 with value: 0.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=109, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=109\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.22223963966012944, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.22223963966012944\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6331754267919684, subsample=0.8523402501226346 will be ignored. Current value: bagging_fraction=0.6331754267919684\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=235, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=235\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10225776149212226, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10225776149212226\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.22026853999108487, subsample=0.8467422988990422 will be ignored. Current value: bagging_fraction=0.22026853999108487\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.20378541353545637, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.20378541353545637\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6503269099186086, subsample=0.18700090520356671 will be ignored. Current value: bagging_fraction=0.6503269099186086\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.4360171703434167, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.4360171703434167\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.24087615321276992, subsample=0.9697866116201368 will be ignored. Current value: bagging_fraction=0.24087615321276992\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:37,239]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'n_estimators': 401, 'importance_type': 'gain', 'num_leaves': 58, 'learning_rate': 0.8356199273633377, 'reg_lambda': 26.48487761519524, 'reg_alpha': 21.11949780485782, 'colsample_bytree': 0.7201120447280136, 'scale_pos_weight': 12.10499566870847, 'depth': 11, 'min_data_in_leaf': 32, 'subsample': 0.9697866116201368, 'bagging_fraction': 0.24087615321276992, 'min_sum_hessian_in_leaf': 0.4360171703434167}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,287]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 133, 'importance_type': 'gain', 'num_leaves': 60, 'learning_rate': 0.31612926781697726, 'reg_lambda': 47.26662508280218, 'reg_alpha': 78.30336833715509, 'colsample_bytree': 0.7740646072691456, 'scale_pos_weight': 12.820845159366629, 'depth': 5, 'min_data_in_leaf': 243, 'subsample': 0.9704912516165524, 'bagging_fraction': 0.16915061569450257, 'min_sum_hessian_in_leaf': 0.9241200972104899}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,348]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'n_estimators': 266, 'importance_type': 'gain', 'num_leaves': 94, 'learning_rate': 0.40592243730801314, 'reg_lambda': 20.17258358774338, 'reg_alpha': 51.81017234882854, 'colsample_bytree': 0.7483330023820599, 'scale_pos_weight': 15.15295529669366, 'depth': 4, 'min_data_in_leaf': 250, 'subsample': 0.6498695040748205, 'bagging_fraction': 0.16429156868919564, 'min_sum_hessian_in_leaf': 0.29660177537859095}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,422]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 627, 'importance_type': 'gain', 'num_leaves': 88, 'learning_rate': 0.10550157281488975, 'reg_lambda': 47.96125299554003, 'reg_alpha': 3.911127256724606, 'colsample_bytree': 0.9475078659268417, 'scale_pos_weight': 19.449468258870535, 'depth': 11, 'min_data_in_leaf': 21, 'subsample': 0.31384430212156184, 'bagging_fraction': 0.49026848704520365, 'min_sum_hessian_in_leaf': 0.27191205141300195}. Best is trial 0 with value: 0.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9241200972104899, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9241200972104899\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.16915061569450257, subsample=0.9704912516165524 will be ignored. Current value: bagging_fraction=0.16915061569450257\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.29660177537859095, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.29660177537859095\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.16429156868919564, subsample=0.6498695040748205 will be ignored. Current value: bagging_fraction=0.16429156868919564\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.27191205141300195, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.27191205141300195\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.49026848704520365, subsample=0.31384430212156184 will be ignored. Current value: bagging_fraction=0.49026848704520365\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:37,472]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 155, 'importance_type': 'gain', 'num_leaves': 51, 'learning_rate': 0.13115178870396485, 'reg_lambda': 22.69737330612657, 'reg_alpha': 60.85094492700962, 'colsample_bytree': 0.2646908236187067, 'scale_pos_weight': 13.81778148014418, 'depth': 12, 'min_data_in_leaf': 296, 'subsample': 0.3721935610026358, 'bagging_fraction': 0.13341946496357177, 'min_sum_hessian_in_leaf': 0.5369395366388487}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,533]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 446, 'importance_type': 'split', 'num_leaves': 21, 'learning_rate': 0.39403626122175234, 'reg_lambda': 18.525733268298715, 'reg_alpha': 49.35304769960683, 'colsample_bytree': 0.9216770224611075, 'scale_pos_weight': 13.196295397857854, 'depth': 15, 'min_data_in_leaf': 152, 'subsample': 0.8104265094028137, 'bagging_fraction': 0.1735776439625611, 'min_sum_hessian_in_leaf': 0.899980812216635}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,592]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 549, 'importance_type': 'gain', 'num_leaves': 68, 'learning_rate': 0.8497667510593325, 'reg_lambda': 35.320705020499545, 'reg_alpha': 2.5966248297173418, 'colsample_bytree': 0.2789860465587902, 'scale_pos_weight': 6.8615450269655165, 'depth': 13, 'min_data_in_leaf': 228, 'subsample': 0.5783188577677075, 'bagging_fraction': 0.18167936870572388, 'min_sum_hessian_in_leaf': 0.29896268993046393}. Best is trial 0 with value: 0.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=296, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=296\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.5369395366388487, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.5369395366388487\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.13341946496357177, subsample=0.3721935610026358 will be ignored. Current value: bagging_fraction=0.13341946496357177\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=152, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=152\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.899980812216635, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.899980812216635\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1735776439625611, subsample=0.8104265094028137 will be ignored. Current value: bagging_fraction=0.1735776439625611\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=228, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=228\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.29896268993046393, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.29896268993046393\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.18167936870572388, subsample=0.5783188577677075 will be ignored. Current value: bagging_fraction=0.18167936870572388\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.6805049472202622, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.6805049472202622\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.943634113040147, subsample=0.7179135324370955 will be ignored. Current value: bagging_fraction=0.943634113040147\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:37,663]\u001b[0m Trial 10 finished with value: 0.0 and parameters: {'n_estimators': 675, 'importance_type': 'split', 'num_leaves': 38, 'learning_rate': 0.6293010580697392, 'reg_lambda': 6.175153630236212, 'reg_alpha': 97.8115010586966, 'colsample_bytree': 0.44394368617576707, 'scale_pos_weight': 8.224000061411283, 'depth': 1, 'min_data_in_leaf': 98, 'subsample': 0.7179135324370955, 'bagging_fraction': 0.943634113040147, 'min_sum_hessian_in_leaf': 0.6805049472202622}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,738]\u001b[0m Trial 11 finished with value: 0.0 and parameters: {'n_estimators': 488, 'importance_type': 'split', 'num_leaves': 12, 'learning_rate': 0.6428019634258063, 'reg_lambda': 86.60108285460072, 'reg_alpha': 33.34778970935895, 'colsample_bytree': 0.9967624411540986, 'scale_pos_weight': 3.1240852162545143, 'depth': 8, 'min_data_in_leaf': 128, 'subsample': 0.8394452929430729, 'bagging_fraction': 0.5412992928789798, 'min_sum_hessian_in_leaf': 0.01178398289817173}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,812]\u001b[0m Trial 12 finished with value: 0.0 and parameters: {'n_estimators': 294, 'importance_type': 'split', 'num_leaves': 36, 'learning_rate': 0.6717844070747686, 'reg_lambda': 65.25584604322286, 'reg_alpha': 36.06749393226754, 'colsample_bytree': 0.4927688010485325, 'scale_pos_weight': 3.9685642916296473, 'depth': 1, 'min_data_in_leaf': 102, 'subsample': 0.8105299131822241, 'bagging_fraction': 0.7375861904208618, 'min_sum_hessian_in_leaf': 0.007423915460312819}. Best is trial 0 with value: 0.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01178398289817173, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.01178398289817173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5412992928789798, subsample=0.8394452929430729 will be ignored. Current value: bagging_fraction=0.5412992928789798\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=102, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=102\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.007423915460312819, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.007423915460312819\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7375861904208618, subsample=0.8105299131822241 will be ignored. Current value: bagging_fraction=0.7375861904208618\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.15937271569217187, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.15937271569217187\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3921808838550564, subsample=0.4659472738124402 will be ignored. Current value: bagging_fraction=0.3921808838550564\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:37,891]\u001b[0m Trial 13 finished with value: 0.0 and parameters: {'n_estimators': 304, 'importance_type': 'split', 'num_leaves': 39, 'learning_rate': 0.9389926580678702, 'reg_lambda': 63.67644026321916, 'reg_alpha': 33.32826248500289, 'colsample_bytree': 0.8329674761750887, 'scale_pos_weight': 7.137634763156901, 'depth': 5, 'min_data_in_leaf': 195, 'subsample': 0.4659472738124402, 'bagging_fraction': 0.3921808838550564, 'min_sum_hessian_in_leaf': 0.15937271569217187}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:37,965]\u001b[0m Trial 14 finished with value: 0.569620253164557 and parameters: {'n_estimators': 548, 'importance_type': 'split', 'num_leaves': 71, 'learning_rate': 0.5451820431683637, 'reg_lambda': 0.18982147693285611, 'reg_alpha': 65.58618060010909, 'colsample_bytree': 0.5718965752147983, 'scale_pos_weight': 9.722381028559631, 'depth': 9, 'min_data_in_leaf': 66, 'subsample': 0.8780495139659923, 'bagging_fraction': 0.37946033709168714, 'min_sum_hessian_in_leaf': 0.11449230117536044}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:38,039]\u001b[0m Trial 15 finished with value: 0.0 and parameters: {'n_estimators': 558, 'importance_type': 'split', 'num_leaves': 77, 'learning_rate': 0.5068232135169922, 'reg_lambda': 0.9002327779100003, 'reg_alpha': 74.15213771915015, 'colsample_bytree': 0.16123970337314403, 'scale_pos_weight': 9.450504032796916, 'depth': 7, 'min_data_in_leaf': 64, 'subsample': 0.7001509346275271, 'bagging_fraction': 0.7805723871913858, 'min_sum_hessian_in_leaf': 0.42471313864670923}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11449230117536044, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11449230117536044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.37946033709168714, subsample=0.8780495139659923 will be ignored. Current value: bagging_fraction=0.37946033709168714\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.20816\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.800028\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=64, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=64\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.42471313864670923, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.42471313864670923\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7805723871913858, subsample=0.7001509346275271 will be ignored. Current value: bagging_fraction=0.7805723871913858\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.5750479631237302, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.5750479631237302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3593379609978577, subsample=0.9800203265857701 will be ignored. Current value: bagging_fraction=0.3593379609978577\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:38,117]\u001b[0m Trial 16 finished with value: 0.0 and parameters: {'n_estimators': 525, 'importance_type': 'split', 'num_leaves': 75, 'learning_rate': 0.5036132773563384, 'reg_lambda': 7.238367150166699, 'reg_alpha': 67.52267759960608, 'colsample_bytree': 0.6139560625280593, 'scale_pos_weight': 16.44770900320187, 'depth': 3, 'min_data_in_leaf': 63, 'subsample': 0.9800203265857701, 'bagging_fraction': 0.3593379609978577, 'min_sum_hessian_in_leaf': 0.5750479631237302}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:38,187]\u001b[0m Trial 17 finished with value: 0.0 and parameters: {'n_estimators': 602, 'importance_type': 'split', 'num_leaves': 48, 'learning_rate': 0.2508248712969767, 'reg_lambda': 98.61104936234156, 'reg_alpha': 88.97405784086257, 'colsample_bytree': 0.38422819269044495, 'scale_pos_weight': 10.247068403310958, 'depth': 9, 'min_data_in_leaf': 79, 'subsample': 0.5264880467097585, 'bagging_fraction': 0.43749373676028297, 'min_sum_hessian_in_leaf': 0.3865045545428163}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:38,263]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'n_estimators': 450, 'importance_type': 'split', 'num_leaves': 68, 'learning_rate': 0.7730065053458729, 'reg_lambda': 35.017027789700336, 'reg_alpha': 53.979982952816364, 'colsample_bytree': 0.5996878343668759, 'scale_pos_weight': 8.012398409703156, 'depth': 6, 'min_data_in_leaf': 138, 'subsample': 0.89404163396387, 'bagging_fraction': 0.607346508267178, 'min_sum_hessian_in_leaf': 0.1166691821133362}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=79, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=79\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.3865045545428163, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.3865045545428163\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.43749373676028297, subsample=0.5264880467097585 will be ignored. Current value: bagging_fraction=0.43749373676028297\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1166691821133362, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1166691821133362\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.607346508267178, subsample=0.89404163396387 will be ignored. Current value: bagging_fraction=0.607346508267178\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.6874337214053401, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.6874337214053401\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.33143778263629986, subsample=0.7292036766057458 will be ignored. Current value: bagging_fraction=0.33143778263629986\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:38,345]\u001b[0m Trial 19 finished with value: 0.0 and parameters: {'n_estimators': 692, 'importance_type': 'split', 'num_leaves': 80, 'learning_rate': 0.5488997544777875, 'reg_lambda': 6.312281454423587, 'reg_alpha': 43.412819499527465, 'colsample_bytree': 0.8565350125479699, 'scale_pos_weight': 5.4617485895875335, 'depth': 3, 'min_data_in_leaf': 116, 'subsample': 0.7292036766057458, 'bagging_fraction': 0.33143778263629986, 'min_sum_hessian_in_leaf': 0.6874337214053401}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:38,426]\u001b[0m Trial 20 finished with value: 0.0 and parameters: {'n_estimators': 192, 'importance_type': 'split', 'num_leaves': 100, 'learning_rate': 0.21141869338708824, 'reg_lambda': 12.55586748341774, 'reg_alpha': 63.30335385508175, 'colsample_bytree': 0.49537743960393077, 'scale_pos_weight': 9.343851557939947, 'depth': 9, 'min_data_in_leaf': 171, 'subsample': 0.10268956010451014, 'bagging_fraction': 0.9308012037839983, 'min_sum_hessian_in_leaf': 0.20632383572624124}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:38,499]\u001b[0m Trial 21 finished with value: 0.0 and parameters: {'n_estimators': 464, 'importance_type': 'split', 'num_leaves': 67, 'learning_rate': 0.7621215782489421, 'reg_lambda': 34.61827760156306, 'reg_alpha': 53.624680924215966, 'colsample_bytree': 0.6144673781596157, 'scale_pos_weight': 7.1888630896882955, 'depth': 6, 'min_data_in_leaf': 141, 'subsample': 0.8832373026084572, 'bagging_fraction': 0.6280969578616099, 'min_sum_hessian_in_leaf': 0.09997659725440813}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.20632383572624124, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.20632383572624124\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9308012037839983, subsample=0.10268956010451014 will be ignored. Current value: bagging_fraction=0.9308012037839983\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=141, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=141\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09997659725440813, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09997659725440813\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6280969578616099, subsample=0.8832373026084572 will be ignored. Current value: bagging_fraction=0.6280969578616099\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.7413538060624039, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.7413538060624039\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3137374023499888, subsample=0.7464416705963139 will be ignored. Current value: bagging_fraction=0.3137374023499888\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:38,579]\u001b[0m Trial 22 finished with value: 0.0 and parameters: {'n_estimators': 689, 'importance_type': 'split', 'num_leaves': 80, 'learning_rate': 0.5527110888077952, 'reg_lambda': 2.757430126335991, 'reg_alpha': 41.64234306613712, 'colsample_bytree': 0.8541890846692738, 'scale_pos_weight': 5.758464533863844, 'depth': 3, 'min_data_in_leaf': 111, 'subsample': 0.7464416705963139, 'bagging_fraction': 0.3137374023499888, 'min_sum_hessian_in_leaf': 0.7413538060624039}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:38,652]\u001b[0m Trial 23 finished with value: 0.0 and parameters: {'n_estimators': 184, 'importance_type': 'split', 'num_leaves': 99, 'learning_rate': 0.21024742187046414, 'reg_lambda': 9.998982733367882, 'reg_alpha': 66.32379837165956, 'colsample_bytree': 0.36448091086427126, 'scale_pos_weight': 9.204891183085037, 'depth': 9, 'min_data_in_leaf': 177, 'subsample': 0.13130647342182122, 'bagging_fraction': 0.9183858647872615, 'min_sum_hessian_in_leaf': 0.2325150383968479}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:38,721]\u001b[0m Trial 24 finished with value: 0.0 and parameters: {'n_estimators': 505, 'importance_type': 'split', 'num_leaves': 66, 'learning_rate': 0.7443533879628518, 'reg_lambda': 31.573053568333062, 'reg_alpha': 80.23224795182806, 'colsample_bytree': 0.549262098322856, 'scale_pos_weight': 7.106748960109787, 'depth': 5, 'min_data_in_leaf': 51, 'subsample': 0.8945910015316945, 'bagging_fraction': 0.7092017916397275, 'min_sum_hessian_in_leaf': 0.09153616792234845}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.2325150383968479, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.2325150383968479\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9183858647872615, subsample=0.13130647342182122 will be ignored. Current value: bagging_fraction=0.9183858647872615\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09153616792234845, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09153616792234845\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7092017916397275, subsample=0.8945910015316945 will be ignored. Current value: bagging_fraction=0.7092017916397275\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.826324570914802, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.826324570914802\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.28725694551066755, subsample=0.7625707675998714 will be ignored. Current value: bagging_fraction=0.28725694551066755\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:38,806]\u001b[0m Trial 25 finished with value: 0.0 and parameters: {'n_estimators': 638, 'importance_type': 'split', 'num_leaves': 83, 'learning_rate': 0.569067808077472, 'reg_lambda': 2.5097531137225237, 'reg_alpha': 41.70626125475019, 'colsample_bytree': 0.8449846651894092, 'scale_pos_weight': 5.2233810708014765, 'depth': 2, 'min_data_in_leaf': 87, 'subsample': 0.7625707675998714, 'bagging_fraction': 0.28725694551066755, 'min_sum_hessian_in_leaf': 0.826324570914802}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:38,877]\u001b[0m Trial 26 finished with value: 0.0 and parameters: {'n_estimators': 222, 'importance_type': 'split', 'num_leaves': 46, 'learning_rate': 0.4546361848122228, 'reg_lambda': 14.318569572196397, 'reg_alpha': 70.48602359295298, 'colsample_bytree': 0.3820192116181278, 'scale_pos_weight': 11.222149567905491, 'depth': 9, 'min_data_in_leaf': 182, 'subsample': 0.27767721458616695, 'bagging_fraction': 0.9985504457522343, 'min_sum_hessian_in_leaf': 0.36543073816965677}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:38,981]\u001b[0m Trial 27 finished with value: 0.569620253164557 and parameters: {'n_estimators': 520, 'importance_type': 'split', 'num_leaves': 64, 'learning_rate': 0.7088534242083535, 'reg_lambda': 28.403076289363412, 'reg_alpha': 83.74896482074344, 'colsample_bytree': 0.5542990194106227, 'scale_pos_weight': 8.212912290690761, 'depth': 5, 'min_data_in_leaf': 46, 'subsample': 0.9115840874911366, 'bagging_fraction': 0.746335186477793, 'min_sum_hessian_in_leaf': 0.05222078811983407}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=182, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=182\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.36543073816965677, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.36543073816965677\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9985504457522343, subsample=0.27767721458616695 will be ignored. Current value: bagging_fraction=0.9985504457522343\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05222078811983407, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05222078811983407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.746335186477793, subsample=0.9115840874911366 will be ignored. Current value: bagging_fraction=0.746335186477793\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.13566\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.860826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:39,064]\u001b[0m Trial 28 finished with value: 0.0 and parameters: {'n_estimators': 607, 'importance_type': 'split', 'num_leaves': 87, 'learning_rate': 0.9805515779519195, 'reg_lambda': 42.554858432351494, 'reg_alpha': 87.43295406154151, 'colsample_bytree': 0.6592841301563768, 'scale_pos_weight': 4.753500591307821, 'depth': 2, 'min_data_in_leaf': 42, 'subsample': 0.641303094822326, 'bagging_fraction': 0.837509845664251, 'min_sum_hessian_in_leaf': 0.8274413593336383}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:39,125]\u001b[0m Trial 29 finished with value: 0.0 and parameters: {'n_estimators': 99, 'importance_type': 'split', 'num_leaves': 47, 'learning_rate': 0.717266575922222, 'reg_lambda': 16.466067371390793, 'reg_alpha': 99.67748840002818, 'colsample_bytree': 0.392691942398051, 'scale_pos_weight': 11.593511345256385, 'depth': 8, 'min_data_in_leaf': 68, 'subsample': 0.37247425974181125, 'bagging_fraction': 0.8314793365595433, 'min_sum_hessian_in_leaf': 0.354802547145565}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.8274413593336383, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.8274413593336383\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.837509845664251, subsample=0.641303094822326 will be ignored. Current value: bagging_fraction=0.837509845664251\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.354802547145565, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.354802547145565\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8314793365595433, subsample=0.37247425974181125 will be ignored. Current value: bagging_fraction=0.8314793365595433\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05086739424715039, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05086739424715039\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.998470938861892, subsample=0.27234888042721733 will be ignored. Current value: bagging_fraction=0.998470938861892\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:39,226]\u001b[0m Trial 30 finished with value: 0.0 and parameters: {'n_estimators': 405, 'importance_type': 'split', 'num_leaves': 55, 'learning_rate': 0.4751712320799069, 'reg_lambda': 27.166109749693064, 'reg_alpha': 87.6155946978265, 'colsample_bytree': 0.3214451894634577, 'scale_pos_weight': 10.60421872647985, 'depth': 13, 'min_data_in_leaf': 194, 'subsample': 0.27234888042721733, 'bagging_fraction': 0.998470938861892, 'min_sum_hessian_in_leaf': 0.05086739424715039}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:39,306]\u001b[0m Trial 31 finished with value: 0.0 and parameters: {'n_estimators': 580, 'importance_type': 'split', 'num_leaves': 72, 'learning_rate': 0.9839376646762102, 'reg_lambda': 41.675155802677374, 'reg_alpha': 87.54437943863566, 'colsample_bytree': 0.6897262599529002, 'scale_pos_weight': 8.298440792586732, 'depth': 2, 'min_data_in_leaf': 42, 'subsample': 0.6549634378139174, 'bagging_fraction': 0.8268436126918114, 'min_sum_hessian_in_leaf': 0.9949383499969218}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:39,375]\u001b[0m Trial 32 finished with value: 0.0 and parameters: {'n_estimators': 351, 'importance_type': 'split', 'num_leaves': 62, 'learning_rate': 0.6798506061988516, 'reg_lambda': 16.05636370053405, 'reg_alpha': 94.26445383598934, 'colsample_bytree': 0.19905437889970937, 'scale_pos_weight': 12.323840655767482, 'depth': 7, 'min_data_in_leaf': 73, 'subsample': 0.4084874313951201, 'bagging_fraction': 0.6706869951912902, 'min_sum_hessian_in_leaf': 0.1441156981832015}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:39,454]\u001b[0m Trial 33 finished with value: 0.0 and parameters: {'n_estimators': 420, 'importance_type': 'split', 'num_leaves': 54, 'learning_rate': 0.6029122471139912, 'reg_lambda': 26.461360119810283, 'reg_alpha': 25.474117797260647, 'colsample_bytree': 0.10078821021823281, 'scale_pos_weight': 10.23321291573307, 'depth': 15, 'min_data_in_leaf': 214, 'subsample': 0.9035189656456916, 'bagging_fraction': 0.5251897564181097, 'min_sum_hessian_in_leaf': 0.06607312871318666}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9949383499969218, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9949383499969218\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8268436126918114, subsample=0.6549634378139174 will be ignored. Current value: bagging_fraction=0.8268436126918114\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1441156981832015, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1441156981832015\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6706869951912902, subsample=0.4084874313951201 will be ignored. Current value: bagging_fraction=0.6706869951912902\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=214, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=214\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06607312871318666, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06607312871318666\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5251897564181097, subsample=0.9035189656456916 will be ignored. Current value: bagging_fraction=0.5251897564181097\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:39,531]\u001b[0m Trial 34 finished with value: 0.0 and parameters: {'n_estimators': 358, 'importance_type': 'split', 'num_leaves': 74, 'learning_rate': 0.5732646269812526, 'reg_lambda': 10.520023727080575, 'reg_alpha': 44.709979970380815, 'colsample_bytree': 0.7920028527334626, 'scale_pos_weight': 6.518744828821988, 'depth': 3, 'min_data_in_leaf': 115, 'subsample': 0.9338518116068775, 'bagging_fraction': 0.45875730128686476, 'min_sum_hessian_in_leaf': 0.6355909966757242}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:39,607]\u001b[0m Trial 35 finished with value: 0.0 and parameters: {'n_estimators': 516, 'importance_type': 'gain', 'num_leaves': 62, 'learning_rate': 0.2817605489481809, 'reg_lambda': 12.351328171551893, 'reg_alpha': 60.38799291468602, 'colsample_bytree': 0.5292244236262503, 'scale_pos_weight': 9.017352557018945, 'depth': 10, 'min_data_in_leaf': 168, 'subsample': 0.7886656207222573, 'bagging_fraction': 0.9009648108084999, 'min_sum_hessian_in_leaf': 0.21212789469355964}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=115, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=115\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.6355909966757242, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.6355909966757242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45875730128686476, subsample=0.9338518116068775 will be ignored. Current value: bagging_fraction=0.45875730128686476\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=168, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=168\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.21212789469355964, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.21212789469355964\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9009648108084999, subsample=0.7886656207222573 will be ignored. Current value: bagging_fraction=0.9009648108084999\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.21834073816547978, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.21834073816547978\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5801682963753287, subsample=0.9834037759613654 will be ignored. Current value: bagging_fraction=0.5801682963753287\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:39,707]\u001b[0m Trial 36 finished with value: 0.569620253164557 and parameters: {'n_estimators': 547, 'importance_type': 'split', 'num_leaves': 97, 'learning_rate': 0.8183336086762214, 'reg_lambda': 23.84649049159551, 'reg_alpha': 14.558543158853212, 'colsample_bytree': 0.4707442760724686, 'scale_pos_weight': 9.712528549399606, 'depth': 10, 'min_data_in_leaf': 21, 'subsample': 0.9834037759613654, 'bagging_fraction': 0.5801682963753287, 'min_sum_hessian_in_leaf': 0.21834073816547978}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:39,796]\u001b[0m Trial 37 finished with value: 0.0 and parameters: {'n_estimators': 340, 'importance_type': 'split', 'num_leaves': 62, 'learning_rate': 0.877180871888528, 'reg_lambda': 22.617031675135127, 'reg_alpha': 13.650334585525478, 'colsample_bytree': 0.23657994559791096, 'scale_pos_weight': 14.798278672625088, 'depth': 7, 'min_data_in_leaf': 25, 'subsample': 0.9903529753588186, 'bagging_fraction': 0.587876551539303, 'min_sum_hessian_in_leaf': 0.15070343666960428}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:39,878]\u001b[0m Trial 38 finished with value: 0.0 and parameters: {'n_estimators': 420, 'importance_type': 'gain', 'num_leaves': 29, 'learning_rate': 0.8225542978456354, 'reg_lambda': 26.179049462953223, 'reg_alpha': 20.375926251912883, 'colsample_bytree': 0.11343538768767629, 'scale_pos_weight': 10.201612576829083, 'depth': 15, 'min_data_in_leaf': 220, 'subsample': 0.9397177748998915, 'bagging_fraction': 0.5427659867546342, 'min_sum_hessian_in_leaf': 0.05660873032295588}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.995913\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.964783\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.15070343666960428, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.15070343666960428\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.587876551539303, subsample=0.9903529753588186 will be ignored. Current value: bagging_fraction=0.587876551539303\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.15069\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=220, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=220\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05660873032295588, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05660873032295588\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5427659867546342, subsample=0.9397177748998915 will be ignored. Current value: bagging_fraction=0.5427659867546342\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:39,958]\u001b[0m Trial 39 finished with value: 0.0 and parameters: {'n_estimators': 476, 'importance_type': 'gain', 'num_leaves': 90, 'learning_rate': 0.9071606106771475, 'reg_lambda': 58.07947332604536, 'reg_alpha': 14.506893437395272, 'colsample_bytree': 0.4510521517014057, 'scale_pos_weight': 8.13439282173747, 'depth': 11, 'min_data_in_leaf': 38, 'subsample': 0.8379882173755601, 'bagging_fraction': 0.6741528293415046, 'min_sum_hessian_in_leaf': 0.484972330652751}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:40,034]\u001b[0m Trial 40 finished with value: 0.0 and parameters: {'n_estimators': 558, 'importance_type': 'split', 'num_leaves': 94, 'learning_rate': 0.6994313785742651, 'reg_lambda': 40.80547471723649, 'reg_alpha': 8.24232267695482, 'colsample_bytree': 0.7146061049893025, 'scale_pos_weight': 11.59201203883893, 'depth': 10, 'min_data_in_leaf': 51, 'subsample': 0.939309949271519, 'bagging_fraction': 0.24013325884951703, 'min_sum_hessian_in_leaf': 0.2607747989216046}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:40,110]\u001b[0m Trial 41 finished with value: 0.0 and parameters: {'n_estimators': 533, 'importance_type': 'split', 'num_leaves': 99, 'learning_rate': 0.1511856610833215, 'reg_lambda': 20.07631604882893, 'reg_alpha': 79.55938525166773, 'colsample_bytree': 0.32754516903782427, 'scale_pos_weight': 9.145306176860315, 'depth': 11, 'min_data_in_leaf': 24, 'subsample': 0.15667112310311881, 'bagging_fraction': 0.7509014948884198, 'min_sum_hessian_in_leaf': 0.24178728033031188}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.484972330652751, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.484972330652751\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6741528293415046, subsample=0.8379882173755601 will be ignored. Current value: bagging_fraction=0.6741528293415046\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.2607747989216046, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.2607747989216046\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.24013325884951703, subsample=0.939309949271519 will be ignored. Current value: bagging_fraction=0.24013325884951703\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.24178728033031188, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.24178728033031188\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7509014948884198, subsample=0.15667112310311881 will be ignored. Current value: bagging_fraction=0.7509014948884198\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:40,185]\u001b[0m Trial 42 finished with value: 0.0 and parameters: {'n_estimators': 494, 'importance_type': 'split', 'num_leaves': 96, 'learning_rate': 0.4187598347603148, 'reg_lambda': 5.72739870714263, 'reg_alpha': 58.75956254311761, 'colsample_bytree': 0.4480289285232189, 'scale_pos_weight': 9.734532638089508, 'depth': 6, 'min_data_in_leaf': 88, 'subsample': 0.9963238135358312, 'bagging_fraction': 0.49696902389932845, 'min_sum_hessian_in_leaf': 0.319205629156051}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:40,260]\u001b[0m Trial 43 finished with value: 0.0 and parameters: {'n_estimators': 504, 'importance_type': 'split', 'num_leaves': 58, 'learning_rate': 0.7681610203261624, 'reg_lambda': 29.876825767721115, 'reg_alpha': 78.77981397235612, 'colsample_bytree': 0.5237542525329688, 'scale_pos_weight': 6.139448631931314, 'depth': 5, 'min_data_in_leaf': 48, 'subsample': 0.8732018178121355, 'bagging_fraction': 0.703779880263421, 'min_sum_hessian_in_leaf': 0.1742162680157722}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:40,335]\u001b[0m Trial 44 finished with value: 0.0 and parameters: {'n_estimators': 643, 'importance_type': 'split', 'num_leaves': 67, 'learning_rate': 0.8005575594037617, 'reg_lambda': 54.89256673999958, 'reg_alpha': 82.48405411671746, 'colsample_bytree': 0.5715505256374956, 'scale_pos_weight': 7.460814298153803, 'depth': 4, 'min_data_in_leaf': 57, 'subsample': 0.8448445380337076, 'bagging_fraction': 0.5924791052453575, 'min_sum_hessian_in_leaf': 0.07840116368335559}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.319205629156051, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.319205629156051\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.49696902389932845, subsample=0.9963238135358312 will be ignored. Current value: bagging_fraction=0.49696902389932845\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1742162680157722, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1742162680157722\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.703779880263421, subsample=0.8732018178121355 will be ignored. Current value: bagging_fraction=0.703779880263421\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.07840116368335559, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.07840116368335559\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5924791052453575, subsample=0.8448445380337076 will be ignored. Current value: bagging_fraction=0.5924791052453575\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:40,415]\u001b[0m Trial 45 finished with value: 0.0 and parameters: {'n_estimators': 658, 'importance_type': 'gain', 'num_leaves': 84, 'learning_rate': 0.6213908763175344, 'reg_lambda': 0.5867642841537339, 'reg_alpha': 24.8762573151482, 'colsample_bytree': 0.9414182832465405, 'scale_pos_weight': 19.849574372348656, 'depth': 4, 'min_data_in_leaf': 85, 'subsample': 0.7809015376677474, 'bagging_fraction': 0.29661205202622265, 'min_sum_hessian_in_leaf': 0.0024682596515310934}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:40,503]\u001b[0m Trial 46 finished with value: 0.0 and parameters: {'n_estimators': 613, 'importance_type': 'split', 'num_leaves': 83, 'learning_rate': 0.5921242442561406, 'reg_lambda': 19.620882160998868, 'reg_alpha': 37.85614592338247, 'colsample_bytree': 0.8923391763323814, 'scale_pos_weight': 4.172012182493637, 'depth': 2, 'min_data_in_leaf': 91, 'subsample': 0.9432793867220104, 'bagging_fraction': 0.3965478324006487, 'min_sum_hessian_in_leaf': 0.8161120830014672}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=85, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=85\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0024682596515310934, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0024682596515310934\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.29661205202622265, subsample=0.7809015376677474 will be ignored. Current value: bagging_fraction=0.29661205202622265\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=91, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.8161120830014672, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.8161120830014672\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3965478324006487, subsample=0.9432793867220104 will be ignored. Current value: bagging_fraction=0.3965478324006487\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=155, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=155\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.3323589297579834, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.3323589297579834\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9925590590847467, subsample=0.22647222511576748 will be ignored. Current value: bagging_fraction=0.9925590590847467\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:40,583]\u001b[0m Trial 47 finished with value: 0.0 and parameters: {'n_estimators': 578, 'importance_type': 'split', 'num_leaves': 42, 'learning_rate': 0.45568938297502815, 'reg_lambda': 16.381567223076217, 'reg_alpha': 71.8168012676105, 'colsample_bytree': 0.4063397030946174, 'scale_pos_weight': 11.179799653579655, 'depth': 12, 'min_data_in_leaf': 155, 'subsample': 0.22647222511576748, 'bagging_fraction': 0.9925590590847467, 'min_sum_hessian_in_leaf': 0.3323589297579834}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:40,669]\u001b[0m Trial 48 finished with value: 0.0 and parameters: {'n_estimators': 428, 'importance_type': 'split', 'num_leaves': 30, 'learning_rate': 0.4331152273362577, 'reg_lambda': 12.531042113151361, 'reg_alpha': 72.27190252063554, 'colsample_bytree': 0.6629566333016406, 'scale_pos_weight': 12.889123648993891, 'depth': 8, 'min_data_in_leaf': 256, 'subsample': 0.5250209476288923, 'bagging_fraction': 0.8787473405919821, 'min_sum_hessian_in_leaf': 0.27632202825400265}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:40,734]\u001b[0m Trial 49 finished with value: 0.0 and parameters: {'n_estimators': 96, 'importance_type': 'split', 'num_leaves': 89, 'learning_rate': 0.03639214995382806, 'reg_lambda': 37.566199015196716, 'reg_alpha': 99.56676759452587, 'colsample_bytree': 0.6617987127825298, 'scale_pos_weight': 14.282111984633293, 'depth': 10, 'min_data_in_leaf': 34, 'subsample': 0.5774143583793656, 'bagging_fraction': 0.8159399339295579, 'min_sum_hessian_in_leaf': 0.41596800017090924}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=256, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=256\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.27632202825400265, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.27632202825400265\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8787473405919821, subsample=0.5250209476288923 will be ignored. Current value: bagging_fraction=0.8787473405919821\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.41596800017090924, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.41596800017090924\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8159399339295579, subsample=0.5774143583793656 will be ignored. Current value: bagging_fraction=0.8159399339295579\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=72, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=72\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.47800792424457716, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.47800792424457716\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.857282707734311, subsample=0.6475964766638462 will be ignored. Current value: bagging_fraction=0.857282707734311\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:40,819]\u001b[0m Trial 50 finished with value: 0.0 and parameters: {'n_estimators': 591, 'importance_type': 'split', 'num_leaves': 86, 'learning_rate': 0.9964305245164223, 'reg_lambda': 46.403959561507904, 'reg_alpha': 92.6891443242115, 'colsample_bytree': 0.48109843031358035, 'scale_pos_weight': 11.924983362239418, 'depth': 8, 'min_data_in_leaf': 72, 'subsample': 0.6475964766638462, 'bagging_fraction': 0.857282707734311, 'min_sum_hessian_in_leaf': 0.47800792424457716}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:40,904]\u001b[0m Trial 51 finished with value: 0.0 and parameters: {'n_estimators': 541, 'importance_type': 'split', 'num_leaves': 52, 'learning_rate': 0.8685568019241088, 'reg_lambda': 43.617983994028954, 'reg_alpha': 95.6332927846575, 'colsample_bytree': 0.9992361679997228, 'scale_pos_weight': 4.217859535565415, 'depth': 1, 'min_data_in_leaf': 63, 'subsample': 0.37314924583761494, 'bagging_fraction': 0.7796637410031485, 'min_sum_hessian_in_leaf': 0.18654789541982997}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.18654789541982997, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.18654789541982997\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7796637410031485, subsample=0.37314924583761494 will be ignored. Current value: bagging_fraction=0.7796637410031485\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.12852737330869868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.12852737330869868\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8146910089818142, subsample=0.4744474681598828 will be ignored. Current value: bagging_fraction=0.8146910089818142\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:40,990]\u001b[0m Trial 52 finished with value: 0.0 and parameters: {'n_estimators': 387, 'importance_type': 'split', 'num_leaves': 47, 'learning_rate': 0.7227132275755951, 'reg_lambda': 23.652884454082553, 'reg_alpha': 84.87851685840504, 'colsample_bytree': 0.5797176783968576, 'scale_pos_weight': 17.766766031578136, 'depth': 4, 'min_data_in_leaf': 30, 'subsample': 0.4744474681598828, 'bagging_fraction': 0.8146910089818142, 'min_sum_hessian_in_leaf': 0.12852737330869868}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:41,070]\u001b[0m Trial 53 finished with value: 0.0 and parameters: {'n_estimators': 296, 'importance_type': 'split', 'num_leaves': 72, 'learning_rate': 0.3676948403108792, 'reg_lambda': 31.6236645562226, 'reg_alpha': 90.56836877944967, 'colsample_bytree': 0.287859571474604, 'scale_pos_weight': 8.359092841709627, 'depth': 12, 'min_data_in_leaf': 197, 'subsample': 0.2674324241621381, 'bagging_fraction': 0.9597244131973053, 'min_sum_hessian_in_leaf': 0.041636654742752285}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:41,145]\u001b[0m Trial 54 finished with value: 0.0 and parameters: {'n_estimators': 573, 'importance_type': 'split', 'num_leaves': 55, 'learning_rate': 0.9359842264057673, 'reg_lambda': 29.781469123582013, 'reg_alpha': 75.32006117108683, 'colsample_bytree': 0.428458834598875, 'scale_pos_weight': 8.514766893107819, 'depth': 14, 'min_data_in_leaf': 268, 'subsample': 0.32393801100527847, 'bagging_fraction': 0.7793908732340838, 'min_sum_hessian_in_leaf': 0.9348891292478891}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:41,220]\u001b[0m Trial 55 finished with value: 0.0 and parameters: {'n_estimators': 324, 'importance_type': 'split', 'num_leaves': 71, 'learning_rate': 0.6676832303745381, 'reg_lambda': 38.67347307063553, 'reg_alpha': 94.3372084238464, 'colsample_bytree': 0.2128638533983086, 'scale_pos_weight': 10.769019947827815, 'depth': 7, 'min_data_in_leaf': 21, 'subsample': 0.46989422369331224, 'bagging_fraction': 0.6583247899155529, 'min_sum_hessian_in_leaf': 0.1399197696228413}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=197, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=197\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.041636654742752285, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.041636654742752285\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9597244131973053, subsample=0.2674324241621381 will be ignored. Current value: bagging_fraction=0.9597244131973053\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=268, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=268\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9348891292478891, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9348891292478891\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7793908732340838, subsample=0.32393801100527847 will be ignored. Current value: bagging_fraction=0.7793908732340838\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1399197696228413, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1399197696228413\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6583247899155529, subsample=0.46989422369331224 will be ignored. Current value: bagging_fraction=0.6583247899155529\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.24841\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:41,293]\u001b[0m Trial 56 finished with value: 0.0 and parameters: {'n_estimators': 381, 'importance_type': 'split', 'num_leaves': 63, 'learning_rate': 0.6705857433407837, 'reg_lambda': 24.0316344301491, 'reg_alpha': 85.30154138668064, 'colsample_bytree': 0.17570796028074656, 'scale_pos_weight': 12.602141828615197, 'depth': 13, 'min_data_in_leaf': 43, 'subsample': 0.41364920152787, 'bagging_fraction': 0.6981033118759239, 'min_sum_hessian_in_leaf': 0.053385380380382166}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:41,368]\u001b[0m Trial 57 finished with value: 0.0 and parameters: {'n_estimators': 257, 'importance_type': 'gain', 'num_leaves': 57, 'learning_rate': 0.5261221520255981, 'reg_lambda': 49.869151606834336, 'reg_alpha': 88.50414959199905, 'colsample_bytree': 0.33074796483547103, 'scale_pos_weight': 13.621220918276418, 'depth': 14, 'min_data_in_leaf': 73, 'subsample': 0.2070490877317171, 'bagging_fraction': 0.57292546875183, 'min_sum_hessian_in_leaf': 0.02510688362440011}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:41,439]\u001b[0m Trial 58 finished with value: 0.0 and parameters: {'n_estimators': 433, 'importance_type': 'split', 'num_leaves': 71, 'learning_rate': 0.6356880655332279, 'reg_lambda': 33.57976654181847, 'reg_alpha': 11.454279520963345, 'colsample_bytree': 0.13352720312073313, 'scale_pos_weight': 9.973906171103483, 'depth': 6, 'min_data_in_leaf': 98, 'subsample': 0.6795746511111329, 'bagging_fraction': 0.5183212045079805, 'min_sum_hessian_in_leaf': 0.10214787321301187}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.053385380380382166, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.053385380380382166\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6981033118759239, subsample=0.41364920152787 will be ignored. Current value: bagging_fraction=0.6981033118759239\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.32582\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.02510688362440011, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.02510688362440011\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.57292546875183, subsample=0.2070490877317171 will be ignored. Current value: bagging_fraction=0.57292546875183\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10214787321301187, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10214787321301187\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5183212045079805, subsample=0.6795746511111329 will be ignored. Current value: bagging_fraction=0.5183212045079805\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:41,536]\u001b[0m Trial 59 finished with value: 0.0 and parameters: {'n_estimators': 356, 'importance_type': 'split', 'num_leaves': 53, 'learning_rate': 0.5996541066502177, 'reg_lambda': 9.579766863616172, 'reg_alpha': 26.333453151001954, 'colsample_bytree': 0.7825226992252717, 'scale_pos_weight': 6.171143193661349, 'depth': 7, 'min_data_in_leaf': 119, 'subsample': 0.9007933141226566, 'bagging_fraction': 0.4324633509426359, 'min_sum_hessian_in_leaf': 0.581577783036078}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:41,619]\u001b[0m Trial 60 finished with value: 0.0 and parameters: {'n_estimators': 515, 'importance_type': 'gain', 'num_leaves': 76, 'learning_rate': 0.3508512364070866, 'reg_lambda': 9.516102588678356, 'reg_alpha': 46.888314013182594, 'colsample_bytree': 0.7793372528788535, 'scale_pos_weight': 8.767864531434196, 'depth': 10, 'min_data_in_leaf': 223, 'subsample': 0.7996788991700489, 'bagging_fraction': 0.4376050908995321, 'min_sum_hessian_in_leaf': 0.5986068619602023}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=119, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=119\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.581577783036078, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.581577783036078\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4324633509426359, subsample=0.9007933141226566 will be ignored. Current value: bagging_fraction=0.4324633509426359\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=223, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=223\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.5986068619602023, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.5986068619602023\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4376050908995321, subsample=0.7996788991700489 will be ignored. Current value: bagging_fraction=0.4376050908995321\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=140, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=140\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.6950448689665141, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.6950448689665141\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4742375144722095, subsample=0.9186760620501842 will be ignored. Current value: bagging_fraction=0.4742375144722095\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:41,702]\u001b[0m Trial 61 finished with value: 0.0 and parameters: {'n_estimators': 459, 'importance_type': 'gain', 'num_leaves': 59, 'learning_rate': 0.5123307352878596, 'reg_lambda': 5.076751748212274, 'reg_alpha': 58.119807257958506, 'colsample_bytree': 0.539353386840197, 'scale_pos_weight': 7.628968516977377, 'depth': 11, 'min_data_in_leaf': 140, 'subsample': 0.9186760620501842, 'bagging_fraction': 0.4742375144722095, 'min_sum_hessian_in_leaf': 0.6950448689665141}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:41,784]\u001b[0m Trial 62 finished with value: 0.0 and parameters: {'n_estimators': 474, 'importance_type': 'gain', 'num_leaves': 63, 'learning_rate': 0.8393898062576255, 'reg_lambda': 11.93180641045532, 'reg_alpha': 1.220987699384935, 'colsample_bytree': 0.8904449226368467, 'scale_pos_weight': 6.656330768404672, 'depth': 3, 'min_data_in_leaf': 106, 'subsample': 0.9693764522493203, 'bagging_fraction': 0.5794646604960371, 'min_sum_hessian_in_leaf': 0.18498169719126192}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:41,865]\u001b[0m Trial 63 finished with value: 0.0 and parameters: {'n_estimators': 326, 'importance_type': 'gain', 'num_leaves': 62, 'learning_rate': 0.3127699080774276, 'reg_lambda': 21.13088332642389, 'reg_alpha': 45.39536536573263, 'colsample_bytree': 0.8205924293752472, 'scale_pos_weight': 18.148604349231622, 'depth': 5, 'min_data_in_leaf': 165, 'subsample': 0.8632044637164477, 'bagging_fraction': 0.6319190824775531, 'min_sum_hessian_in_leaf': 0.2166689797567214}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=106, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=106\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.18498169719126192, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.18498169719126192\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5794646604960371, subsample=0.9693764522493203 will be ignored. Current value: bagging_fraction=0.5794646604960371\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.2166689797567214, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.2166689797567214\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6319190824775531, subsample=0.8632044637164477 will be ignored. Current value: bagging_fraction=0.6319190824775531\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:41,946]\u001b[0m Trial 64 finished with value: 0.0 and parameters: {'n_estimators': 412, 'importance_type': 'gain', 'num_leaves': 20, 'learning_rate': 0.802278124972573, 'reg_lambda': 75.47248325509847, 'reg_alpha': 16.921473168045445, 'colsample_bytree': 0.21265672135061403, 'scale_pos_weight': 9.176933927468557, 'depth': 8, 'min_data_in_leaf': 129, 'subsample': 0.9697226350523532, 'bagging_fraction': 0.5538942510465208, 'min_sum_hessian_in_leaf': 0.160068423501793}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:42,032]\u001b[0m Trial 65 finished with value: 0.0 and parameters: {'n_estimators': 438, 'importance_type': 'gain', 'num_leaves': 43, 'learning_rate': 0.8709060600475445, 'reg_lambda': 26.06762792413858, 'reg_alpha': 20.898942092603615, 'colsample_bytree': 0.25575411953655314, 'scale_pos_weight': 15.257559725367248, 'depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.9613202508588465, 'bagging_fraction': 0.6180233215969696, 'min_sum_hessian_in_leaf': 0.10620525584761792}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.160068423501793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.160068423501793\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5538942510465208, subsample=0.9697226350523532 will be ignored. Current value: bagging_fraction=0.5538942510465208\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10620525584761792, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10620525584761792\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6180233215969696, subsample=0.9613202508588465 will be ignored. Current value: bagging_fraction=0.6180233215969696\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.28687\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.512061890028794, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.512061890028794\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6796963847243591, subsample=0.8274971516224611 will be ignored. Current value: bagging_fraction=0.6796963847243591\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:42,115]\u001b[0m Trial 66 finished with value: 0.0 and parameters: {'n_estimators': 475, 'importance_type': 'gain', 'num_leaves': 92, 'learning_rate': 0.9153398751228082, 'reg_lambda': 68.19635902959266, 'reg_alpha': 14.876386841772183, 'colsample_bytree': 0.47078721372718896, 'scale_pos_weight': 7.772267175471772, 'depth': 9, 'min_data_in_leaf': 38, 'subsample': 0.8274971516224611, 'bagging_fraction': 0.6796963847243591, 'min_sum_hessian_in_leaf': 0.512061890028794}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:42,201]\u001b[0m Trial 67 finished with value: 0.0 and parameters: {'n_estimators': 667, 'importance_type': 'split', 'num_leaves': 84, 'learning_rate': 0.6100901180145998, 'reg_lambda': 0.12036793068180818, 'reg_alpha': 39.04361145992616, 'colsample_bytree': 0.9511768955770734, 'scale_pos_weight': 11.072042932734627, 'depth': 4, 'min_data_in_leaf': 89, 'subsample': 0.7788982246299893, 'bagging_fraction': 0.38075915664984183, 'min_sum_hessian_in_leaf': 0.35506254165444634}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:42,286]\u001b[0m Trial 68 finished with value: 0.0 and parameters: {'n_estimators': 620, 'importance_type': 'split', 'num_leaves': 33, 'learning_rate': 0.44733907524425215, 'reg_lambda': 18.74936070944491, 'reg_alpha': 72.01653828930242, 'colsample_bytree': 0.9129236873279707, 'scale_pos_weight': 15.859340205635158, 'depth': 12, 'min_data_in_leaf': 87, 'subsample': 0.6040360421105061, 'bagging_fraction': 0.8778185182419815, 'min_sum_hessian_in_leaf': 0.2966344323043336}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.35506254165444634, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.35506254165444634\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.38075915664984183, subsample=0.7788982246299893 will be ignored. Current value: bagging_fraction=0.38075915664984183\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.2966344323043336, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.2966344323043336\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8778185182419815, subsample=0.6040360421105061 will be ignored. Current value: bagging_fraction=0.8778185182419815\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:42,366]\u001b[0m Trial 69 finished with value: 0.0 and parameters: {'n_estimators': 570, 'importance_type': 'split', 'num_leaves': 80, 'learning_rate': 0.0731068192680755, 'reg_lambda': 16.93755024613427, 'reg_alpha': 65.54279740562605, 'colsample_bytree': 0.6372408280341533, 'scale_pos_weight': 14.193155199233257, 'depth': 10, 'min_data_in_leaf': 298, 'subsample': 0.5700560273775818, 'bagging_fraction': 0.887389382765384, 'min_sum_hessian_in_leaf': 0.42017611367421986}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:42,441]\u001b[0m Trial 70 finished with value: 0.0 and parameters: {'n_estimators': 610, 'importance_type': 'split', 'num_leaves': 26, 'learning_rate': 0.04103886789728711, 'reg_lambda': 13.546519736570925, 'reg_alpha': 69.18644544860749, 'colsample_bytree': 0.6683326360230415, 'scale_pos_weight': 3.1670742456565986, 'depth': 11, 'min_data_in_leaf': 247, 'subsample': 0.20851173887151145, 'bagging_fraction': 0.9638782519953342, 'min_sum_hessian_in_leaf': 0.33164075817171673}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=298, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=298\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.42017611367421986, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.42017611367421986\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.887389382765384, subsample=0.5700560273775818 will be ignored. Current value: bagging_fraction=0.887389382765384\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=247, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=247\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.33164075817171673, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.33164075817171673\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9638782519953342, subsample=0.20851173887151145 will be ignored. Current value: bagging_fraction=0.9638782519953342\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=262, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=262\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.40238711952335254, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.40238711952335254\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.863023571036152, subsample=0.5021162951738342 will be ignored. Current value: bagging_fraction=0.863023571036152\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:42,535]\u001b[0m Trial 71 finished with value: 0.0 and parameters: {'n_estimators': 593, 'importance_type': 'split', 'num_leaves': 91, 'learning_rate': 0.4746004720007168, 'reg_lambda': 46.481246421072115, 'reg_alpha': 75.73504602988534, 'colsample_bytree': 0.4933074590846313, 'scale_pos_weight': 13.026684464077517, 'depth': 8, 'min_data_in_leaf': 262, 'subsample': 0.5021162951738342, 'bagging_fraction': 0.863023571036152, 'min_sum_hessian_in_leaf': 0.40238711952335254}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:42,617]\u001b[0m Trial 72 finished with value: 0.0 and parameters: {'n_estimators': 544, 'importance_type': 'split', 'num_leaves': 96, 'learning_rate': 0.7027101514551964, 'reg_lambda': 54.19313007893717, 'reg_alpha': 7.314187730390526, 'colsample_bytree': 0.5158625255016209, 'scale_pos_weight': 9.596882722737536, 'depth': 6, 'min_data_in_leaf': 56, 'subsample': 0.8680338830980331, 'bagging_fraction': 0.20953310741960876, 'min_sum_hessian_in_leaf': 0.24706521786588015}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:42,695]\u001b[0m Trial 73 finished with value: 0.569620253164557 and parameters: {'n_estimators': 493, 'importance_type': 'split', 'num_leaves': 94, 'learning_rate': 0.791018436999757, 'reg_lambda': 4.509682102181973, 'reg_alpha': 83.10038226230891, 'colsample_bytree': 0.5828510355541663, 'scale_pos_weight': 9.566665250847214, 'depth': 5, 'min_data_in_leaf': 56, 'subsample': 0.85352732664152, 'bagging_fraction': 0.733777052071444, 'min_sum_hessian_in_leaf': 0.006387768407557289}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.24706521786588015, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.24706521786588015\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.20953310741960876, subsample=0.8680338830980331 will be ignored. Current value: bagging_fraction=0.20953310741960876\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.006387768407557289, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.006387768407557289\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.733777052071444, subsample=0.85352732664152 will be ignored. Current value: bagging_fraction=0.733777052071444\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.20366\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.938928\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.23713513323555127, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.23713513323555127\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7248034556690122, subsample=0.9970736450906554 will be ignored. Current value: bagging_fraction=0.7248034556690122\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:42,777]\u001b[0m Trial 74 finished with value: 0.0 and parameters: {'n_estimators': 493, 'importance_type': 'split', 'num_leaves': 97, 'learning_rate': 0.16544723564075767, 'reg_lambda': 4.419766750381285, 'reg_alpha': 79.33115164759306, 'colsample_bytree': 0.5189302571763106, 'scale_pos_weight': 9.731120698350749, 'depth': 6, 'min_data_in_leaf': 48, 'subsample': 0.9970736450906554, 'bagging_fraction': 0.7248034556690122, 'min_sum_hessian_in_leaf': 0.23713513323555127}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:42,855]\u001b[0m Trial 75 finished with value: 0.0 and parameters: {'n_estimators': 536, 'importance_type': 'split', 'num_leaves': 50, 'learning_rate': 0.998496120007473, 'reg_lambda': 43.627910270860504, 'reg_alpha': 93.91708233067178, 'colsample_bytree': 0.5914173018305737, 'scale_pos_weight': 18.064795188396936, 'depth': 1, 'min_data_in_leaf': 70, 'subsample': 0.3325112146480449, 'bagging_fraction': 0.782519499510794, 'min_sum_hessian_in_leaf': 0.033677208777162015}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:42,947]\u001b[0m Trial 76 finished with value: 0.569620253164557 and parameters: {'n_estimators': 273, 'importance_type': 'split', 'num_leaves': 51, 'learning_rate': 0.733497254159525, 'reg_lambda': 7.953859340499946, 'reg_alpha': 83.36983310181262, 'colsample_bytree': 0.9833934927652632, 'scale_pos_weight': 8.602782685432423, 'depth': 5, 'min_data_in_leaf': 61, 'subsample': 0.4097769816997309, 'bagging_fraction': 0.7611291567274692, 'min_sum_hessian_in_leaf': 0.1257573276630201}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.033677208777162015, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.033677208777162015\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.782519499510794, subsample=0.3325112146480449 will be ignored. Current value: bagging_fraction=0.782519499510794\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1257573276630201, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1257573276630201\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7611291567274692, subsample=0.4097769816997309 will be ignored. Current value: bagging_fraction=0.7611291567274692\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.14821\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.886152\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=272, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=272\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.130538143998912, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.130538143998912\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.10509743453701531, subsample=0.2988413846942429 will be ignored. Current value: bagging_fraction=0.10509743453701531\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:43,033]\u001b[0m Trial 77 finished with value: 0.0 and parameters: {'n_estimators': 245, 'importance_type': 'split', 'num_leaves': 49, 'learning_rate': 0.7398154459351926, 'reg_lambda': 28.91226322862108, 'reg_alpha': 83.16652462369638, 'colsample_bytree': 0.4173411600116157, 'scale_pos_weight': 8.640675604244878, 'depth': 14, 'min_data_in_leaf': 272, 'subsample': 0.2988413846942429, 'bagging_fraction': 0.10509743453701531, 'min_sum_hessian_in_leaf': 0.130538143998912}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:43,117]\u001b[0m Trial 78 finished with value: 0.0 and parameters: {'n_estimators': 560, 'importance_type': 'split', 'num_leaves': 65, 'learning_rate': 0.672547188686721, 'reg_lambda': 37.49233229796842, 'reg_alpha': 74.33701576550364, 'colsample_bytree': 0.6307263089712093, 'scale_pos_weight': 10.569252972550409, 'depth': 5, 'min_data_in_leaf': 21, 'subsample': 0.4685575911853995, 'bagging_fraction': 0.7508430030648138, 'min_sum_hessian_in_leaf': 0.9974972845714896}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:43,208]\u001b[0m Trial 79 finished with value: 0.569620253164557 and parameters: {'n_estimators': 274, 'importance_type': 'split', 'num_leaves': 69, 'learning_rate': 0.7965076542861171, 'reg_lambda': 7.657809561881582, 'reg_alpha': 77.40891436391355, 'colsample_bytree': 0.9732851293723969, 'scale_pos_weight': 10.697031917806907, 'depth': 4, 'min_data_in_leaf': 58, 'subsample': 0.405763265097501, 'bagging_fraction': 0.645437397413546, 'min_sum_hessian_in_leaf': 0.08518223972771116}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9974972845714896, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9974972845714896\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7508430030648138, subsample=0.4685575911853995 will be ignored. Current value: bagging_fraction=0.7508430030648138\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.08518223972771116, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.08518223972771116\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.645437397413546, subsample=0.405763265097501 will be ignored. Current value: bagging_fraction=0.645437397413546\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.23667\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.959334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:43,296]\u001b[0m Trial 80 finished with value: 0.569620253164557 and parameters: {'n_estimators': 321, 'importance_type': 'split', 'num_leaves': 70, 'learning_rate': 0.7906406133446455, 'reg_lambda': 8.705125950309586, 'reg_alpha': 77.23817952660835, 'colsample_bytree': 0.35929722169066347, 'scale_pos_weight': 10.744894561354487, 'depth': 5, 'min_data_in_leaf': 58, 'subsample': 0.42916126336429516, 'bagging_fraction': 0.7803070541180356, 'min_sum_hessian_in_leaf': 0.07911750342761563}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:43,371]\u001b[0m Trial 81 finished with value: 0.0 and parameters: {'n_estimators': 315, 'importance_type': 'split', 'num_leaves': 70, 'learning_rate': 0.7863139527936226, 'reg_lambda': 7.944822455984241, 'reg_alpha': 85.14588229884144, 'colsample_bytree': 0.1752646506764354, 'scale_pos_weight': 12.08794439385046, 'depth': 5, 'min_data_in_leaf': 62, 'subsample': 0.4286146926795618, 'bagging_fraction': 0.6644320476171641, 'min_sum_hessian_in_leaf': 0.07055423736053452}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.07911750342761563, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.07911750342761563\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7803070541180356, subsample=0.42916126336429516 will be ignored. Current value: bagging_fraction=0.7803070541180356\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.26737\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.955534\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.07055423736053452, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.07055423736053452\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6644320476171641, subsample=0.4286146926795618 will be ignored. Current value: bagging_fraction=0.6644320476171641\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=79, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=79\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0814179299840152, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0814179299840152\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7005315317351563, subsample=0.4088661365823353 will be ignored. Current value: bagging_fraction=0.7005315317351563\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:43,453]\u001b[0m Trial 82 finished with value: 0.0 and parameters: {'n_estimators': 279, 'importance_type': 'split', 'num_leaves': 64, 'learning_rate': 0.7430234155644642, 'reg_lambda': 3.0789880861818792, 'reg_alpha': 82.1240241225909, 'colsample_bytree': 0.964347957805717, 'scale_pos_weight': 12.553712615675266, 'depth': 4, 'min_data_in_leaf': 79, 'subsample': 0.4088661365823353, 'bagging_fraction': 0.7005315317351563, 'min_sum_hessian_in_leaf': 0.0814179299840152}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:43,537]\u001b[0m Trial 83 finished with value: 0.569620253164557 and parameters: {'n_estimators': 243, 'importance_type': 'split', 'num_leaves': 57, 'learning_rate': 0.5399180854464778, 'reg_lambda': 7.461421032460402, 'reg_alpha': 89.92303448748146, 'colsample_bytree': 0.3422132437141703, 'scale_pos_weight': 10.572873884319296, 'depth': 3, 'min_data_in_leaf': 60, 'subsample': 0.3554712630958349, 'bagging_fraction': 0.640987191017799, 'min_sum_hessian_in_leaf': 0.0223410838822959}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:43,619]\u001b[0m Trial 84 finished with value: 0.569620253164557 and parameters: {'n_estimators': 249, 'importance_type': 'split', 'num_leaves': 59, 'learning_rate': 0.5279126322981254, 'reg_lambda': 7.688076211568076, 'reg_alpha': 90.51862705807577, 'colsample_bytree': 0.3537618340790314, 'scale_pos_weight': 10.64859320323823, 'depth': 3, 'min_data_in_leaf': 77, 'subsample': 0.3562255947803659, 'bagging_fraction': 0.7360348562579077, 'min_sum_hessian_in_leaf': 0.022233580708959047}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0223410838822959, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0223410838822959\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.640987191017799, subsample=0.3554712630958349 will be ignored. Current value: bagging_fraction=0.640987191017799\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.24587\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.800767\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.022233580708959047, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.022233580708959047\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7360348562579077, subsample=0.3562255947803659 will be ignored. Current value: bagging_fraction=0.7360348562579077\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.24515\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.795294\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00954828710480042, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00954828710480042\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7385276669232586, subsample=0.3562563108136354 will be ignored. Current value: bagging_fraction=0.7385276669232586\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.24331\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.9652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:43,701]\u001b[0m Trial 85 finished with value: 0.569620253164557 and parameters: {'n_estimators': 216, 'importance_type': 'split', 'num_leaves': 60, 'learning_rate': 0.8178188254133822, 'reg_lambda': 7.5803819287361245, 'reg_alpha': 90.48752474838489, 'colsample_bytree': 0.29959404655303545, 'scale_pos_weight': 10.18728512692354, 'depth': 3, 'min_data_in_leaf': 45, 'subsample': 0.3562563108136354, 'bagging_fraction': 0.7385276669232586, 'min_sum_hessian_in_leaf': 0.00954828710480042}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:43,778]\u001b[0m Trial 86 finished with value: 0.569620253164557 and parameters: {'n_estimators': 224, 'importance_type': 'split', 'num_leaves': 60, 'learning_rate': 0.8148520871089259, 'reg_lambda': 7.549649669371195, 'reg_alpha': 90.94019500761999, 'colsample_bytree': 0.3626342742032123, 'scale_pos_weight': 10.582879787547249, 'depth': 3, 'min_data_in_leaf': 56, 'subsample': 0.34387961427219366, 'bagging_fraction': 0.7320467997710758, 'min_sum_hessian_in_leaf': 0.0016223046649675443}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:43,854]\u001b[0m Trial 87 finished with value: 0.569620253164557 and parameters: {'n_estimators': 181, 'importance_type': 'split', 'num_leaves': 66, 'learning_rate': 0.8202277879727355, 'reg_lambda': 3.2313247781120857, 'reg_alpha': 97.27283994655697, 'colsample_bytree': 0.3558655998551097, 'scale_pos_weight': 10.03979999625903, 'depth': 2, 'min_data_in_leaf': 53, 'subsample': 0.4485587045992733, 'bagging_fraction': 0.7312483574608272, 'min_sum_hessian_in_leaf': 0.0021247802953241746}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0016223046649675443, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0016223046649675443\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7320467997710758, subsample=0.34387961427219366 will be ignored. Current value: bagging_fraction=0.7320467997710758\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.26189\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.968976\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021247802953241746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021247802953241746\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7312483574608272, subsample=0.4485587045992733 will be ignored. Current value: bagging_fraction=0.7312483574608272\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.964846\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00947460062352004, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00947460062352004\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6863338068626501, subsample=0.3760163124806272 will be ignored. Current value: bagging_fraction=0.6863338068626501\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.94406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:43,939]\u001b[0m Trial 88 finished with value: 0.569620253164557 and parameters: {'n_estimators': 198, 'importance_type': 'split', 'num_leaves': 66, 'learning_rate': 0.8183745719978547, 'reg_lambda': 3.651129652355294, 'reg_alpha': 97.5131668706612, 'colsample_bytree': 0.5623242247458287, 'scale_pos_weight': 8.927057734636675, 'depth': 2, 'min_data_in_leaf': 52, 'subsample': 0.3760163124806272, 'bagging_fraction': 0.6863338068626501, 'min_sum_hessian_in_leaf': 0.00947460062352004}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:44,022]\u001b[0m Trial 89 finished with value: 0.569620253164557 and parameters: {'n_estimators': 157, 'importance_type': 'split', 'num_leaves': 68, 'learning_rate': 0.8452901438328158, 'reg_lambda': 3.1163590169692243, 'reg_alpha': 96.55150484333622, 'colsample_bytree': 0.9726183275958871, 'scale_pos_weight': 9.004319548629343, 'depth': 2, 'min_data_in_leaf': 43, 'subsample': 0.3896146045698462, 'bagging_fraction': 0.7567303621915036, 'min_sum_hessian_in_leaf': 0.05198570177625888}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:44,100]\u001b[0m Trial 90 finished with value: 0.569620253164557 and parameters: {'n_estimators': 174, 'importance_type': 'split', 'num_leaves': 69, 'learning_rate': 0.8460921235207821, 'reg_lambda': 1.1135753913927253, 'reg_alpha': 76.87491400937515, 'colsample_bytree': 0.5506326596816384, 'scale_pos_weight': 8.805532625241133, 'depth': 2, 'min_data_in_leaf': 36, 'subsample': 0.39466434186655736, 'bagging_fraction': 0.7723644153439223, 'min_sum_hessian_in_leaf': 0.11339840600272871}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:44,169]\u001b[0m Trial 91 finished with value: 0.569620253164557 and parameters: {'n_estimators': 126, 'importance_type': 'split', 'num_leaves': 69, 'learning_rate': 0.8488958256003338, 'reg_lambda': 0.06370281962358715, 'reg_alpha': 80.95699042811994, 'colsample_bytree': 0.46891691295131255, 'scale_pos_weight': 9.412549171357218, 'depth': 4, 'min_data_in_leaf': 36, 'subsample': 0.443029732847787, 'bagging_fraction': 0.6467116677535014, 'min_sum_hessian_in_leaf': 0.1163551277017819}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05198570177625888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05198570177625888\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7567303621915036, subsample=0.3896146045698462 will be ignored. Current value: bagging_fraction=0.7567303621915036\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.963978\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11339840600272871, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11339840600272871\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723644153439223, subsample=0.39466434186655736 will be ignored. Current value: bagging_fraction=0.7723644153439223\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.964658\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1163551277017819, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1163551277017819\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6467116677535014, subsample=0.443029732847787 will be ignored. Current value: bagging_fraction=0.6467116677535014\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.977997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:44,247]\u001b[0m Trial 92 finished with value: 0.569620253164557 and parameters: {'n_estimators': 118, 'importance_type': 'split', 'num_leaves': 79, 'learning_rate': 0.7739634006642155, 'reg_lambda': 0.8407250957290571, 'reg_alpha': 77.05399165996639, 'colsample_bytree': 0.7398014941461277, 'scale_pos_weight': 9.473347650577256, 'depth': 5, 'min_data_in_leaf': 36, 'subsample': 0.43254319642532196, 'bagging_fraction': 0.6146213409707546, 'min_sum_hessian_in_leaf': 0.1153297842829222}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:44,316]\u001b[0m Trial 93 finished with value: 0.569620253164557 and parameters: {'n_estimators': 135, 'importance_type': 'split', 'num_leaves': 78, 'learning_rate': 0.7658763943612662, 'reg_lambda': 14.694541798460836, 'reg_alpha': 81.82736337259739, 'colsample_bytree': 0.4640144543712873, 'scale_pos_weight': 11.518303413560455, 'depth': 5, 'min_data_in_leaf': 26, 'subsample': 0.44533538977250636, 'bagging_fraction': 0.7994091938233293, 'min_sum_hessian_in_leaf': 0.08660262294372721}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:44,391]\u001b[0m Trial 94 finished with value: 0.0 and parameters: {'n_estimators': 128, 'importance_type': 'split', 'num_leaves': 78, 'learning_rate': 0.7638966782926557, 'reg_lambda': 9.974481916233046, 'reg_alpha': 77.14732881139341, 'colsample_bytree': 0.7413828448048592, 'scale_pos_weight': 11.465292461696087, 'depth': 3, 'min_data_in_leaf': 76, 'subsample': 0.34549093512151613, 'bagging_fraction': 0.8004989326374639, 'min_sum_hessian_in_leaf': 0.028414797762076782}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1153297842829222, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1153297842829222\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6146213409707546, subsample=0.43254319642532196 will be ignored. Current value: bagging_fraction=0.6146213409707546\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.928021\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.08660262294372721, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.08660262294372721\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7994091938233293, subsample=0.44533538977250636 will be ignored. Current value: bagging_fraction=0.7994091938233293\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.945353\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=76, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=76\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.028414797762076782, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.028414797762076782\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8004989326374639, subsample=0.34549093512151613 will be ignored. Current value: bagging_fraction=0.8004989326374639\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:44,472]\u001b[0m Trial 95 finished with value: 0.569620253164557 and parameters: {'n_estimators': 235, 'importance_type': 'split', 'num_leaves': 74, 'learning_rate': 0.8910243816236014, 'reg_lambda': 14.446024702855595, 'reg_alpha': 91.44751611829518, 'colsample_bytree': 0.36687477188593937, 'scale_pos_weight': 10.634768795138324, 'depth': 3, 'min_data_in_leaf': 65, 'subsample': 0.30752472427431016, 'bagging_fraction': 0.7916836367916371, 'min_sum_hessian_in_leaf': 0.08522141355345789}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:44,554]\u001b[0m Trial 96 finished with value: 0.569620253164557 and parameters: {'n_estimators': 285, 'importance_type': 'split', 'num_leaves': 73, 'learning_rate': 0.5424021097258674, 'reg_lambda': 6.165430522272489, 'reg_alpha': 86.1273997435471, 'colsample_bytree': 0.3439678072758155, 'scale_pos_weight': 10.997912681278574, 'depth': 4, 'min_data_in_leaf': 64, 'subsample': 0.2652054104557549, 'bagging_fraction': 0.71834307294427, 'min_sum_hessian_in_leaf': 0.06562977939300077}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.08522141355345789, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.08522141355345789\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7916836367916371, subsample=0.30752472427431016 will be ignored. Current value: bagging_fraction=0.7916836367916371\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.2614\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.02429\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=64, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=64\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06562977939300077, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06562977939300077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.71834307294427, subsample=0.2652054104557549 will be ignored. Current value: bagging_fraction=0.71834307294427\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.25884\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.805195\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04213893133562936, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04213893133562936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6510094927846246, subsample=0.2518577574103126 will be ignored. Current value: bagging_fraction=0.6510094927846246\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:44,648]\u001b[0m Trial 97 finished with value: 0.569620253164557 and parameters: {'n_estimators': 270, 'importance_type': 'split', 'num_leaves': 73, 'learning_rate': 0.5432857954920779, 'reg_lambda': 6.2277789351356345, 'reg_alpha': 84.51660877578718, 'colsample_bytree': 0.3037565868217786, 'scale_pos_weight': 11.085235895517519, 'depth': 3, 'min_data_in_leaf': 69, 'subsample': 0.2518577574103126, 'bagging_fraction': 0.6510094927846246, 'min_sum_hessian_in_leaf': 0.04213893133562936}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:44,728]\u001b[0m Trial 98 finished with value: 0.0 and parameters: {'n_estimators': 268, 'importance_type': 'split', 'num_leaves': 57, 'learning_rate': 0.5296574810250056, 'reg_lambda': 6.679017419559811, 'reg_alpha': 86.31103841427915, 'colsample_bytree': 0.30830319860361505, 'scale_pos_weight': 11.018353042843136, 'depth': 4, 'min_data_in_leaf': 80, 'subsample': 0.27880736987892907, 'bagging_fraction': 0.6417888095479116, 'min_sum_hessian_in_leaf': 0.15802472895335953}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:44,808]\u001b[0m Trial 99 finished with value: 0.569620253164557 and parameters: {'n_estimators': 222, 'importance_type': 'split', 'num_leaves': 59, 'learning_rate': 0.5754461867564726, 'reg_lambda': 8.541888620738831, 'reg_alpha': 89.24088810048, 'colsample_bytree': 0.39474312914007126, 'scale_pos_weight': 10.45318206845684, 'depth': 4, 'min_data_in_leaf': 57, 'subsample': 0.4994647610693712, 'bagging_fraction': 0.7596667061561002, 'min_sum_hessian_in_leaf': 0.04077276308339613}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 1.26369\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.806293\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.15802472895335953, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.15802472895335953\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6417888095479116, subsample=0.27880736987892907 will be ignored. Current value: bagging_fraction=0.6417888095479116\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04077276308339613, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04077276308339613\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7596667061561002, subsample=0.4994647610693712 will be ignored. Current value: bagging_fraction=0.7596667061561002\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.23987\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.817921\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:44,898]\u001b[0m Trial 100 finished with value: 0.569620253164557 and parameters: {'n_estimators': 211, 'importance_type': 'split', 'num_leaves': 56, 'learning_rate': 0.5733242910313171, 'reg_lambda': 8.759338707151494, 'reg_alpha': 89.70402500544034, 'colsample_bytree': 0.39557109296961085, 'scale_pos_weight': 10.477058049569976, 'depth': 4, 'min_data_in_leaf': 59, 'subsample': 0.48848622121141616, 'bagging_fraction': 0.7569695893315257, 'min_sum_hessian_in_leaf': 0.030760053204650806}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:44,979]\u001b[0m Trial 101 finished with value: 0.569620253164557 and parameters: {'n_estimators': 214, 'importance_type': 'split', 'num_leaves': 61, 'learning_rate': 0.4918078564513461, 'reg_lambda': 8.894472126263153, 'reg_alpha': 91.91915585226057, 'colsample_bytree': 0.4337840838439227, 'scale_pos_weight': 10.254090780729587, 'depth': 4, 'min_data_in_leaf': 59, 'subsample': 0.49828817386771984, 'bagging_fraction': 0.7430285833565483, 'min_sum_hessian_in_leaf': 0.022902990338904493}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.030760053204650806, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.030760053204650806\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7569695893315257, subsample=0.48848622121141616 will be ignored. Current value: bagging_fraction=0.7569695893315257\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.23816\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.816925\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.022902990338904493, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.022902990338904493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7430285833565483, subsample=0.49828817386771984 will be ignored. Current value: bagging_fraction=0.7430285833565483\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.22899\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.775899\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01238919706785286, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.01238919706785286\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7368354037309502, subsample=0.3531121570625115 will be ignored. Current value: bagging_fraction=0.7368354037309502\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:45,067]\u001b[0m Trial 102 finished with value: 0.569620253164557 and parameters: {'n_estimators': 199, 'importance_type': 'split', 'num_leaves': 61, 'learning_rate': 0.5027527010204925, 'reg_lambda': 11.005126108852936, 'reg_alpha': 91.47091481872327, 'colsample_bytree': 0.37642371866661944, 'scale_pos_weight': 10.128527740749918, 'depth': 3, 'min_data_in_leaf': 45, 'subsample': 0.3531121570625115, 'bagging_fraction': 0.7368354037309502, 'min_sum_hessian_in_leaf': 0.01238919706785286}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:45,144]\u001b[0m Trial 103 finished with value: 0.569620253164557 and parameters: {'n_estimators': 239, 'importance_type': 'split', 'num_leaves': 61, 'learning_rate': 0.8043269414538335, 'reg_lambda': 11.440482853207733, 'reg_alpha': 91.05088384954891, 'colsample_bytree': 0.42931064691131804, 'scale_pos_weight': 10.147243321683135, 'depth': 3, 'min_data_in_leaf': 46, 'subsample': 0.3486010316000294, 'bagging_fraction': 0.7405367480235875, 'min_sum_hessian_in_leaf': 0.01472354663161142}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:45,218]\u001b[0m Trial 104 finished with value: 0.0 and parameters: {'n_estimators': 243, 'importance_type': 'split', 'num_leaves': 51, 'learning_rate': 0.7930505745561816, 'reg_lambda': 11.366590670848051, 'reg_alpha': 87.69442346515407, 'colsample_bytree': 0.2683618998681111, 'scale_pos_weight': 11.888832187317899, 'depth': 3, 'min_data_in_leaf': 47, 'subsample': 0.33697783617221855, 'bagging_fraction': 0.7186493069613489, 'min_sum_hessian_in_leaf': 0.06644779418350734}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.77982\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01472354663161142, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.01472354663161142\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7405367480235875, subsample=0.3486010316000294 will be ignored. Current value: bagging_fraction=0.7405367480235875\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.2291\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.953907\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06644779418350734, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06644779418350734\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7186493069613489, subsample=0.33697783617221855 will be ignored. Current value: bagging_fraction=0.7186493069613489\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.006924298977349764, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.006924298977349764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6881068368306708, subsample=0.3746346879788396 will be ignored. Current value: bagging_fraction=0.6881068368306708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:45,309]\u001b[0m Trial 105 finished with value: 0.0 and parameters: {'n_estimators': 186, 'importance_type': 'split', 'num_leaves': 65, 'learning_rate': 0.8106409081141416, 'reg_lambda': 3.7699926973911517, 'reg_alpha': 98.26458000025869, 'colsample_bytree': 0.347319797816076, 'scale_pos_weight': 7.980659426196739, 'depth': 2, 'min_data_in_leaf': 51, 'subsample': 0.3746346879788396, 'bagging_fraction': 0.6881068368306708, 'min_sum_hessian_in_leaf': 0.006924298977349764}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:45,392]\u001b[0m Trial 106 finished with value: 0.569620253164557 and parameters: {'n_estimators': 252, 'importance_type': 'split', 'num_leaves': 53, 'learning_rate': 0.8284418785029428, 'reg_lambda': 5.190656535447319, 'reg_alpha': 96.13575796877635, 'colsample_bytree': 0.29072156429745777, 'scale_pos_weight': 9.720615105038108, 'depth': 1, 'min_data_in_leaf': 53, 'subsample': 0.3911673290899858, 'bagging_fraction': 0.6889762877933722, 'min_sum_hessian_in_leaf': 0.09028354100113353}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:45,471]\u001b[0m Trial 107 finished with value: 0.569620253164557 and parameters: {'n_estimators': 258, 'importance_type': 'split', 'num_leaves': 53, 'learning_rate': 0.8211601514456746, 'reg_lambda': 17.877840386570117, 'reg_alpha': 95.66984362228507, 'colsample_bytree': 0.29460340624765347, 'scale_pos_weight': 9.75507990081699, 'depth': 1, 'min_data_in_leaf': 29, 'subsample': 0.38968017339227545, 'bagging_fraction': 0.7275851691316315, 'min_sum_hessian_in_leaf': 0.0034218315104083546}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09028354100113353, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09028354100113353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6889762877933722, subsample=0.3911673290899858 will be ignored. Current value: bagging_fraction=0.6889762877933722\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.21233\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.964921\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0034218315104083546, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0034218315104083546\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7275851691316315, subsample=0.38968017339227545 will be ignored. Current value: bagging_fraction=0.7275851691316315\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.21443\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.956687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:45,562]\u001b[0m Trial 108 finished with value: 0.0 and parameters: {'n_estimators': 256, 'importance_type': 'split', 'num_leaves': 52, 'learning_rate': 0.959959322585145, 'reg_lambda': 17.658382398578873, 'reg_alpha': 95.0462239468617, 'colsample_bytree': 0.2439398642378423, 'scale_pos_weight': 9.722671953424198, 'depth': 1, 'min_data_in_leaf': 28, 'subsample': 0.29245760628745643, 'bagging_fraction': 0.5937804567038345, 'min_sum_hessian_in_leaf': 0.09285046969153143}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:45,654]\u001b[0m Trial 109 finished with value: 0.569620253164557 and parameters: {'n_estimators': 296, 'importance_type': 'split', 'num_leaves': 55, 'learning_rate': 0.8921026039349058, 'reg_lambda': 21.68063772110392, 'reg_alpha': 83.25496151131438, 'colsample_bytree': 0.3374330197165121, 'scale_pos_weight': 10.843599173242879, 'depth': 5, 'min_data_in_leaf': 41, 'subsample': 0.31483496587380616, 'bagging_fraction': 0.8184535873873795, 'min_sum_hessian_in_leaf': 0.06205857633088155}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09285046969153143, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09285046969153143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5937804567038345, subsample=0.29245760628745643 will be ignored. Current value: bagging_fraction=0.5937804567038345\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.21217\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06205857633088155, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06205857633088155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8184535873873795, subsample=0.31483496587380616 will be ignored. Current value: bagging_fraction=0.8184535873873795\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.2713\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.0276\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04293423761842612, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04293423761842612\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8319644136990507, subsample=0.4169566157220756 will be ignored. Current value: bagging_fraction=0.8319644136990507\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:45,744]\u001b[0m Trial 110 finished with value: 0.0 and parameters: {'n_estimators': 305, 'importance_type': 'split', 'num_leaves': 59, 'learning_rate': 0.9022519963121828, 'reg_lambda': 14.609193562157701, 'reg_alpha': 93.71568428072013, 'colsample_bytree': 0.35937101354276807, 'scale_pos_weight': 11.329834321702997, 'depth': 2, 'min_data_in_leaf': 97, 'subsample': 0.4169566157220756, 'bagging_fraction': 0.8319644136990507, 'min_sum_hessian_in_leaf': 0.04293423761842612}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:45,818]\u001b[0m Trial 111 finished with value: 0.569620253164557 and parameters: {'n_estimators': 162, 'importance_type': 'split', 'num_leaves': 67, 'learning_rate': 0.8577619463745761, 'reg_lambda': 2.3324001863403288, 'reg_alpha': 97.13160479926717, 'colsample_bytree': 0.32764825155569594, 'scale_pos_weight': 9.286408770266261, 'depth': 2, 'min_data_in_leaf': 38, 'subsample': 0.4414552393594863, 'bagging_fraction': 0.6161682738316161, 'min_sum_hessian_in_leaf': 0.05665690259879409}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:45,896]\u001b[0m Trial 112 finished with value: 0.569620253164557 and parameters: {'n_estimators': 166, 'importance_type': 'split', 'num_leaves': 68, 'learning_rate': 0.8476901079229362, 'reg_lambda': 2.0578977411408284, 'reg_alpha': 78.12310500883235, 'colsample_bytree': 0.8127039051918322, 'scale_pos_weight': 8.962421500793331, 'depth': 2, 'min_data_in_leaf': 35, 'subsample': 0.4279383010203635, 'bagging_fraction': 0.6192312231622974, 'min_sum_hessian_in_leaf': 0.11766238993523667}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05665690259879409, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05665690259879409\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6161682738316161, subsample=0.4414552393594863 will be ignored. Current value: bagging_fraction=0.6161682738316161\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.978319\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11766238993523667, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11766238993523667\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6192312231622974, subsample=0.4279383010203635 will be ignored. Current value: bagging_fraction=0.6192312231622974\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.968361\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.059809413527281134, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.059809413527281134\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7728721808120937, subsample=0.44123133742393955 will be ignored. Current value: bagging_fraction=0.7728721808120937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:45,980]\u001b[0m Trial 113 finished with value: 0.569620253164557 and parameters: {'n_estimators': 164, 'importance_type': 'split', 'num_leaves': 67, 'learning_rate': 0.8591943907800577, 'reg_lambda': 3.2704357671371884, 'reg_alpha': 98.36258222431411, 'colsample_bytree': 0.3156734684421017, 'scale_pos_weight': 8.948900999589174, 'depth': 2, 'min_data_in_leaf': 41, 'subsample': 0.44123133742393955, 'bagging_fraction': 0.7728721808120937, 'min_sum_hessian_in_leaf': 0.059809413527281134}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:46,065]\u001b[0m Trial 114 finished with value: 0.569620253164557 and parameters: {'n_estimators': 159, 'importance_type': 'split', 'num_leaves': 68, 'learning_rate': 0.8483782118354918, 'reg_lambda': 2.2643386239889347, 'reg_alpha': 99.49709470131745, 'colsample_bytree': 0.5557955027160647, 'scale_pos_weight': 8.97521471086013, 'depth': 2, 'min_data_in_leaf': 35, 'subsample': 0.38486588502504404, 'bagging_fraction': 0.8476070812624678, 'min_sum_hessian_in_leaf': 0.11279734303321703}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:46,138]\u001b[0m Trial 115 finished with value: 0.0 and parameters: {'n_estimators': 134, 'importance_type': 'split', 'num_leaves': 78, 'learning_rate': 0.9272827588968959, 'reg_lambda': 0.4123741550624187, 'reg_alpha': 98.92833838900975, 'colsample_bytree': 0.5689527994664557, 'scale_pos_weight': 7.379972401023326, 'depth': 2, 'min_data_in_leaf': 34, 'subsample': 0.44436483702721885, 'bagging_fraction': 0.8024753792813147, 'min_sum_hessian_in_leaf': 0.19379366122019415}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.972027\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11279734303321703, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11279734303321703\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8476070812624678, subsample=0.38486588502504404 will be ignored. Current value: bagging_fraction=0.8476070812624678\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.965277\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.19379366122019415, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.19379366122019415\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8024753792813147, subsample=0.44436483702721885 will be ignored. Current value: bagging_fraction=0.8024753792813147\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:46,224]\u001b[0m Trial 116 finished with value: 0.569620253164557 and parameters: {'n_estimators': 108, 'importance_type': 'split', 'num_leaves': 65, 'learning_rate': 0.8270042687822103, 'reg_lambda': 1.976815850374205, 'reg_alpha': 92.95547054376468, 'colsample_bytree': 0.6079894155849335, 'scale_pos_weight': 9.340355765672383, 'depth': 3, 'min_data_in_leaf': 39, 'subsample': 0.3619801552568963, 'bagging_fraction': 0.7074254826298233, 'min_sum_hessian_in_leaf': 0.1142716853975481}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:46,293]\u001b[0m Trial 117 finished with value: 0.569620253164557 and parameters: {'n_estimators': 118, 'importance_type': 'split', 'num_leaves': 75, 'learning_rate': 0.885200875893809, 'reg_lambda': 14.594264068654935, 'reg_alpha': 80.30212111548288, 'colsample_bytree': 0.45539136950400366, 'scale_pos_weight': 8.304469699970884, 'depth': 3, 'min_data_in_leaf': 27, 'subsample': 0.5218670832775814, 'bagging_fraction': 0.8011108583720405, 'min_sum_hessian_in_leaf': 0.1692288072966241}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:46,359]\u001b[0m Trial 118 finished with value: 0.569620253164557 and parameters: {'n_estimators': 110, 'importance_type': 'split', 'num_leaves': 76, 'learning_rate': 0.7653106183965593, 'reg_lambda': 1.0348926045647495, 'reg_alpha': 79.77374079007366, 'colsample_bytree': 0.6075966611387025, 'scale_pos_weight': 8.186805809825016, 'depth': 3, 'min_data_in_leaf': 28, 'subsample': 0.5190963159415259, 'bagging_fraction': 0.6716855413541246, 'min_sum_hessian_in_leaf': 0.15323974558995723}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1142716853975481, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1142716853975481\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7074254826298233, subsample=0.3619801552568963 will be ignored. Current value: bagging_fraction=0.7074254826298233\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.95877\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1692288072966241, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1692288072966241\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8011108583720405, subsample=0.5218670832775814 will be ignored. Current value: bagging_fraction=0.8011108583720405\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.974819\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.15323974558995723, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.15323974558995723\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6716855413541246, subsample=0.5190963159415259 will be ignored. Current value: bagging_fraction=0.6716855413541246\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.900257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:46,434]\u001b[0m Trial 119 finished with value: 0.569620253164557 and parameters: {'n_estimators': 120, 'importance_type': 'split', 'num_leaves': 75, 'learning_rate': 0.8846356073131303, 'reg_lambda': 15.378705529430123, 'reg_alpha': 81.05675448371818, 'colsample_bytree': 0.45816633736244283, 'scale_pos_weight': 8.202531499693848, 'depth': 4, 'min_data_in_leaf': 25, 'subsample': 0.5344601705776908, 'bagging_fraction': 0.7899160452196373, 'min_sum_hessian_in_leaf': 0.17639800027131025}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:46,512]\u001b[0m Trial 120 finished with value: 0.569620253164557 and parameters: {'n_estimators': 144, 'importance_type': 'split', 'num_leaves': 81, 'learning_rate': 0.7651645091178998, 'reg_lambda': 4.894593616594761, 'reg_alpha': 80.24320795662393, 'colsample_bytree': 0.473103232408914, 'scale_pos_weight': 7.152265630872844, 'depth': 4, 'min_data_in_leaf': 20, 'subsample': 0.5487566815873552, 'bagging_fraction': 0.6705295708616238, 'min_sum_hessian_in_leaf': 0.15428121879295878}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:46,595]\u001b[0m Trial 121 finished with value: 0.569620253164557 and parameters: {'n_estimators': 142, 'importance_type': 'split', 'num_leaves': 80, 'learning_rate': 0.8826536078337449, 'reg_lambda': 99.25192758809277, 'reg_alpha': 86.83044207139264, 'colsample_bytree': 0.5103355745911208, 'scale_pos_weight': 6.96736866182548, 'depth': 2, 'min_data_in_leaf': 26, 'subsample': 0.6042992944861904, 'bagging_fraction': 0.8003923407705047, 'min_sum_hessian_in_leaf': 0.13125742065428117}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.17639800027131025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.17639800027131025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7899160452196373, subsample=0.5344601705776908 will be ignored. Current value: bagging_fraction=0.7899160452196373\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.971534\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.15428121879295878, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.15428121879295878\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6705295708616238, subsample=0.5487566815873552 will be ignored. Current value: bagging_fraction=0.6705295708616238\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.877852\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.13125742065428117, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.13125742065428117\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8003923407705047, subsample=0.6042992944861904 will be ignored. Current value: bagging_fraction=0.8003923407705047\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.907033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:46,671]\u001b[0m Trial 122 finished with value: 0.569620253164557 and parameters: {'n_estimators': 139, 'importance_type': 'split', 'num_leaves': 82, 'learning_rate': 0.8354197225890259, 'reg_lambda': 5.200750141916868, 'reg_alpha': 87.35040670246683, 'colsample_bytree': 0.507395719226968, 'scale_pos_weight': 7.081936430010718, 'depth': 2, 'min_data_in_leaf': 22, 'subsample': 0.553806005695009, 'bagging_fraction': 0.7072254552849282, 'min_sum_hessian_in_leaf': 0.1399750222452598}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:46,744]\u001b[0m Trial 123 finished with value: 0.0 and parameters: {'n_estimators': 144, 'importance_type': 'split', 'num_leaves': 74, 'learning_rate': 0.9572950398758431, 'reg_lambda': 94.37598490872806, 'reg_alpha': 86.99961162175552, 'colsample_bytree': 0.5024854750415231, 'scale_pos_weight': 6.659196612234783, 'depth': 2, 'min_data_in_leaf': 51, 'subsample': 0.6024472377940537, 'bagging_fraction': 0.7667761526721514, 'min_sum_hessian_in_leaf': 0.1391221935395589}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:46,826]\u001b[0m Trial 124 finished with value: 0.0 and parameters: {'n_estimators': 179, 'importance_type': 'split', 'num_leaves': 73, 'learning_rate': 0.7041237225974135, 'reg_lambda': 5.677842050573563, 'reg_alpha': 84.60078988408843, 'colsample_bytree': 0.5503181015080683, 'scale_pos_weight': 7.713003623975001, 'depth': 1, 'min_data_in_leaf': 67, 'subsample': 0.24968408396316724, 'bagging_fraction': 0.5541230873058018, 'min_sum_hessian_in_leaf': 0.08887329418249809}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1399750222452598, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1399750222452598\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7072254552849282, subsample=0.553806005695009 will be ignored. Current value: bagging_fraction=0.7072254552849282\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.914373\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1391221935395589, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1391221935395589\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7667761526721514, subsample=0.6024472377940537 will be ignored. Current value: bagging_fraction=0.7667761526721514\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.08887329418249809, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.08887329418249809\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5541230873058018, subsample=0.24968408396316724 will be ignored. Current value: bagging_fraction=0.5541230873058018\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:46,905]\u001b[0m Trial 125 finished with value: 0.0 and parameters: {'n_estimators': 177, 'importance_type': 'split', 'num_leaves': 72, 'learning_rate': 0.6446701896028741, 'reg_lambda': 3.292086723485318, 'reg_alpha': 96.1700065176014, 'colsample_bytree': 0.39064914490115865, 'scale_pos_weight': 11.743208266903743, 'depth': 6, 'min_data_in_leaf': 68, 'subsample': 0.45810334825836574, 'bagging_fraction': 0.6553755261838553, 'min_sum_hessian_in_leaf': 0.04260879181114204}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:46,989]\u001b[0m Trial 126 finished with value: 0.569620253164557 and parameters: {'n_estimators': 230, 'importance_type': 'split', 'num_leaves': 93, 'learning_rate': 0.5717606030144561, 'reg_lambda': 13.375491847686515, 'reg_alpha': 88.83768536200381, 'colsample_bytree': 0.4030249428269429, 'scale_pos_weight': 11.211136063005302, 'depth': 4, 'min_data_in_leaf': 71, 'subsample': 0.4869498413566963, 'bagging_fraction': 0.6009615910213648, 'min_sum_hessian_in_leaf': 0.044393811126732276}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04260879181114204, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04260879181114204\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6553755261838553, subsample=0.45810334825836574 will be ignored. Current value: bagging_fraction=0.6553755261838553\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.044393811126732276, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.044393811126732276\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6009615910213648, subsample=0.4869498413566963 will be ignored. Current value: bagging_fraction=0.6009615910213648\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.2705\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.820781\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04970836406995585, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04970836406995585\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6050470058600192, subsample=0.5058810058521706 will be ignored. Current value: bagging_fraction=0.6050470058600192\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:47,081]\u001b[0m Trial 127 finished with value: 0.569620253164557 and parameters: {'n_estimators': 202, 'importance_type': 'split', 'num_leaves': 85, 'learning_rate': 0.6507018431301979, 'reg_lambda': 13.227092564728476, 'reg_alpha': 88.94554292159144, 'colsample_bytree': 0.4040972508447769, 'scale_pos_weight': 12.26186208775599, 'depth': 4, 'min_data_in_leaf': 32, 'subsample': 0.5058810058521706, 'bagging_fraction': 0.6050470058600192, 'min_sum_hessian_in_leaf': 0.04970836406995585}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:47,169]\u001b[0m Trial 128 finished with value: 0.569620253164557 and parameters: {'n_estimators': 214, 'importance_type': 'split', 'num_leaves': 78, 'learning_rate': 0.5726346599271142, 'reg_lambda': 14.074643938275347, 'reg_alpha': 88.67636932512497, 'colsample_bytree': 0.40033205843271186, 'scale_pos_weight': 13.322311100482978, 'depth': 4, 'min_data_in_leaf': 32, 'subsample': 0.5096968621315112, 'bagging_fraction': 0.5691111108300234, 'min_sum_hessian_in_leaf': 0.034838284441705225}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:47,240]\u001b[0m Trial 129 finished with value: 0.569620253164557 and parameters: {'n_estimators': 90, 'importance_type': 'split', 'num_leaves': 78, 'learning_rate': 0.6227331111712533, 'reg_lambda': 12.74494816302359, 'reg_alpha': 33.38238860708742, 'colsample_bytree': 0.44476728374048646, 'scale_pos_weight': 12.195910023600206, 'depth': 4, 'min_data_in_leaf': 34, 'subsample': 0.4923461710381672, 'bagging_fraction': 0.5730718368359822, 'min_sum_hessian_in_leaf': 0.09794403785391648}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 1.313\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.87459\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.034838284441705225, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.034838284441705225\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5691111108300234, subsample=0.5096968621315112 will be ignored. Current value: bagging_fraction=0.5691111108300234\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.35372\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.833876\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09794403785391648, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09794403785391648\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5730718368359822, subsample=0.4923461710381672 will be ignored. Current value: bagging_fraction=0.5730718368359822\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.861355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:47,328]\u001b[0m Trial 130 finished with value: 0.0 and parameters: {'n_estimators': 209, 'importance_type': 'split', 'num_leaves': 78, 'learning_rate': 0.5636362346970386, 'reg_lambda': 10.57456958912725, 'reg_alpha': 34.078319633409464, 'colsample_bytree': 0.376425998633755, 'scale_pos_weight': 13.594880163120264, 'depth': 5, 'min_data_in_leaf': 65, 'subsample': 0.24112640423543602, 'bagging_fraction': 0.5708726904083502, 'min_sum_hessian_in_leaf': 0.07333218369377055}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:47,413]\u001b[0m Trial 131 finished with value: 0.569620253164557 and parameters: {'n_estimators': 230, 'importance_type': 'split', 'num_leaves': 61, 'learning_rate': 0.49653982133231345, 'reg_lambda': 9.392836506912495, 'reg_alpha': 92.64548212173594, 'colsample_bytree': 0.43516114191822597, 'scale_pos_weight': 10.324831963776942, 'depth': 4, 'min_data_in_leaf': 57, 'subsample': 0.4881072600672607, 'bagging_fraction': 0.754589038477085, 'min_sum_hessian_in_leaf': 0.0775939265072299}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.07333218369377055, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.07333218369377055\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5708726904083502, subsample=0.24112640423543602 will be ignored. Current value: bagging_fraction=0.5708726904083502\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0775939265072299, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0775939265072299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.754589038477085, subsample=0.4881072600672607 will be ignored. Current value: bagging_fraction=0.754589038477085\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.23256\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.778325\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.026213506725062723, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.026213506725062723\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7461985933718305, subsample=0.30591599465747826 will be ignored. Current value: bagging_fraction=0.7461985933718305\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:47,507]\u001b[0m Trial 132 finished with value: 0.569620253164557 and parameters: {'n_estimators': 195, 'importance_type': 'split', 'num_leaves': 62, 'learning_rate': 0.5000164578210788, 'reg_lambda': 10.996220379486633, 'reg_alpha': 92.18738430437153, 'colsample_bytree': 0.41724488376556995, 'scale_pos_weight': 10.054950519116954, 'depth': 3, 'min_data_in_leaf': 48, 'subsample': 0.30591599465747826, 'bagging_fraction': 0.7461985933718305, 'min_sum_hessian_in_leaf': 0.026213506725062723}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:47,609]\u001b[0m Trial 133 finished with value: 0.569620253164557 and parameters: {'n_estimators': 233, 'importance_type': 'split', 'num_leaves': 70, 'learning_rate': 0.4619368177072544, 'reg_lambda': 10.244252971611077, 'reg_alpha': 91.93841668947114, 'colsample_bytree': 0.4207133308953777, 'scale_pos_weight': 10.337356632648822, 'depth': 3, 'min_data_in_leaf': 45, 'subsample': 0.3063615039684097, 'bagging_fraction': 0.7558374473089451, 'min_sum_hessian_in_leaf': 0.10073049060579076}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:47,692]\u001b[0m Trial 134 finished with value: 0.569620253164557 and parameters: {'n_estimators': 236, 'importance_type': 'split', 'num_leaves': 73, 'learning_rate': 0.48707607004327924, 'reg_lambda': 11.48444940216376, 'reg_alpha': 91.739334270881, 'colsample_bytree': 0.3834961272636396, 'scale_pos_weight': 9.920133171582195, 'depth': 3, 'min_data_in_leaf': 46, 'subsample': 0.3067522943885955, 'bagging_fraction': 0.7161511139285889, 'min_sum_hessian_in_leaf': 0.10001726459874707}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.778102\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10073049060579076, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10073049060579076\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7558374473089451, subsample=0.3063615039684097 will be ignored. Current value: bagging_fraction=0.7558374473089451\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.2302\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.763355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10001726459874707, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10001726459874707\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7161511139285889, subsample=0.3067522943885955 will be ignored. Current value: bagging_fraction=0.7161511139285889\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.21257\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.771596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:47,782]\u001b[0m Trial 135 finished with value: 0.569620253164557 and parameters: {'n_estimators': 235, 'importance_type': 'split', 'num_leaves': 71, 'learning_rate': 0.3950358111413781, 'reg_lambda': 11.870397092860806, 'reg_alpha': 85.04049164478144, 'colsample_bytree': 0.41768008466017104, 'scale_pos_weight': 9.905504860596206, 'depth': 4, 'min_data_in_leaf': 44, 'subsample': 0.17205722037402876, 'bagging_fraction': 0.6909315590419508, 'min_sum_hessian_in_leaf': 0.09956437512649095}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:47,862]\u001b[0m Trial 136 finished with value: 0.0 and parameters: {'n_estimators': 278, 'importance_type': 'split', 'num_leaves': 74, 'learning_rate': 0.39246089763209996, 'reg_lambda': 6.04934937657336, 'reg_alpha': 84.27376760509203, 'colsample_bytree': 0.43257771938310813, 'scale_pos_weight': 11.5661400442968, 'depth': 4, 'min_data_in_leaf': 61, 'subsample': 0.1604493870803214, 'bagging_fraction': 0.6905641799833082, 'min_sum_hessian_in_leaf': 0.09054468118753484}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09956437512649095, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09956437512649095\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6909315590419508, subsample=0.17205722037402876 will be ignored. Current value: bagging_fraction=0.6909315590419508\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.21521\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.736035\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09054468118753484, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09054468118753484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6905641799833082, subsample=0.1604493870803214 will be ignored. Current value: bagging_fraction=0.6905641799833082\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.03153406612826694, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.03153406612826694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7101685705387117, subsample=0.1819723643544684 will be ignored. Current value: bagging_fraction=0.7101685705387117\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:47,965]\u001b[0m Trial 137 finished with value: 0.569620253164557 and parameters: {'n_estimators': 289, 'importance_type': 'split', 'num_leaves': 55, 'learning_rate': 0.5850536101519875, 'reg_lambda': 22.33613796375616, 'reg_alpha': 51.11934945564877, 'colsample_bytree': 0.2896954961039759, 'scale_pos_weight': 10.943869416088887, 'depth': 1, 'min_data_in_leaf': 55, 'subsample': 0.1819723643544684, 'bagging_fraction': 0.7101685705387117, 'min_sum_hessian_in_leaf': 0.03153406612826694}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:48,055]\u001b[0m Trial 138 finished with value: 0.569620253164557 and parameters: {'n_estimators': 285, 'importance_type': 'split', 'num_leaves': 54, 'learning_rate': 0.5848091802970603, 'reg_lambda': 22.778926303645836, 'reg_alpha': 29.114167205145723, 'colsample_bytree': 0.27860478389936955, 'scale_pos_weight': 11.074293276307174, 'depth': 1, 'min_data_in_leaf': 56, 'subsample': 0.19533728622413205, 'bagging_fraction': 0.7166484280338293, 'min_sum_hessian_in_leaf': 0.06675133744125578}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:48,140]\u001b[0m Trial 139 finished with value: 0.569620253164557 and parameters: {'n_estimators': 254, 'importance_type': 'split', 'num_leaves': 55, 'learning_rate': 0.5238088716672336, 'reg_lambda': 22.815296261004057, 'reg_alpha': 52.83889811923025, 'colsample_bytree': 0.2872949359615386, 'scale_pos_weight': 10.621461317698447, 'depth': 5, 'min_data_in_leaf': 56, 'subsample': 0.2056795761387509, 'bagging_fraction': 0.7264377290814061, 'min_sum_hessian_in_leaf': 0.02346445539078078}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 1.28087\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.827552\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06675133744125578, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06675133744125578\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7166484280338293, subsample=0.19533728622413205 will be ignored. Current value: bagging_fraction=0.7166484280338293\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.27068\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.829959\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.02346445539078078, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.02346445539078078\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7264377290814061, subsample=0.2056795761387509 will be ignored. Current value: bagging_fraction=0.7264377290814061\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.23781\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.79361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:48,242]\u001b[0m Trial 140 finished with value: 0.569620253164557 and parameters: {'n_estimators': 259, 'importance_type': 'split', 'num_leaves': 54, 'learning_rate': 0.516201743493554, 'reg_lambda': 20.745830042005164, 'reg_alpha': 28.869461997025336, 'colsample_bytree': 0.33025426905924987, 'scale_pos_weight': 10.392362355782307, 'depth': 1, 'min_data_in_leaf': 58, 'subsample': 0.39648100885967197, 'bagging_fraction': 0.7383802194274001, 'min_sum_hessian_in_leaf': 0.062437496941749056}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:48,334]\u001b[0m Trial 141 finished with value: 0.569620253164557 and parameters: {'n_estimators': 264, 'importance_type': 'split', 'num_leaves': 45, 'learning_rate': 0.5512357727185473, 'reg_lambda': 20.200524021704688, 'reg_alpha': 49.016741850268595, 'colsample_bytree': 0.3381732773360705, 'scale_pos_weight': 10.261839519960954, 'depth': 5, 'min_data_in_leaf': 64, 'subsample': 0.32736892203395707, 'bagging_fraction': 0.8138570735273061, 'min_sum_hessian_in_leaf': 0.020583164826512332}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.062437496941749056, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.062437496941749056\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7383802194274001, subsample=0.39648100885967197 will be ignored. Current value: bagging_fraction=0.7383802194274001\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.24076\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.790292\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=64, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=64\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.020583164826512332, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.020583164826512332\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8138570735273061, subsample=0.32736892203395707 will be ignored. Current value: bagging_fraction=0.8138570735273061\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.23189\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.805343\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06402084757731447, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06402084757731447\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8299644520594576, subsample=0.31935514780680785 will be ignored. Current value: bagging_fraction=0.8299644520594576\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:48,434]\u001b[0m Trial 142 finished with value: 0.569620253164557 and parameters: {'n_estimators': 207, 'importance_type': 'split', 'num_leaves': 41, 'learning_rate': 0.5133246256745074, 'reg_lambda': 19.6933943725204, 'reg_alpha': 94.40902123121117, 'colsample_bytree': 0.32909839964822213, 'scale_pos_weight': 10.470456159417306, 'depth': 1, 'min_data_in_leaf': 65, 'subsample': 0.31935514780680785, 'bagging_fraction': 0.8299644520594576, 'min_sum_hessian_in_leaf': 0.06402084757731447}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:48,520]\u001b[0m Trial 143 finished with value: 0.569620253164557 and parameters: {'n_estimators': 206, 'importance_type': 'split', 'num_leaves': 44, 'learning_rate': 0.5523223697867015, 'reg_lambda': 18.807521153556888, 'reg_alpha': 47.864837412308006, 'colsample_bytree': 0.33534463926862074, 'scale_pos_weight': 11.297131292190867, 'depth': 1, 'min_data_in_leaf': 66, 'subsample': 0.3255508401603417, 'bagging_fraction': 0.8182181571426083, 'min_sum_hessian_in_leaf': 0.05726841749671456}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:48,622]\u001b[0m Trial 144 finished with value: 0.569620253164557 and parameters: {'n_estimators': 219, 'importance_type': 'split', 'num_leaves': 57, 'learning_rate': 0.8986558276929697, 'reg_lambda': 15.592015968876643, 'reg_alpha': 56.22488237429046, 'colsample_bytree': 0.3131279505703424, 'scale_pos_weight': 9.443573560567447, 'depth': 1, 'min_data_in_leaf': 41, 'subsample': 0.26008212797577124, 'bagging_fraction': 0.8488778071419567, 'min_sum_hessian_in_leaf': 0.03819371891366906}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 1.23619\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.785558\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05726841749671456, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05726841749671456\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8182181571426083, subsample=0.3255508401603417 will be ignored. Current value: bagging_fraction=0.8182181571426083\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.29444\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.813061\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.03819371891366906, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.03819371891366906\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8488778071419567, subsample=0.26008212797577124 will be ignored. Current value: bagging_fraction=0.8488778071419567\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.21229\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.01378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:48,702]\u001b[0m Trial 145 finished with value: 0.569620253164557 and parameters: {'n_estimators': 162, 'importance_type': 'split', 'num_leaves': 58, 'learning_rate': 0.5521497635836121, 'reg_lambda': 18.674465166452308, 'reg_alpha': 96.0643325440701, 'colsample_bytree': 0.3210768205415855, 'scale_pos_weight': 9.798153391774491, 'depth': 1, 'min_data_in_leaf': 41, 'subsample': 0.26295603247864546, 'bagging_fraction': 0.8487260617712382, 'min_sum_hessian_in_leaf': 0.05110097532895854}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:48,777]\u001b[0m Trial 146 finished with value: 0.0 and parameters: {'n_estimators': 170, 'importance_type': 'split', 'num_leaves': 67, 'learning_rate': 0.8731804841229928, 'reg_lambda': 24.910414727175787, 'reg_alpha': 96.59264128722698, 'colsample_bytree': 0.23170187439453, 'scale_pos_weight': 9.14576934654511, 'depth': 2, 'min_data_in_leaf': 40, 'subsample': 0.3768926031307708, 'bagging_fraction': 0.9150580970481641, 'min_sum_hessian_in_leaf': 0.004953677008962577}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:48,860]\u001b[0m Trial 147 finished with value: 0.569620253164557 and parameters: {'n_estimators': 299, 'importance_type': 'split', 'num_leaves': 49, 'learning_rate': 0.474588765393178, 'reg_lambda': 17.155647713774915, 'reg_alpha': 99.982712485106, 'colsample_bytree': 0.307782178794319, 'scale_pos_weight': 9.756720099570195, 'depth': 1, 'min_data_in_leaf': 50, 'subsample': 0.2790677776594692, 'bagging_fraction': 0.7577288339405971, 'min_sum_hessian_in_leaf': 0.020124181213663002}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05110097532895854, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05110097532895854\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8487260617712382, subsample=0.26295603247864546 will be ignored. Current value: bagging_fraction=0.8487260617712382\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.79918\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004953677008962577, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004953677008962577\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9150580970481641, subsample=0.3768926031307708 will be ignored. Current value: bagging_fraction=0.9150580970481641\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.020124181213663002, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.020124181213663002\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7577288339405971, subsample=0.2790677776594692 will be ignored. Current value: bagging_fraction=0.7577288339405971\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.19974\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.764334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:48,956]\u001b[0m Trial 148 finished with value: 0.0 and parameters: {'n_estimators': 194, 'importance_type': 'split', 'num_leaves': 63, 'learning_rate': 0.8615770620624627, 'reg_lambda': 6.260625493064158, 'reg_alpha': 90.68727783694575, 'colsample_bytree': 0.8093239297149643, 'scale_pos_weight': 9.39015424517499, 'depth': 3, 'min_data_in_leaf': 82, 'subsample': 0.461040948482967, 'bagging_fraction': 0.6227291078551449, 'min_sum_hessian_in_leaf': 0.043827340867871635}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:49,047]\u001b[0m Trial 149 finished with value: 0.569620253164557 and parameters: {'n_estimators': 246, 'importance_type': 'split', 'num_leaves': 56, 'learning_rate': 0.9194665204887182, 'reg_lambda': 8.215205280166906, 'reg_alpha': 94.87275191363852, 'colsample_bytree': 0.3802386517013751, 'scale_pos_weight': 10.099715224057972, 'depth': 2, 'min_data_in_leaf': 40, 'subsample': 0.4762805816302026, 'bagging_fraction': 0.7786220719124648, 'min_sum_hessian_in_leaf': 0.059062680835219324}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.043827340867871635, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.043827340867871635\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6227291078551449, subsample=0.461040948482967 will be ignored. Current value: bagging_fraction=0.6227291078551449\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.059062680835219324, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.059062680835219324\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7786220719124648, subsample=0.4762805816302026 will be ignored. Current value: bagging_fraction=0.7786220719124648\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.23848\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.03803\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06624342371599247, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06624342371599247\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6609975309938511, subsample=0.4739180961530977 will be ignored. Current value: bagging_fraction=0.6609975309938511\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:49,137]\u001b[0m Trial 150 finished with value: 0.569620253164557 and parameters: {'n_estimators': 155, 'importance_type': 'split', 'num_leaves': 61, 'learning_rate': 0.839891248452764, 'reg_lambda': 8.865259249502941, 'reg_alpha': 94.75133517602212, 'colsample_bytree': 0.38294652153837444, 'scale_pos_weight': 10.945387691890232, 'depth': 2, 'min_data_in_leaf': 31, 'subsample': 0.4739180961530977, 'bagging_fraction': 0.6609975309938511, 'min_sum_hessian_in_leaf': 0.06624342371599247}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:49,225]\u001b[0m Trial 151 finished with value: 0.569620253164557 and parameters: {'n_estimators': 168, 'importance_type': 'split', 'num_leaves': 52, 'learning_rate': 0.8496173576087135, 'reg_lambda': 8.990542656484827, 'reg_alpha': 93.70403984483625, 'colsample_bytree': 0.2988498629857662, 'scale_pos_weight': 8.67948209962769, 'depth': 2, 'min_data_in_leaf': 30, 'subsample': 0.42933454830876633, 'bagging_fraction': 0.6260300332935791, 'min_sum_hessian_in_leaf': 0.0716318196638751}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.991688\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0716318196638751, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0716318196638751\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6260300332935791, subsample=0.42933454830876633 will be ignored. Current value: bagging_fraction=0.6260300332935791\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.958819\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1162139449594532, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1162139449594532\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6270282944938306, subsample=0.419925533178547 will be ignored. Current value: bagging_fraction=0.6270282944938306\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.972986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:49,342]\u001b[0m Trial 152 finished with value: 0.569620253164557 and parameters: {'n_estimators': 168, 'importance_type': 'split', 'num_leaves': 51, 'learning_rate': 0.8688132700142491, 'reg_lambda': 2.244205080661379, 'reg_alpha': 99.19893501696257, 'colsample_bytree': 0.7030089148041542, 'scale_pos_weight': 8.674455250778802, 'depth': 2, 'min_data_in_leaf': 38, 'subsample': 0.419925533178547, 'bagging_fraction': 0.6270282944938306, 'min_sum_hessian_in_leaf': 0.1162139449594532}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:49,429]\u001b[0m Trial 153 finished with value: 0.0 and parameters: {'n_estimators': 272, 'importance_type': 'split', 'num_leaves': 53, 'learning_rate': 0.7277130447218607, 'reg_lambda': 5.41161011858257, 'reg_alpha': 89.52939232917649, 'colsample_bytree': 0.270606968857491, 'scale_pos_weight': 9.315798137238318, 'depth': 3, 'min_data_in_leaf': 51, 'subsample': 0.2299005709888686, 'bagging_fraction': 0.7687465786558113, 'min_sum_hessian_in_leaf': 0.12432460826580356}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:49,504]\u001b[0m Trial 154 finished with value: 0.569620253164557 and parameters: {'n_estimators': 152, 'importance_type': 'split', 'num_leaves': 67, 'learning_rate': 0.790644318926037, 'reg_lambda': 1.9958554965912056, 'reg_alpha': 97.52716467239509, 'colsample_bytree': 0.36815949057874475, 'scale_pos_weight': 8.940882604500482, 'depth': 3, 'min_data_in_leaf': 26, 'subsample': 0.5228608142895625, 'bagging_fraction': 0.7661444979338032, 'min_sum_hessian_in_leaf': 0.15336650304334826}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:49,574]\u001b[0m Trial 155 finished with value: 0.569620253164557 and parameters: {'n_estimators': 101, 'importance_type': 'split', 'num_leaves': 66, 'learning_rate': 0.8258990988168661, 'reg_lambda': 2.116392051787382, 'reg_alpha': 96.81607379164228, 'colsample_bytree': 0.6020755007029582, 'scale_pos_weight': 7.934574521675032, 'depth': 3, 'min_data_in_leaf': 28, 'subsample': 0.5350134639939721, 'bagging_fraction': 0.7826610395677909, 'min_sum_hessian_in_leaf': 0.17613673469323002}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.12432460826580356, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.12432460826580356\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7687465786558113, subsample=0.2299005709888686 will be ignored. Current value: bagging_fraction=0.7687465786558113\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.18904\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.15336650304334826, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.15336650304334826\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7661444979338032, subsample=0.5228608142895625 will be ignored. Current value: bagging_fraction=0.7661444979338032\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.926718\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.17613673469323002, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.17613673469323002\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7826610395677909, subsample=0.5350134639939721 will be ignored. Current value: bagging_fraction=0.7826610395677909\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.928938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:49,666]\u001b[0m Trial 156 finished with value: 0.0 and parameters: {'n_estimators': 110, 'importance_type': 'split', 'num_leaves': 64, 'learning_rate': 0.8271662332220827, 'reg_lambda': 1.9365830920494371, 'reg_alpha': 99.84412025062429, 'colsample_bytree': 0.6314330788865002, 'scale_pos_weight': 7.968698339457114, 'depth': 3, 'min_data_in_leaf': 35, 'subsample': 0.5454267770022063, 'bagging_fraction': 0.6770124284509065, 'min_sum_hessian_in_leaf': 0.17949044140920414}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:49,746]\u001b[0m Trial 157 finished with value: 0.569620253164557 and parameters: {'n_estimators': 143, 'importance_type': 'split', 'num_leaves': 82, 'learning_rate': 0.8608461996145017, 'reg_lambda': 3.8250534852371327, 'reg_alpha': 78.7370256707452, 'colsample_bytree': 0.5010139058606639, 'scale_pos_weight': 7.171727463263868, 'depth': 2, 'min_data_in_leaf': 20, 'subsample': 0.5536544390784602, 'bagging_fraction': 0.7982045167026981, 'min_sum_hessian_in_leaf': 0.13857051978144513}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:49,823]\u001b[0m Trial 158 finished with value: 0.0 and parameters: {'n_estimators': 152, 'importance_type': 'split', 'num_leaves': 69, 'learning_rate': 0.866077538314565, 'reg_lambda': 4.340339719556892, 'reg_alpha': 79.52058889998196, 'colsample_bytree': 0.2554151885305753, 'scale_pos_weight': 8.532503465119435, 'depth': 2, 'min_data_in_leaf': 22, 'subsample': 0.5582455332481692, 'bagging_fraction': 0.6720121067464647, 'min_sum_hessian_in_leaf': 0.20643843705559348}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.17949044140920414, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.17949044140920414\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6770124284509065, subsample=0.5454267770022063 will be ignored. Current value: bagging_fraction=0.6770124284509065\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.13857051978144513, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.13857051978144513\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7982045167026981, subsample=0.5536544390784602 will be ignored. Current value: bagging_fraction=0.7982045167026981\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.934126\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.20643843705559348, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.20643843705559348\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6720121067464647, subsample=0.5582455332481692 will be ignored. Current value: bagging_fraction=0.6720121067464647\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:49,907]\u001b[0m Trial 159 finished with value: 0.569620253164557 and parameters: {'n_estimators': 115, 'importance_type': 'split', 'num_leaves': 75, 'learning_rate': 0.8866900140501504, 'reg_lambda': 15.986637894418298, 'reg_alpha': 74.14030291207716, 'colsample_bytree': 0.8703154908395042, 'scale_pos_weight': 8.434389447878647, 'depth': 3, 'min_data_in_leaf': 40, 'subsample': 0.3940982827272039, 'bagging_fraction': 0.8599124939177799, 'min_sum_hessian_in_leaf': 0.16555567279553424}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:49,996]\u001b[0m Trial 160 finished with value: 0.569620253164557 and parameters: {'n_estimators': 217, 'importance_type': 'split', 'num_leaves': 64, 'learning_rate': 0.9389276753502082, 'reg_lambda': 8.570036473532799, 'reg_alpha': 92.90575996676083, 'colsample_bytree': 0.7623599780757795, 'scale_pos_weight': 9.089734216340423, 'depth': 3, 'min_data_in_leaf': 46, 'subsample': 0.35701539323558495, 'bagging_fraction': 0.6468502222702149, 'min_sum_hessian_in_leaf': 0.030170948678942162}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.16555567279553424, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.16555567279553424\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8599124939177799, subsample=0.3940982827272039 will be ignored. Current value: bagging_fraction=0.8599124939177799\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.979622\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.030170948678942162, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.030170948678942162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6468502222702149, subsample=0.35701539323558495 will be ignored. Current value: bagging_fraction=0.6468502222702149\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.17356\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.03138\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.07703654580095469, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.07703654580095469\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7044163941696088, subsample=0.4439079875402398 will be ignored. Current value: bagging_fraction=0.7044163941696088\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:50,099]\u001b[0m Trial 161 finished with value: 0.569620253164557 and parameters: {'n_estimators': 188, 'importance_type': 'split', 'num_leaves': 59, 'learning_rate': 0.427589486225475, 'reg_lambda': 5.740050388743997, 'reg_alpha': 85.87456110970638, 'colsample_bytree': 0.3460962715557165, 'scale_pos_weight': 10.923550058268107, 'depth': 6, 'min_data_in_leaf': 44, 'subsample': 0.4439079875402398, 'bagging_fraction': 0.7044163941696088, 'min_sum_hessian_in_leaf': 0.07703654580095469}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:50,185]\u001b[0m Trial 162 finished with value: 0.569620253164557 and parameters: {'n_estimators': 337, 'importance_type': 'split', 'num_leaves': 65, 'learning_rate': 0.8894227226452769, 'reg_lambda': 6.004966563705736, 'reg_alpha': 91.65342738054817, 'colsample_bytree': 0.3654905908960082, 'scale_pos_weight': 10.772421055058988, 'depth': 4, 'min_data_in_leaf': 74, 'subsample': 0.3859565039154696, 'bagging_fraction': 0.7268786651175464, 'min_sum_hessian_in_leaf': 0.08417053561220304}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:50,259]\u001b[0m Trial 163 finished with value: 0.569620253164557 and parameters: {'n_estimators': 107, 'importance_type': 'split', 'num_leaves': 61, 'learning_rate': 0.9130798421289292, 'reg_lambda': 0.30444582977226964, 'reg_alpha': 82.11196765671839, 'colsample_bytree': 0.4665339648032036, 'scale_pos_weight': 8.290786741227011, 'depth': 3, 'min_data_in_leaf': 27, 'subsample': 0.38546970702635214, 'bagging_fraction': 0.7285093604067303, 'min_sum_hessian_in_leaf': 0.15020618130231997}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.752619\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.08417053561220304, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.08417053561220304\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7268786651175464, subsample=0.3859565039154696 will be ignored. Current value: bagging_fraction=0.7268786651175464\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.27048\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.02818\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.15020618130231997, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.15020618130231997\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7285093604067303, subsample=0.38546970702635214 will be ignored. Current value: bagging_fraction=0.7285093604067303\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.998662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:50,341]\u001b[0m Trial 164 finished with value: 0.569620253164557 and parameters: {'n_estimators': 126, 'importance_type': 'split', 'num_leaves': 76, 'learning_rate': 0.9026758670825988, 'reg_lambda': 82.80663873693076, 'reg_alpha': 81.09445451181941, 'colsample_bytree': 0.47290982840598306, 'scale_pos_weight': 8.24821520068009, 'depth': 2, 'min_data_in_leaf': 26, 'subsample': 0.5797763489989589, 'bagging_fraction': 0.8059667552131314, 'min_sum_hessian_in_leaf': 0.1678752809860481}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:50,416]\u001b[0m Trial 165 finished with value: 0.569620253164557 and parameters: {'n_estimators': 122, 'importance_type': 'split', 'num_leaves': 76, 'learning_rate': 0.8828485178838787, 'reg_lambda': 83.14815902010744, 'reg_alpha': 80.11867432315688, 'colsample_bytree': 0.450462609676837, 'scale_pos_weight': 7.4526701795519, 'depth': 2, 'min_data_in_leaf': 20, 'subsample': 0.6261552567067118, 'bagging_fraction': 0.8096354904564245, 'min_sum_hessian_in_leaf': 0.19228716292835152}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:50,497]\u001b[0m Trial 166 finished with value: 0.569620253164557 and parameters: {'n_estimators': 145, 'importance_type': 'split', 'num_leaves': 81, 'learning_rate': 0.952634857103271, 'reg_lambda': 82.80469966808658, 'reg_alpha': 79.40804147125073, 'colsample_bytree': 0.5307285276550706, 'scale_pos_weight': 6.918705675543692, 'depth': 2, 'min_data_in_leaf': 22, 'subsample': 0.6157033423520406, 'bagging_fraction': 0.8373429152647219, 'min_sum_hessian_in_leaf': 0.22063539520661485}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1678752809860481, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1678752809860481\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8059667552131314, subsample=0.5797763489989589 will be ignored. Current value: bagging_fraction=0.8059667552131314\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.96097\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.19228716292835152, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.19228716292835152\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8096354904564245, subsample=0.6261552567067118 will be ignored. Current value: bagging_fraction=0.8096354904564245\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.927688\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.22063539520661485, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.22063539520661485\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8373429152647219, subsample=0.6157033423520406 will be ignored. Current value: bagging_fraction=0.8373429152647219\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.951715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:50,595]\u001b[0m Trial 167 finished with value: 0.569620253164557 and parameters: {'n_estimators': 221, 'importance_type': 'gain', 'num_leaves': 57, 'learning_rate': 0.8364234559999528, 'reg_lambda': 2.7125704211564257, 'reg_alpha': 89.6675487530412, 'colsample_bytree': 0.3143880137345107, 'scale_pos_weight': 9.271504525878342, 'depth': 3, 'min_data_in_leaf': 33, 'subsample': 0.5140634872452128, 'bagging_fraction': 0.6852321611899487, 'min_sum_hessian_in_leaf': 0.0027949328960017}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:50,681]\u001b[0m Trial 168 finished with value: 0.569620253164557 and parameters: {'n_estimators': 93, 'importance_type': 'split', 'num_leaves': 56, 'learning_rate': 0.7590122576516756, 'reg_lambda': 0.03006996817052876, 'reg_alpha': 95.89681635850259, 'colsample_bytree': 0.48514819163861655, 'scale_pos_weight': 8.869125584892506, 'depth': 3, 'min_data_in_leaf': 36, 'subsample': 0.35011139124929735, 'bagging_fraction': 0.7015177040335965, 'min_sum_hessian_in_leaf': 0.10980206885445452}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0027949328960017, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0027949328960017\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6852321611899487, subsample=0.5140634872452128 will be ignored. Current value: bagging_fraction=0.6852321611899487\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.19804\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.96431\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10980206885445452, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10980206885445452\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7015177040335965, subsample=0.35011139124929735 will be ignored. Current value: bagging_fraction=0.7015177040335965\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.906291\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.12519445641664817, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.12519445641664817\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7431117887749729, subsample=0.3687840367175206 will be ignored. Current value: bagging_fraction=0.7431117887749729\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:50,777]\u001b[0m Trial 169 finished with value: 0.569620253164557 and parameters: {'n_estimators': 113, 'importance_type': 'split', 'num_leaves': 60, 'learning_rate': 0.8034011488405773, 'reg_lambda': 4.107571720973223, 'reg_alpha': 97.52960312321795, 'colsample_bytree': 0.45044186157120975, 'scale_pos_weight': 9.820822189493663, 'depth': 3, 'min_data_in_leaf': 30, 'subsample': 0.3687840367175206, 'bagging_fraction': 0.7431117887749729, 'min_sum_hessian_in_leaf': 0.12519445641664817}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:50,862]\u001b[0m Trial 170 finished with value: 0.0 and parameters: {'n_estimators': 130, 'importance_type': 'split', 'num_leaves': 63, 'learning_rate': 0.8586283888151841, 'reg_lambda': 11.661612378266272, 'reg_alpha': 93.16978050273535, 'colsample_bytree': 0.43357780788892253, 'scale_pos_weight': 6.143954230096481, 'depth': 4, 'min_data_in_leaf': 38, 'subsample': 0.40708711504946293, 'bagging_fraction': 0.7818660261334109, 'min_sum_hessian_in_leaf': 0.021573532790237875}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:50,943]\u001b[0m Trial 171 finished with value: 0.569620253164557 and parameters: {'n_estimators': 138, 'importance_type': 'split', 'num_leaves': 87, 'learning_rate': 0.8317545468600193, 'reg_lambda': 60.94027616133352, 'reg_alpha': 75.31987577873814, 'colsample_bytree': 0.5377652557174882, 'scale_pos_weight': 5.632441143441461, 'depth': 2, 'min_data_in_leaf': 32, 'subsample': 0.5810573820957761, 'bagging_fraction': 0.6085783904175481, 'min_sum_hessian_in_leaf': 0.15089177197814857}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.94935\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.021573532790237875, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.021573532790237875\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7818660261334109, subsample=0.40708711504946293 will be ignored. Current value: bagging_fraction=0.7818660261334109\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.15089177197814857, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.15089177197814857\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6085783904175481, subsample=0.5810573820957761 will be ignored. Current value: bagging_fraction=0.6085783904175481\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.852946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:51,032]\u001b[0m Trial 172 finished with value: 0.569620253164557 and parameters: {'n_estimators': 156, 'importance_type': 'split', 'num_leaves': 82, 'learning_rate': 0.8176398168235622, 'reg_lambda': 67.57426982654442, 'reg_alpha': 87.37555111193156, 'colsample_bytree': 0.507010150193725, 'scale_pos_weight': 7.707526189435259, 'depth': 2, 'min_data_in_leaf': 23, 'subsample': 0.5350862811983317, 'bagging_fraction': 0.6742973671349342, 'min_sum_hessian_in_leaf': 0.1319471396062866}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:51,120]\u001b[0m Trial 173 finished with value: 0.569620253164557 and parameters: {'n_estimators': 185, 'importance_type': 'split', 'num_leaves': 68, 'learning_rate': 0.777535828396583, 'reg_lambda': 2.536346038630521, 'reg_alpha': 82.99087064513354, 'colsample_bytree': 0.41067702077706203, 'scale_pos_weight': 8.178766808538747, 'depth': 1, 'min_data_in_leaf': 30, 'subsample': 0.5233465846509101, 'bagging_fraction': 0.7933560002354894, 'min_sum_hessian_in_leaf': 0.11863280137719062}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1319471396062866, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1319471396062866\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6742973671349342, subsample=0.5350862811983317 will be ignored. Current value: bagging_fraction=0.6742973671349342\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.900449\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11863280137719062, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11863280137719062\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7933560002354894, subsample=0.5233465846509101 will be ignored. Current value: bagging_fraction=0.7933560002354894\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.906549\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.14558153799471943, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.14558153799471943\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7038917639791045, subsample=0.5931379411462431 will be ignored. Current value: bagging_fraction=0.7038917639791045\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:51,210]\u001b[0m Trial 174 finished with value: 0.569620253164557 and parameters: {'n_estimators': 135, 'importance_type': 'split', 'num_leaves': 85, 'learning_rate': 0.8796225814398373, 'reg_lambda': 13.917434990780018, 'reg_alpha': 87.18740658464036, 'colsample_bytree': 0.49578796548848153, 'scale_pos_weight': 7.064742873985997, 'depth': 2, 'min_data_in_leaf': 24, 'subsample': 0.5931379411462431, 'bagging_fraction': 0.7038917639791045, 'min_sum_hessian_in_leaf': 0.14558153799471943}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:51,298]\u001b[0m Trial 175 finished with value: 0.569620253164557 and parameters: {'n_estimators': 144, 'importance_type': 'split', 'num_leaves': 67, 'learning_rate': 0.7509496998916136, 'reg_lambda': 4.252770375994686, 'reg_alpha': 95.3117052983877, 'colsample_bytree': 0.4798089511314916, 'scale_pos_weight': 7.50022099789363, 'depth': 1, 'min_data_in_leaf': 26, 'subsample': 0.5584883827615207, 'bagging_fraction': 0.667181165898435, 'min_sum_hessian_in_leaf': 0.1631997762792359}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:51,373]\u001b[0m Trial 176 finished with value: 0.0 and parameters: {'n_estimators': 113, 'importance_type': 'split', 'num_leaves': 80, 'learning_rate': 0.8471899331532926, 'reg_lambda': 92.44105441663271, 'reg_alpha': 97.72258220823397, 'colsample_bytree': 0.6118072780332928, 'scale_pos_weight': 6.3730745453090805, 'depth': 1, 'min_data_in_leaf': 35, 'subsample': 0.46162656337721425, 'bagging_fraction': 0.6014248047714363, 'min_sum_hessian_in_leaf': 0.11055374824484065}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.936984\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1631997762792359, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1631997762792359\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.667181165898435, subsample=0.5584883827615207 will be ignored. Current value: bagging_fraction=0.667181165898435\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.875308\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11055374824484065, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11055374824484065\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6014248047714363, subsample=0.46162656337721425 will be ignored. Current value: bagging_fraction=0.6014248047714363\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:51,454]\u001b[0m Trial 177 finished with value: 0.569620253164557 and parameters: {'n_estimators': 90, 'importance_type': 'split', 'num_leaves': 76, 'learning_rate': 0.6344701771578507, 'reg_lambda': 13.694999355098885, 'reg_alpha': 87.89433119926187, 'colsample_bytree': 0.5519850719946467, 'scale_pos_weight': 12.259274691177861, 'depth': 4, 'min_data_in_leaf': 32, 'subsample': 0.5030886599825671, 'bagging_fraction': 0.521314392062312, 'min_sum_hessian_in_leaf': 0.054738721694101926}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:51,539]\u001b[0m Trial 178 finished with value: 0.569620253164557 and parameters: {'n_estimators': 163, 'importance_type': 'split', 'num_leaves': 84, 'learning_rate': 0.8338383912214108, 'reg_lambda': 16.202342104106542, 'reg_alpha': 88.09529016280662, 'colsample_bytree': 0.5140065763018302, 'scale_pos_weight': 13.42023308028751, 'depth': 2, 'min_data_in_leaf': 20, 'subsample': 0.5132325820005877, 'bagging_fraction': 0.553735080275479, 'min_sum_hessian_in_leaf': 0.13408110206212498}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.054738721694101926, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.054738721694101926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.521314392062312, subsample=0.5030886599825671 will be ignored. Current value: bagging_fraction=0.521314392062312\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.864441\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.13408110206212498, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.13408110206212498\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.553735080275479, subsample=0.5132325820005877 will be ignored. Current value: bagging_fraction=0.553735080275479\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.01658\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.18836656811912642, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.18836656811912642\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.607525765788932, subsample=0.5469754537098321 will be ignored. Current value: bagging_fraction=0.607525765788932\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.970025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:51,642]\u001b[0m Trial 179 finished with value: 0.569620253164557 and parameters: {'n_estimators': 154, 'importance_type': 'split', 'num_leaves': 88, 'learning_rate': 0.8520018732202574, 'reg_lambda': 4.753451610445044, 'reg_alpha': 81.53159754801676, 'colsample_bytree': 0.45251799909878304, 'scale_pos_weight': 8.971995718318265, 'depth': 2, 'min_data_in_leaf': 41, 'subsample': 0.5469754537098321, 'bagging_fraction': 0.607525765788932, 'min_sum_hessian_in_leaf': 0.18836656811912642}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:51,718]\u001b[0m Trial 180 finished with value: 0.569620253164557 and parameters: {'n_estimators': 122, 'importance_type': 'split', 'num_leaves': 80, 'learning_rate': 0.9007019991619034, 'reg_lambda': 2.2631497807229968, 'reg_alpha': 84.06431093088926, 'colsample_bytree': 0.6484528340129904, 'scale_pos_weight': 6.793974777145561, 'depth': 2, 'min_data_in_leaf': 29, 'subsample': 0.48473797933153084, 'bagging_fraction': 0.585103502929873, 'min_sum_hessian_in_leaf': 0.09967071585818754}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:51,794]\u001b[0m Trial 181 finished with value: 0.569620253164557 and parameters: {'n_estimators': 100, 'importance_type': 'split', 'num_leaves': 77, 'learning_rate': 0.92825509372428, 'reg_lambda': 13.685422501426254, 'reg_alpha': 78.37006126663705, 'colsample_bytree': 0.4044307774260545, 'scale_pos_weight': 12.020132303519318, 'depth': 4, 'min_data_in_leaf': 35, 'subsample': 0.5110370537745936, 'bagging_fraction': 0.537290923406943, 'min_sum_hessian_in_leaf': 0.10838516279405465}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09967071585818754, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09967071585818754\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.585103502929873, subsample=0.48473797933153084 will be ignored. Current value: bagging_fraction=0.585103502929873\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.946389\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10838516279405465, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10838516279405465\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.537290923406943, subsample=0.5110370537745936 will be ignored. Current value: bagging_fraction=0.537290923406943\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.07894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:51,890]\u001b[0m Trial 182 finished with value: 0.569620253164557 and parameters: {'n_estimators': 169, 'importance_type': 'split', 'num_leaves': 82, 'learning_rate': 0.8706261149843413, 'reg_lambda': 12.735725049315228, 'reg_alpha': 72.75107358891248, 'colsample_bytree': 0.4453950162925183, 'scale_pos_weight': 12.752522188803017, 'depth': 4, 'min_data_in_leaf': 34, 'subsample': 0.5388960421469506, 'bagging_fraction': 0.5770993654885543, 'min_sum_hessian_in_leaf': 0.1320267342746959}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:51,976]\u001b[0m Trial 183 finished with value: 0.569620253164557 and parameters: {'n_estimators': 130, 'importance_type': 'split', 'num_leaves': 78, 'learning_rate': 0.5986550752573019, 'reg_lambda': 72.89997275140763, 'reg_alpha': 80.88326513397384, 'colsample_bytree': 0.4597549528119315, 'scale_pos_weight': 14.376819637787474, 'depth': 4, 'min_data_in_leaf': 38, 'subsample': 0.49351155844764344, 'bagging_fraction': 0.6261463726222873, 'min_sum_hessian_in_leaf': 0.0981462248337981}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1320267342746959, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1320267342746959\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5770993654885543, subsample=0.5388960421469506 will be ignored. Current value: bagging_fraction=0.5770993654885543\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.04206\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0981462248337981, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0981462248337981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6261463726222873, subsample=0.49351155844764344 will be ignored. Current value: bagging_fraction=0.6261463726222873\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.847497\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.14648036874851345, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.14648036874851345\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5633375336874424, subsample=0.49271071640711367 will be ignored. Current value: bagging_fraction=0.5633375336874424\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:52,072]\u001b[0m Trial 184 finished with value: 0.569620253164557 and parameters: {'n_estimators': 104, 'importance_type': 'split', 'num_leaves': 86, 'learning_rate': 0.6238951312840297, 'reg_lambda': 10.337402791659937, 'reg_alpha': 86.08758714107007, 'colsample_bytree': 0.4068614539540879, 'scale_pos_weight': 12.333918120507661, 'depth': 4, 'min_data_in_leaf': 25, 'subsample': 0.49271071640711367, 'bagging_fraction': 0.5633375336874424, 'min_sum_hessian_in_leaf': 0.14648036874851345}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:52,149]\u001b[0m Trial 185 finished with value: 0.0 and parameters: {'n_estimators': 115, 'importance_type': 'split', 'num_leaves': 79, 'learning_rate': 0.6159096543461641, 'reg_lambda': 0.8972707176519918, 'reg_alpha': 88.46802313373517, 'colsample_bytree': 0.4355144915489893, 'scale_pos_weight': 7.989496969534108, 'depth': 5, 'min_data_in_leaf': 33, 'subsample': 0.48103482594349517, 'bagging_fraction': 0.590845521686732, 'min_sum_hessian_in_leaf': 0.16822439689599777}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:52,237]\u001b[0m Trial 186 finished with value: 0.569620253164557 and parameters: {'n_estimators': 122, 'importance_type': 'split', 'num_leaves': 72, 'learning_rate': 0.4680433200781991, 'reg_lambda': 10.459176726991712, 'reg_alpha': 92.37288223252304, 'colsample_bytree': 0.5940210097112121, 'scale_pos_weight': 8.476502031042862, 'depth': 5, 'min_data_in_leaf': 48, 'subsample': 0.6856342693321812, 'bagging_fraction': 0.7548700126515496, 'min_sum_hessian_in_leaf': 0.0966474688948461}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.859186\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.16822439689599777, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.16822439689599777\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.590845521686732, subsample=0.48103482594349517 will be ignored. Current value: bagging_fraction=0.590845521686732\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0966474688948461, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0966474688948461\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7548700126515496, subsample=0.6856342693321812 will be ignored. Current value: bagging_fraction=0.7548700126515496\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.754793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:52,334]\u001b[0m Trial 187 finished with value: 0.569620253164557 and parameters: {'n_estimators': 229, 'importance_type': 'split', 'num_leaves': 75, 'learning_rate': 0.4895718357560592, 'reg_lambda': 12.358851687655836, 'reg_alpha': 92.44817070375053, 'colsample_bytree': 0.48723207347480146, 'scale_pos_weight': 11.576216026621173, 'depth': 4, 'min_data_in_leaf': 27, 'subsample': 0.566363579413471, 'bagging_fraction': 0.794189880618636, 'min_sum_hessian_in_leaf': 0.10134971956432823}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:52,419]\u001b[0m Trial 188 finished with value: 0.569620253164557 and parameters: {'n_estimators': 140, 'importance_type': 'split', 'num_leaves': 71, 'learning_rate': 0.42741304345033293, 'reg_lambda': 15.500995835561266, 'reg_alpha': 88.81942327987855, 'colsample_bytree': 0.41774907292724256, 'scale_pos_weight': 12.521968058824017, 'depth': 4, 'min_data_in_leaf': 45, 'subsample': 0.52776908742996, 'bagging_fraction': 0.7679956127432949, 'min_sum_hessian_in_leaf': 0.08728229132563135}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10134971956432823, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10134971956432823\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.794189880618636, subsample=0.566363579413471 will be ignored. Current value: bagging_fraction=0.794189880618636\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.28363\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.781454\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.08728229132563135, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.08728229132563135\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7679956127432949, subsample=0.52776908742996 will be ignored. Current value: bagging_fraction=0.7679956127432949\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.757381\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1329814411371082, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1329814411371082\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7566408889475398, subsample=0.2940338026217328 will be ignored. Current value: bagging_fraction=0.7566408889475398\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:52,502]\u001b[0m Trial 189 finished with value: 0.0 and parameters: {'n_estimators': 97, 'importance_type': 'split', 'num_leaves': 92, 'learning_rate': 0.45455316179378163, 'reg_lambda': 15.346783459488552, 'reg_alpha': 89.08818865063864, 'colsample_bytree': 0.4179000561046712, 'scale_pos_weight': 12.827680697422092, 'depth': 4, 'min_data_in_leaf': 48, 'subsample': 0.2940338026217328, 'bagging_fraction': 0.7566408889475398, 'min_sum_hessian_in_leaf': 0.1329814411371082}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:52,608]\u001b[0m Trial 190 finished with value: 0.0 and parameters: {'n_estimators': 236, 'importance_type': 'split', 'num_leaves': 94, 'learning_rate': 0.68719161789205, 'reg_lambda': 12.818665275654869, 'reg_alpha': 84.47287835587878, 'colsample_bytree': 0.9240029966826162, 'scale_pos_weight': 14.023749512543127, 'depth': 4, 'min_data_in_leaf': 56, 'subsample': 0.7309132947330378, 'bagging_fraction': 0.7128649909151586, 'min_sum_hessian_in_leaf': 0.0815782129054077}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:52,721]\u001b[0m Trial 191 finished with value: 0.569620253164557 and parameters: {'n_estimators': 232, 'importance_type': 'split', 'num_leaves': 74, 'learning_rate': 0.5914870078880827, 'reg_lambda': 12.336907743202229, 'reg_alpha': 32.449620854442884, 'colsample_bytree': 0.398648083696641, 'scale_pos_weight': 11.342082099339393, 'depth': 4, 'min_data_in_leaf': 53, 'subsample': 0.11339028062067616, 'bagging_fraction': 0.7133030767420824, 'min_sum_hessian_in_leaf': 0.03613311747427882}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0815782129054077, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0815782129054077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7128649909151586, subsample=0.7309132947330378 will be ignored. Current value: bagging_fraction=0.7128649909151586\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.03613311747427882, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.03613311747427882\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7133030767420824, subsample=0.11339028062067616 will be ignored. Current value: bagging_fraction=0.7133030767420824\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.24569\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.836974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:52,817]\u001b[0m Trial 192 finished with value: 0.569620253164557 and parameters: {'n_estimators': 197, 'importance_type': 'split', 'num_leaves': 70, 'learning_rate': 0.5760466309471679, 'reg_lambda': 14.434919136707457, 'reg_alpha': 27.921714026285954, 'colsample_bytree': 0.42085390677074414, 'scale_pos_weight': 13.070677377412567, 'depth': 3, 'min_data_in_leaf': 44, 'subsample': 0.1552249689174236, 'bagging_fraction': 0.5007364341133093, 'min_sum_hessian_in_leaf': 0.10062381784326588}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:52,920]\u001b[0m Trial 193 finished with value: 0.569620253164557 and parameters: {'n_estimators': 201, 'importance_type': 'split', 'num_leaves': 73, 'learning_rate': 0.36722008007092827, 'reg_lambda': 11.041132135215154, 'reg_alpha': 40.75081574159619, 'colsample_bytree': 0.3904027361541211, 'scale_pos_weight': 9.903658434457022, 'depth': 4, 'min_data_in_leaf': 20, 'subsample': 0.5131810199931456, 'bagging_fraction': 0.7097633692388644, 'min_sum_hessian_in_leaf': 0.06809122920454404}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10062381784326588, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10062381784326588\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5007364341133093, subsample=0.1552249689174236 will be ignored. Current value: bagging_fraction=0.5007364341133093\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.838463\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06809122920454404, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06809122920454404\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7097633692388644, subsample=0.5131810199931456 will be ignored. Current value: bagging_fraction=0.7097633692388644\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.20511\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.728204\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.079053189372211, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.079053189372211\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7160604306123415, subsample=0.16419330003257332 will be ignored. Current value: bagging_fraction=0.7160604306123415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:53,019]\u001b[0m Trial 194 finished with value: 0.0 and parameters: {'n_estimators': 288, 'importance_type': 'split', 'num_leaves': 77, 'learning_rate': 0.4931063575299022, 'reg_lambda': 10.352593995397791, 'reg_alpha': 61.3517649216732, 'colsample_bytree': 0.4351158421994611, 'scale_pos_weight': 11.12143042735618, 'depth': 3, 'min_data_in_leaf': 146, 'subsample': 0.16419330003257332, 'bagging_fraction': 0.7160604306123415, 'min_sum_hessian_in_leaf': 0.079053189372211}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:53,124]\u001b[0m Trial 195 finished with value: 0.569620253164557 and parameters: {'n_estimators': 307, 'importance_type': 'split', 'num_leaves': 100, 'learning_rate': 0.6502827945179704, 'reg_lambda': 7.583115121340219, 'reg_alpha': 83.29870712006655, 'colsample_bytree': 0.9723409800901311, 'scale_pos_weight': 10.170948305050844, 'depth': 5, 'min_data_in_leaf': 69, 'subsample': 0.21693198685126996, 'bagging_fraction': 0.645278881707671, 'min_sum_hessian_in_leaf': 0.034319475864976696}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.034319475864976696, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.034319475864976696\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.645278881707671, subsample=0.21693198685126996 will be ignored. Current value: bagging_fraction=0.645278881707671\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.22283\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.857504\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05442546643980359, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05442546643980359\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6934912049281403, subsample=0.1863670368199061 will be ignored. Current value: bagging_fraction=0.6934912049281403\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:53,217]\u001b[0m Trial 196 finished with value: 0.0 and parameters: {'n_estimators': 238, 'importance_type': 'split', 'num_leaves': 81, 'learning_rate': 0.5253840965038294, 'reg_lambda': 22.25822222944325, 'reg_alpha': 52.25438550443533, 'colsample_bytree': 0.2766633430756239, 'scale_pos_weight': 11.735896939496937, 'depth': 3, 'min_data_in_leaf': 53, 'subsample': 0.1863670368199061, 'bagging_fraction': 0.6934912049281403, 'min_sum_hessian_in_leaf': 0.05442546643980359}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:53,309]\u001b[0m Trial 197 finished with value: 0.569620253164557 and parameters: {'n_estimators': 259, 'importance_type': 'split', 'num_leaves': 47, 'learning_rate': 0.5712251150783126, 'reg_lambda': 7.707188737628972, 'reg_alpha': 32.2367584870036, 'colsample_bytree': 0.3868334209901611, 'scale_pos_weight': 10.387317187460903, 'depth': 5, 'min_data_in_leaf': 61, 'subsample': 0.13564249144038285, 'bagging_fraction': 0.6421001771414678, 'min_sum_hessian_in_leaf': 0.0318077768516881}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:53,404]\u001b[0m Trial 198 finished with value: 0.569620253164557 and parameters: {'n_estimators': 278, 'importance_type': 'gain', 'num_leaves': 47, 'learning_rate': 0.581427625766223, 'reg_lambda': 8.352453014836696, 'reg_alpha': 31.204363393368812, 'colsample_bytree': 0.37914853936726894, 'scale_pos_weight': 10.637803863687042, 'depth': 5, 'min_data_in_leaf': 58, 'subsample': 0.18390637041365954, 'bagging_fraction': 0.7212855254712677, 'min_sum_hessian_in_leaf': 0.04256737801520523}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0318077768516881, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0318077768516881\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6421001771414678, subsample=0.13564249144038285 will be ignored. Current value: bagging_fraction=0.6421001771414678\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.20483\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.819666\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04256737801520523, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04256737801520523\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7212855254712677, subsample=0.18390637041365954 will be ignored. Current value: bagging_fraction=0.7212855254712677\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.20958\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.827016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:53,508]\u001b[0m Trial 199 finished with value: 0.569620253164557 and parameters: {'n_estimators': 230, 'importance_type': 'split', 'num_leaves': 55, 'learning_rate': 0.5068877669785029, 'reg_lambda': 24.691330502859124, 'reg_alpha': 23.562260121731654, 'colsample_bytree': 0.40933217679488265, 'scale_pos_weight': 10.418048926154759, 'depth': 4, 'min_data_in_leaf': 55, 'subsample': 0.49386532125423976, 'bagging_fraction': 0.740017717037187, 'min_sum_hessian_in_leaf': 0.04687554459576}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:53,601]\u001b[0m Trial 200 finished with value: 0.569620253164557 and parameters: {'n_estimators': 253, 'importance_type': 'split', 'num_leaves': 39, 'learning_rate': 0.5199798688137061, 'reg_lambda': 21.519769369225052, 'reg_alpha': 48.27729166041871, 'colsample_bytree': 0.42215816936868866, 'scale_pos_weight': 10.228160513924822, 'depth': 4, 'min_data_in_leaf': 49, 'subsample': 0.20454906471933135, 'bagging_fraction': 0.7510587935997217, 'min_sum_hessian_in_leaf': 0.025764467442861032}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04687554459576, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04687554459576\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.740017717037187, subsample=0.49386532125423976 will be ignored. Current value: bagging_fraction=0.740017717037187\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.1728\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.785876\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.025764467442861032, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.025764467442861032\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7510587935997217, subsample=0.20454906471933135 will be ignored. Current value: bagging_fraction=0.7510587935997217\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.21972\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.789759\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06580124091073312, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06580124091073312\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7415199552983256, subsample=0.19645387652100868 will be ignored. Current value: bagging_fraction=0.7415199552983256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:53,718]\u001b[0m Trial 201 finished with value: 0.0 and parameters: {'n_estimators': 208, 'importance_type': 'split', 'num_leaves': 36, 'learning_rate': 0.5547329199383703, 'reg_lambda': 19.669524028010024, 'reg_alpha': 28.9105136366052, 'colsample_bytree': 0.27638155871946085, 'scale_pos_weight': 10.459098172830773, 'depth': 1, 'min_data_in_leaf': 73, 'subsample': 0.19645387652100868, 'bagging_fraction': 0.7415199552983256, 'min_sum_hessian_in_leaf': 0.06580124091073312}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:53,817]\u001b[0m Trial 202 finished with value: 0.569620253164557 and parameters: {'n_estimators': 248, 'importance_type': 'split', 'num_leaves': 56, 'learning_rate': 0.5316894417813043, 'reg_lambda': 7.418539493380244, 'reg_alpha': 90.53987312190225, 'colsample_bytree': 0.35125477323921495, 'scale_pos_weight': 10.644572263551213, 'depth': 5, 'min_data_in_leaf': 59, 'subsample': 0.17275483112581141, 'bagging_fraction': 0.7297648313179914, 'min_sum_hessian_in_leaf': 0.007271973784428544}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.24536\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=59, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=59\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.007271973784428544, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.007271973784428544\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7297648313179914, subsample=0.17275483112581141 will be ignored. Current value: bagging_fraction=0.7297648313179914\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.24954\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.797145\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.02845471864379091, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.02845471864379091\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8332865424853668, subsample=0.31730235689889397 will be ignored. Current value: bagging_fraction=0.8332865424853668\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:53,916]\u001b[0m Trial 203 finished with value: 0.569620253164557 and parameters: {'n_estimators': 208, 'importance_type': 'split', 'num_leaves': 44, 'learning_rate': 0.49141966415634464, 'reg_lambda': 19.138057472747377, 'reg_alpha': 57.40322079158432, 'colsample_bytree': 0.3242458898165733, 'scale_pos_weight': 11.274746276264452, 'depth': 1, 'min_data_in_leaf': 66, 'subsample': 0.31730235689889397, 'bagging_fraction': 0.8332865424853668, 'min_sum_hessian_in_leaf': 0.02845471864379091}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:54,010]\u001b[0m Trial 204 finished with value: 0.569620253164557 and parameters: {'n_estimators': 263, 'importance_type': 'split', 'num_leaves': 54, 'learning_rate': 0.5120879993397255, 'reg_lambda': 27.02074976886854, 'reg_alpha': 49.30923016118809, 'colsample_bytree': 0.4377591131030638, 'scale_pos_weight': 11.123222048711, 'depth': 1, 'min_data_in_leaf': 65, 'subsample': 0.3282523766590718, 'bagging_fraction': 0.8258592073443303, 'min_sum_hessian_in_leaf': 0.05825079865785783}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:54,107]\u001b[0m Trial 205 finished with value: 0.569620253164557 and parameters: {'n_estimators': 218, 'importance_type': 'split', 'num_leaves': 41, 'learning_rate': 0.5559778671255645, 'reg_lambda': 20.392557909397144, 'reg_alpha': 54.693612243450914, 'colsample_bytree': 0.33087715189798045, 'scale_pos_weight': 10.064923247422382, 'depth': 1, 'min_data_in_leaf': 46, 'subsample': 0.2975109368446445, 'bagging_fraction': 0.8728310272000985, 'min_sum_hessian_in_leaf': 0.0448344614905827}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 1.29414\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.781961\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05825079865785783, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05825079865785783\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8258592073443303, subsample=0.3282523766590718 will be ignored. Current value: bagging_fraction=0.8258592073443303\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.29007\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.79057\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0448344614905827, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0448344614905827\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8728310272000985, subsample=0.2975109368446445 will be ignored. Current value: bagging_fraction=0.8728310272000985\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.24377\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.805844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:54,206]\u001b[0m Trial 206 finished with value: 0.569620253164557 and parameters: {'n_estimators': 199, 'importance_type': 'split', 'num_leaves': 43, 'learning_rate': 0.5068392802252727, 'reg_lambda': 18.280459148181226, 'reg_alpha': 54.975912245099366, 'colsample_bytree': 0.37192367264951154, 'scale_pos_weight': 10.880998516703942, 'depth': 1, 'min_data_in_leaf': 62, 'subsample': 0.31338205878899844, 'bagging_fraction': 0.8228322471743075, 'min_sum_hessian_in_leaf': 0.06852932298745865}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:54,302]\u001b[0m Trial 207 finished with value: 0.569620253164557 and parameters: {'n_estimators': 230, 'importance_type': 'split', 'num_leaves': 45, 'learning_rate': 0.5469327192986472, 'reg_lambda': 22.655223007115925, 'reg_alpha': 35.90031728380059, 'colsample_bytree': 0.3165512093181503, 'scale_pos_weight': 10.182447315548144, 'depth': 1, 'min_data_in_leaf': 50, 'subsample': 0.2642074505308584, 'bagging_fraction': 0.8514101089575523, 'min_sum_hessian_in_leaf': 0.04894553987773405}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06852932298745865, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06852932298745865\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8228322471743075, subsample=0.31338205878899844 will be ignored. Current value: bagging_fraction=0.8228322471743075\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.787402\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04894553987773405, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04894553987773405\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8514101089575523, subsample=0.2642074505308584 will be ignored. Current value: bagging_fraction=0.8514101089575523\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.2384\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.803207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:54,421]\u001b[0m Trial 208 finished with value: 0.569620253164557 and parameters: {'n_estimators': 241, 'importance_type': 'split', 'num_leaves': 58, 'learning_rate': 0.47176491041559315, 'reg_lambda': 16.97791342715268, 'reg_alpha': 46.879750377075155, 'colsample_bytree': 0.29691839176548934, 'scale_pos_weight': 9.718598218209776, 'depth': 1, 'min_data_in_leaf': 49, 'subsample': 0.27746850437928516, 'bagging_fraction': 0.846397178365427, 'min_sum_hessian_in_leaf': 0.025127080424864834}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:54,511]\u001b[0m Trial 209 finished with value: 0.569620253164557 and parameters: {'n_estimators': 288, 'importance_type': 'split', 'num_leaves': 58, 'learning_rate': 0.792805029484994, 'reg_lambda': 6.732098589650637, 'reg_alpha': 52.394693955250204, 'colsample_bytree': 0.29617611086240875, 'scale_pos_weight': 9.551553187857147, 'depth': 3, 'min_data_in_leaf': 55, 'subsample': 0.40639147557401994, 'bagging_fraction': 0.738439838747466, 'min_sum_hessian_in_leaf': 0.001859200448060512}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.025127080424864834, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.025127080424864834\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.846397178365427, subsample=0.27746850437928516 will be ignored. Current value: bagging_fraction=0.846397178365427\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.22361\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.765801\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001859200448060512, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001859200448060512\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.738439838747466, subsample=0.40639147557401994 will be ignored. Current value: bagging_fraction=0.738439838747466\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.20357\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.943825\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:54,623]\u001b[0m Trial 210 finished with value: 0.569620253164557 and parameters: {'n_estimators': 263, 'importance_type': 'split', 'num_leaves': 70, 'learning_rate': 0.7925049990622773, 'reg_lambda': 6.886583693623001, 'reg_alpha': 51.85027733945643, 'colsample_bytree': 0.3546600709362016, 'scale_pos_weight': 10.78112395508286, 'depth': 3, 'min_data_in_leaf': 55, 'subsample': 0.34166584874521594, 'bagging_fraction': 0.7373891969436849, 'min_sum_hessian_in_leaf': 0.0033055335176895794}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:54,727]\u001b[0m Trial 211 finished with value: 0.569620253164557 and parameters: {'n_estimators': 266, 'importance_type': 'split', 'num_leaves': 69, 'learning_rate': 0.8099027956695077, 'reg_lambda': 23.052316204120814, 'reg_alpha': 50.01718177516413, 'colsample_bytree': 0.34394267368460457, 'scale_pos_weight': 10.719708897537272, 'depth': 1, 'min_data_in_leaf': 60, 'subsample': 0.3625061369557918, 'bagging_fraction': 0.7334492195465744, 'min_sum_hessian_in_leaf': 0.014169530866267618}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0033055335176895794, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0033055335176895794\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7373891969436849, subsample=0.34166584874521594 will be ignored. Current value: bagging_fraction=0.7373891969436849\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.26259\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.96135\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.014169530866267618, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.014169530866267618\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7334492195465744, subsample=0.3625061369557918 will be ignored. Current value: bagging_fraction=0.7334492195465744\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.27623\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.968802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:54,844]\u001b[0m Trial 212 finished with value: 0.0 and parameters: {'n_estimators': 269, 'importance_type': 'split', 'num_leaves': 39, 'learning_rate': 0.8070671703128812, 'reg_lambda': 24.293763232373067, 'reg_alpha': 63.954459262215835, 'colsample_bytree': 0.9862300097219852, 'scale_pos_weight': 10.636110544206577, 'depth': 5, 'min_data_in_leaf': 78, 'subsample': 0.3610734040867345, 'bagging_fraction': 0.7741649074836751, 'min_sum_hessian_in_leaf': 0.020616083971465374}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:54,947]\u001b[0m Trial 213 finished with value: 0.569620253164557 and parameters: {'n_estimators': 280, 'importance_type': 'split', 'num_leaves': 50, 'learning_rate': 0.7792866093123704, 'reg_lambda': 4.460115773586173, 'reg_alpha': 45.902062080262624, 'colsample_bytree': 0.9512801364810316, 'scale_pos_weight': 9.384428025311049, 'depth': 1, 'min_data_in_leaf': 64, 'subsample': 0.3989222874403127, 'bagging_fraction': 0.6954659568318492, 'min_sum_hessian_in_leaf': 0.001846672387475547}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=78, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=78\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.020616083971465374, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.020616083971465374\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7741649074836751, subsample=0.3610734040867345 will be ignored. Current value: bagging_fraction=0.7741649074836751\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=64, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=64\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001846672387475547, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001846672387475547\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6954659568318492, subsample=0.3989222874403127 will be ignored. Current value: bagging_fraction=0.6954659568318492\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.20606\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.933689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:55,049]\u001b[0m Trial 214 finished with value: 0.569620253164557 and parameters: {'n_estimators': 247, 'importance_type': 'split', 'num_leaves': 51, 'learning_rate': 0.483815862844318, 'reg_lambda': 19.599313535077382, 'reg_alpha': 43.719603280240385, 'colsample_bytree': 0.2874376663275352, 'scale_pos_weight': 9.938872773974857, 'depth': 1, 'min_data_in_leaf': 43, 'subsample': 0.2816257760538568, 'bagging_fraction': 0.8979814663786431, 'min_sum_hessian_in_leaf': 0.06983482793722676}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:55,143]\u001b[0m Trial 215 finished with value: 0.569620253164557 and parameters: {'n_estimators': 219, 'importance_type': 'split', 'num_leaves': 49, 'learning_rate': 0.4582931550309378, 'reg_lambda': 17.54322196766424, 'reg_alpha': 94.86737057631126, 'colsample_bytree': 0.307481639267831, 'scale_pos_weight': 9.842994306444272, 'depth': 1, 'min_data_in_leaf': 43, 'subsample': 0.24954871886655577, 'bagging_fraction': 0.813004057977334, 'min_sum_hessian_in_leaf': 0.0692330449191026}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06983482793722676, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06983482793722676\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8979814663786431, subsample=0.2816257760538568 will be ignored. Current value: bagging_fraction=0.8979814663786431\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.23074\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.77209\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0692330449191026, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0692330449191026\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.813004057977334, subsample=0.24954871886655577 will be ignored. Current value: bagging_fraction=0.813004057977334\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.20513\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.758449\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06675938463114707, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06675938463114707\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7725182888120214, subsample=0.23615688494501497 will be ignored. Current value: bagging_fraction=0.7725182888120214\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:55,253]\u001b[0m Trial 216 finished with value: 0.569620253164557 and parameters: {'n_estimators': 301, 'importance_type': 'split', 'num_leaves': 54, 'learning_rate': 0.3122939772512298, 'reg_lambda': 18.268328298710816, 'reg_alpha': 94.26292608045429, 'colsample_bytree': 0.3284530407619456, 'scale_pos_weight': 9.925950670069339, 'depth': 1, 'min_data_in_leaf': 41, 'subsample': 0.23615688494501497, 'bagging_fraction': 0.7725182888120214, 'min_sum_hessian_in_leaf': 0.06675938463114707}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:55,348]\u001b[0m Trial 217 finished with value: 0.569620253164557 and parameters: {'n_estimators': 310, 'importance_type': 'split', 'num_leaves': 59, 'learning_rate': 0.5409562772279588, 'reg_lambda': 3.91034588825349, 'reg_alpha': 74.09737721004264, 'colsample_bytree': 0.3352773781663372, 'scale_pos_weight': 9.450250302530756, 'depth': 5, 'min_data_in_leaf': 68, 'subsample': 0.4292230760067071, 'bagging_fraction': 0.7830992304651148, 'min_sum_hessian_in_leaf': 0.02411802004073037}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:55,433]\u001b[0m Trial 218 finished with value: 0.569620253164557 and parameters: {'n_estimators': 185, 'importance_type': 'split', 'num_leaves': 41, 'learning_rate': 0.5381285260711322, 'reg_lambda': 4.213522809870227, 'reg_alpha': 74.59953272340043, 'colsample_bytree': 0.3556487369853336, 'scale_pos_weight': 9.45786612766796, 'depth': 6, 'min_data_in_leaf': 71, 'subsample': 0.42895805077518095, 'bagging_fraction': 0.8205531928395102, 'min_sum_hessian_in_leaf': 0.04953865875121251}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 1.21334\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.710111\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.02411802004073037, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.02411802004073037\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7830992304651148, subsample=0.4292230760067071 will be ignored. Current value: bagging_fraction=0.7830992304651148\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.19408\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.794775\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04953865875121251, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04953865875121251\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8205531928395102, subsample=0.42895805077518095 will be ignored. Current value: bagging_fraction=0.8205531928395102\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.793423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:55,524]\u001b[0m Trial 219 finished with value: 0.0 and parameters: {'n_estimators': 289, 'importance_type': 'split', 'num_leaves': 49, 'learning_rate': 0.918881876800747, 'reg_lambda': 20.139607990476495, 'reg_alpha': 99.53179905834192, 'colsample_bytree': 0.2580488130319549, 'scale_pos_weight': 10.236142607651095, 'depth': 1, 'min_data_in_leaf': 51, 'subsample': 0.31071709855554025, 'bagging_fraction': 0.8433692682918394, 'min_sum_hessian_in_leaf': 0.06691629899135915}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:55,630]\u001b[0m Trial 220 finished with value: 0.0 and parameters: {'n_estimators': 296, 'importance_type': 'split', 'num_leaves': 72, 'learning_rate': 0.7354167074786128, 'reg_lambda': 7.012260322483533, 'reg_alpha': 76.70351872785726, 'colsample_bytree': 0.9953455037391884, 'scale_pos_weight': 11.075733195704345, 'depth': 5, 'min_data_in_leaf': 63, 'subsample': 0.2626330385680081, 'bagging_fraction': 0.8655846573327174, 'min_sum_hessian_in_leaf': 0.45547178942753097}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06691629899135915, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06691629899135915\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8433692682918394, subsample=0.31071709855554025 will be ignored. Current value: bagging_fraction=0.8433692682918394\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.23269\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.45547178942753097, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.45547178942753097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8655846573327174, subsample=0.2626330385680081 will be ignored. Current value: bagging_fraction=0.8655846573327174\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:55,736]\u001b[0m Trial 221 finished with value: 0.569620253164557 and parameters: {'n_estimators': 152, 'importance_type': 'split', 'num_leaves': 61, 'learning_rate': 0.7725742602755304, 'reg_lambda': 8.514595649675073, 'reg_alpha': 97.77177404730641, 'colsample_bytree': 0.3702247930555406, 'scale_pos_weight': 8.6316152258855, 'depth': 2, 'min_data_in_leaf': 28, 'subsample': 0.47309412346447455, 'bagging_fraction': 0.7830849190443304, 'min_sum_hessian_in_leaf': 0.17906270829355275}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:55,821]\u001b[0m Trial 222 finished with value: 0.569620253164557 and parameters: {'n_estimators': 175, 'importance_type': 'split', 'num_leaves': 58, 'learning_rate': 0.7736054865494145, 'reg_lambda': 8.544641414823124, 'reg_alpha': 96.96759042293718, 'colsample_bytree': 0.3638266368845589, 'scale_pos_weight': 8.76269773700635, 'depth': 2, 'min_data_in_leaf': 53, 'subsample': 0.4496329580697399, 'bagging_fraction': 0.7892449067246453, 'min_sum_hessian_in_leaf': 0.08661269854868875}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.17906270829355275, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.17906270829355275\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7830849190443304, subsample=0.47309412346447455 will be ignored. Current value: bagging_fraction=0.7830849190443304\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.90796\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.08661269854868875, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.08661269854868875\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7892449067246453, subsample=0.4496329580697399 will be ignored. Current value: bagging_fraction=0.7892449067246453\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.911028\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0629623678588207, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0629623678588207\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8682035675605733, subsample=0.29224730477953903 will be ignored. Current value: bagging_fraction=0.8682035675605733\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.714854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:55,908]\u001b[0m Trial 223 finished with value: 0.569620253164557 and parameters: {'n_estimators': 165, 'importance_type': 'split', 'num_leaves': 53, 'learning_rate': 0.3441179447701499, 'reg_lambda': 21.263278825321976, 'reg_alpha': 94.9482841894121, 'colsample_bytree': 0.3103020807180609, 'scale_pos_weight': 8.676916828789759, 'depth': 1, 'min_data_in_leaf': 40, 'subsample': 0.29224730477953903, 'bagging_fraction': 0.8682035675605733, 'min_sum_hessian_in_leaf': 0.0629623678588207}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:56,016]\u001b[0m Trial 224 finished with value: 0.0 and parameters: {'n_estimators': 250, 'importance_type': 'split', 'num_leaves': 55, 'learning_rate': 0.9616628642066112, 'reg_lambda': 17.274480938536307, 'reg_alpha': 99.85883765344904, 'colsample_bytree': 0.8696645578555213, 'scale_pos_weight': 9.145657182695304, 'depth': 1, 'min_data_in_leaf': 40, 'subsample': 0.3308384343940029, 'bagging_fraction': 0.8873648874541996, 'min_sum_hessian_in_leaf': 0.7407909804179766}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:56,106]\u001b[0m Trial 225 finished with value: 0.0 and parameters: {'n_estimators': 180, 'importance_type': 'split', 'num_leaves': 70, 'learning_rate': 0.8240281356876462, 'reg_lambda': 8.3188367909502, 'reg_alpha': 77.36217361777754, 'colsample_bytree': 0.685425577314811, 'scale_pos_weight': 11.486112453750021, 'depth': 2, 'min_data_in_leaf': 77, 'subsample': 0.4315223994983588, 'bagging_fraction': 0.656205607473659, 'min_sum_hessian_in_leaf': 0.01928921409615917}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.7407909804179766, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.7407909804179766\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8873648874541996, subsample=0.3308384343940029 will be ignored. Current value: bagging_fraction=0.8873648874541996\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01928921409615917, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.01928921409615917\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.656205607473659, subsample=0.4315223994983588 will be ignored. Current value: bagging_fraction=0.656205607473659\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0832595409626489, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0832595409626489\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6392291085590226, subsample=0.42629581063230354 will be ignored. Current value: bagging_fraction=0.6392291085590226\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:56,211]\u001b[0m Trial 226 finished with value: 0.569620253164557 and parameters: {'n_estimators': 179, 'importance_type': 'split', 'num_leaves': 68, 'learning_rate': 0.8516867104530164, 'reg_lambda': 0.6247597236299169, 'reg_alpha': 93.8661196098139, 'colsample_bytree': 0.8251373285572559, 'scale_pos_weight': 10.947512121058505, 'depth': 2, 'min_data_in_leaf': 51, 'subsample': 0.42629581063230354, 'bagging_fraction': 0.6392291085590226, 'min_sum_hessian_in_leaf': 0.0832595409626489}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:56,300]\u001b[0m Trial 227 finished with value: 0.0 and parameters: {'n_estimators': 192, 'importance_type': 'split', 'num_leaves': 52, 'learning_rate': 0.42175055503624376, 'reg_lambda': 20.972521599959567, 'reg_alpha': 97.45927356446948, 'colsample_bytree': 0.3215107788055789, 'scale_pos_weight': 8.906546305867955, 'depth': 1, 'min_data_in_leaf': 238, 'subsample': 0.22549668025331862, 'bagging_fraction': 0.8512749076335875, 'min_sum_hessian_in_leaf': 0.05704769002350631}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:56,389]\u001b[0m Trial 228 finished with value: 0.569620253164557 and parameters: {'n_estimators': 173, 'importance_type': 'gain', 'num_leaves': 66, 'learning_rate': 0.8405677324505961, 'reg_lambda': 6.305226182496016, 'reg_alpha': 90.72380147674053, 'colsample_bytree': 0.36600924730138523, 'scale_pos_weight': 10.545924016720257, 'depth': 2, 'min_data_in_leaf': 61, 'subsample': 0.45401678205754054, 'bagging_fraction': 0.6292669983069306, 'min_sum_hessian_in_leaf': 0.03784387867861775}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.00328\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05704769002350631, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05704769002350631\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8512749076335875, subsample=0.22549668025331862 will be ignored. Current value: bagging_fraction=0.8512749076335875\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.03784387867861775, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.03784387867861775\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6292669983069306, subsample=0.45401678205754054 will be ignored. Current value: bagging_fraction=0.6292669983069306\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.987565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:56,493]\u001b[0m Trial 229 finished with value: 0.0 and parameters: {'n_estimators': 331, 'importance_type': 'split', 'num_leaves': 46, 'learning_rate': 0.9126065755060505, 'reg_lambda': 25.874718287403077, 'reg_alpha': 99.5502616276854, 'colsample_bytree': 0.2847548763334995, 'scale_pos_weight': 7.787442085144403, 'depth': 1, 'min_data_in_leaf': 38, 'subsample': 0.3830680452637829, 'bagging_fraction': 0.8555240922785389, 'min_sum_hessian_in_leaf': 0.07754205199871672}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:56,592]\u001b[0m Trial 230 finished with value: 0.569620253164557 and parameters: {'n_estimators': 217, 'importance_type': 'split', 'num_leaves': 60, 'learning_rate': 0.813219995773111, 'reg_lambda': 1.9104165906762607, 'reg_alpha': 91.19250095810416, 'colsample_bytree': 0.7323121561613206, 'scale_pos_weight': 8.940094816196464, 'depth': 3, 'min_data_in_leaf': 70, 'subsample': 0.3446555008144001, 'bagging_fraction': 0.76298138984616, 'min_sum_hessian_in_leaf': 0.001144834280378787}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.07754205199871672, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.07754205199871672\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8555240922785389, subsample=0.3830680452637829 will be ignored. Current value: bagging_fraction=0.8555240922785389\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001144834280378787, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001144834280378787\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.76298138984616, subsample=0.3446555008144001 will be ignored. Current value: bagging_fraction=0.76298138984616\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.16927\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.942466\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.015230657284216746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.015230657284216746\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7627737146944344, subsample=0.3521388501561028 will be ignored. Current value: bagging_fraction=0.7627737146944344\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:56,719]\u001b[0m Trial 231 finished with value: 0.569620253164557 and parameters: {'n_estimators': 206, 'importance_type': 'split', 'num_leaves': 65, 'learning_rate': 0.8062434672290836, 'reg_lambda': 1.3265112064334819, 'reg_alpha': 90.73727960934553, 'colsample_bytree': 0.7353449828713648, 'scale_pos_weight': 10.231091017348612, 'depth': 3, 'min_data_in_leaf': 71, 'subsample': 0.3521388501561028, 'bagging_fraction': 0.7627737146944344, 'min_sum_hessian_in_leaf': 0.015230657284216746}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:56,823]\u001b[0m Trial 232 finished with value: 0.569620253164557 and parameters: {'n_estimators': 192, 'importance_type': 'split', 'num_leaves': 64, 'learning_rate': 0.7886301932258102, 'reg_lambda': 0.04689243117686792, 'reg_alpha': 84.64609565673841, 'colsample_bytree': 0.761606556730018, 'scale_pos_weight': 9.100642815543624, 'depth': 6, 'min_data_in_leaf': 46, 'subsample': 0.41138788465315573, 'bagging_fraction': 0.7613026663928026, 'min_sum_hessian_in_leaf': 0.02134344275211031}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 1.22775\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.95948\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.02134344275211031, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.02134344275211031\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7613026663928026, subsample=0.41138788465315573 will be ignored. Current value: bagging_fraction=0.7613026663928026\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.930726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:56,921]\u001b[0m Trial 233 finished with value: 0.569620253164557 and parameters: {'n_estimators': 379, 'importance_type': 'split', 'num_leaves': 56, 'learning_rate': 0.9326019411658656, 'reg_lambda': 19.01213418657609, 'reg_alpha': 56.906682873464476, 'colsample_bytree': 0.33556203412781554, 'scale_pos_weight': 8.120330412961101, 'depth': 1, 'min_data_in_leaf': 31, 'subsample': 0.37925023292761834, 'bagging_fraction': 0.8037663351635902, 'min_sum_hessian_in_leaf': 0.14645612192503912}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:57,018]\u001b[0m Trial 234 finished with value: 0.569620253164557 and parameters: {'n_estimators': 345, 'importance_type': 'split', 'num_leaves': 63, 'learning_rate': 0.8990747259608239, 'reg_lambda': 83.55050008367287, 'reg_alpha': 67.73680357551484, 'colsample_bytree': 0.3423064572056376, 'scale_pos_weight': 7.442440841481076, 'depth': 2, 'min_data_in_leaf': 27, 'subsample': 0.6550788561246504, 'bagging_fraction': 0.8081150427096478, 'min_sum_hessian_in_leaf': 0.17109103623472335}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.14645612192503912, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.14645612192503912\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8037663351635902, subsample=0.37925023292761834 will be ignored. Current value: bagging_fraction=0.8037663351635902\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.14564\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.00586\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.17109103623472335, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.17109103623472335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8081150427096478, subsample=0.6550788561246504 will be ignored. Current value: bagging_fraction=0.8081150427096478\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.10853\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.939158\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:57,118]\u001b[0m Trial 235 finished with value: 0.569620253164557 and parameters: {'n_estimators': 130, 'importance_type': 'split', 'num_leaves': 51, 'learning_rate': 0.8901898125481524, 'reg_lambda': 79.45454040522128, 'reg_alpha': 94.63536510478994, 'colsample_bytree': 0.3119418740522702, 'scale_pos_weight': 8.296445440856631, 'depth': 2, 'min_data_in_leaf': 26, 'subsample': 0.6319569876031136, 'bagging_fraction': 0.821409061986239, 'min_sum_hessian_in_leaf': 0.19655050406310542}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:57,209]\u001b[0m Trial 236 finished with value: 0.569620253164557 and parameters: {'n_estimators': 149, 'importance_type': 'split', 'num_leaves': 42, 'learning_rate': 0.9465033476579072, 'reg_lambda': 84.50050988602507, 'reg_alpha': 80.51455264455213, 'colsample_bytree': 0.5277964588993208, 'scale_pos_weight': 7.785861209757089, 'depth': 2, 'min_data_in_leaf': 24, 'subsample': 0.612581282041342, 'bagging_fraction': 0.8295668311204609, 'min_sum_hessian_in_leaf': 0.22680667006346242}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.19655050406310542, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.19655050406310542\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.821409061986239, subsample=0.6319569876031136 will be ignored. Current value: bagging_fraction=0.821409061986239\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.95291\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.22680667006346242, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.22680667006346242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8295668311204609, subsample=0.612581282041342 will be ignored. Current value: bagging_fraction=0.8295668311204609\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.97536\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.21001764797890465, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.21001764797890465\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8318555736004329, subsample=0.5659100991187362 will be ignored. Current value: bagging_fraction=0.8318555736004329\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:57,303]\u001b[0m Trial 237 finished with value: 0.569620253164557 and parameters: {'n_estimators': 105, 'importance_type': 'gain', 'num_leaves': 12, 'learning_rate': 0.9119545924849953, 'reg_lambda': 89.11809004432004, 'reg_alpha': 95.71315413746869, 'colsample_bytree': 0.6864577528377902, 'scale_pos_weight': 8.212774632805974, 'depth': 2, 'min_data_in_leaf': 20, 'subsample': 0.5659100991187362, 'bagging_fraction': 0.8318555736004329, 'min_sum_hessian_in_leaf': 0.21001764797890465}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:57,393]\u001b[0m Trial 238 finished with value: 0.569620253164557 and parameters: {'n_estimators': 102, 'importance_type': 'gain', 'num_leaves': 45, 'learning_rate': 0.9445407723596234, 'reg_lambda': 2.826392827621303, 'reg_alpha': 96.17898040474644, 'colsample_bytree': 0.4739704479226614, 'scale_pos_weight': 8.49769352666644, 'depth': 3, 'min_data_in_leaf': 29, 'subsample': 0.6189572545129879, 'bagging_fraction': 0.806068326136811, 'min_sum_hessian_in_leaf': 0.1586206183407007}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:57,475]\u001b[0m Trial 239 finished with value: 0.569620253164557 and parameters: {'n_estimators': 124, 'importance_type': 'gain', 'num_leaves': 58, 'learning_rate': 0.8805737466417637, 'reg_lambda': 83.25740617449365, 'reg_alpha': 93.54787683277806, 'colsample_bytree': 0.48895613676498706, 'scale_pos_weight': 8.50404955360209, 'depth': 2, 'min_data_in_leaf': 20, 'subsample': 0.576553200548862, 'bagging_fraction': 0.8432005902015499, 'min_sum_hessian_in_leaf': 0.20662718607873581}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.961007\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1586206183407007, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1586206183407007\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.806068326136811, subsample=0.6189572545129879 will be ignored. Current value: bagging_fraction=0.806068326136811\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.02236\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.20662718607873581, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.20662718607873581\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8432005902015499, subsample=0.576553200548862 will be ignored. Current value: bagging_fraction=0.8432005902015499\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.950911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:57,575]\u001b[0m Trial 240 finished with value: 0.569620253164557 and parameters: {'n_estimators': 118, 'importance_type': 'gain', 'num_leaves': 60, 'learning_rate': 0.9732299933987514, 'reg_lambda': 77.6138047513677, 'reg_alpha': 98.27586747431027, 'colsample_bytree': 0.45737204393291897, 'scale_pos_weight': 7.402712253484741, 'depth': 3, 'min_data_in_leaf': 31, 'subsample': 0.5333949763827551, 'bagging_fraction': 0.784761645395429, 'min_sum_hessian_in_leaf': 0.1755381623248533}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:57,667]\u001b[0m Trial 241 finished with value: 0.569620253164557 and parameters: {'n_estimators': 151, 'importance_type': 'gain', 'num_leaves': 56, 'learning_rate': 0.9092308977981215, 'reg_lambda': 4.857023598995511, 'reg_alpha': 96.27296376533772, 'colsample_bytree': 0.48551724621276304, 'scale_pos_weight': 7.20039190890377, 'depth': 3, 'min_data_in_leaf': 31, 'subsample': 0.6324638496055462, 'bagging_fraction': 0.8146835417461619, 'min_sum_hessian_in_leaf': 0.18652929856773007}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1755381623248533, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1755381623248533\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.784761645395429, subsample=0.5333949763827551 will be ignored. Current value: bagging_fraction=0.784761645395429\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.97852\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.18652929856773007, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.18652929856773007\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8146835417461619, subsample=0.6324638496055462 will be ignored. Current value: bagging_fraction=0.8146835417461619\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.960736\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.15140339518750576, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.15140339518750576\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8375320300779204, subsample=0.5867688769874186 will be ignored. Current value: bagging_fraction=0.8375320300779204\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:57,770]\u001b[0m Trial 242 finished with value: 0.569620253164557 and parameters: {'n_estimators': 139, 'importance_type': 'split', 'num_leaves': 62, 'learning_rate': 0.8947803218402661, 'reg_lambda': 52.512722343613376, 'reg_alpha': 94.22053735168201, 'colsample_bytree': 0.521930888711162, 'scale_pos_weight': 7.037649656349185, 'depth': 2, 'min_data_in_leaf': 20, 'subsample': 0.5867688769874186, 'bagging_fraction': 0.8375320300779204, 'min_sum_hessian_in_leaf': 0.15140339518750576}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:57,864]\u001b[0m Trial 243 finished with value: 0.569620253164557 and parameters: {'n_estimators': 156, 'importance_type': 'split', 'num_leaves': 87, 'learning_rate': 0.8726147522625071, 'reg_lambda': 68.33127857155085, 'reg_alpha': 97.04292062085703, 'colsample_bytree': 0.5386203884959818, 'scale_pos_weight': 6.567507348621222, 'depth': 2, 'min_data_in_leaf': 27, 'subsample': 0.5852990596860843, 'bagging_fraction': 0.678639379677465, 'min_sum_hessian_in_leaf': 0.12485024964118474}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:57,954]\u001b[0m Trial 244 finished with value: 0.569620253164557 and parameters: {'n_estimators': 149, 'importance_type': 'split', 'num_leaves': 84, 'learning_rate': 0.9309192838686224, 'reg_lambda': 67.60030746062849, 'reg_alpha': 82.5202630993873, 'colsample_bytree': 0.5000469486111123, 'scale_pos_weight': 4.736374291772262, 'depth': 2, 'min_data_in_leaf': 32, 'subsample': 0.657035138891845, 'bagging_fraction': 0.65756524297687, 'min_sum_hessian_in_leaf': 0.1365602210186914}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.929849\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.12485024964118474, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.12485024964118474\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.678639379677465, subsample=0.5852990596860843 will be ignored. Current value: bagging_fraction=0.678639379677465\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.897066\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1365602210186914, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1365602210186914\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.65756524297687, subsample=0.657035138891845 will be ignored. Current value: bagging_fraction=0.65756524297687\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.854812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:58,047]\u001b[0m Trial 245 finished with value: 0.569620253164557 and parameters: {'n_estimators': 137, 'importance_type': 'split', 'num_leaves': 82, 'learning_rate': 0.8646357796181487, 'reg_lambda': 59.389749065068145, 'reg_alpha': 78.7930570108233, 'colsample_bytree': 0.5080348734194363, 'scale_pos_weight': 7.861470881608556, 'depth': 2, 'min_data_in_leaf': 24, 'subsample': 0.5500220380195389, 'bagging_fraction': 0.6795325217566865, 'min_sum_hessian_in_leaf': 0.12678739147763216}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:58,134]\u001b[0m Trial 246 finished with value: 0.569620253164557 and parameters: {'n_estimators': 132, 'importance_type': 'split', 'num_leaves': 86, 'learning_rate': 0.8397002493294122, 'reg_lambda': 86.13681202210529, 'reg_alpha': 82.2355436225797, 'colsample_bytree': 0.5301276231453493, 'scale_pos_weight': 6.928186196044793, 'depth': 2, 'min_data_in_leaf': 24, 'subsample': 0.6007666267848173, 'bagging_fraction': 0.7041682419265426, 'min_sum_hessian_in_leaf': 0.15159774380666147}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.12678739147763216, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.12678739147763216\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6795325217566865, subsample=0.5500220380195389 will be ignored. Current value: bagging_fraction=0.6795325217566865\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.93567\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.15159774380666147, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.15159774380666147\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7041682419265426, subsample=0.6007666267848173 will be ignored. Current value: bagging_fraction=0.7041682419265426\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.888041\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.2677621802751088, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.2677621802751088\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6946432496703296, subsample=0.3697390689515416 will be ignored. Current value: bagging_fraction=0.6946432496703296\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:58,248]\u001b[0m Trial 247 finished with value: 0.0 and parameters: {'n_estimators': 274, 'importance_type': 'split', 'num_leaves': 56, 'learning_rate': 0.8397848469325901, 'reg_lambda': 81.23914739355935, 'reg_alpha': 76.38859638752606, 'colsample_bytree': 0.5470222789412517, 'scale_pos_weight': 5.627604958771336, 'depth': 3, 'min_data_in_leaf': 37, 'subsample': 0.3697390689515416, 'bagging_fraction': 0.6946432496703296, 'min_sum_hessian_in_leaf': 0.2677621802751088}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:58,342]\u001b[0m Trial 248 finished with value: 0.569620253164557 and parameters: {'n_estimators': 223, 'importance_type': 'split', 'num_leaves': 89, 'learning_rate': 0.8141680102612148, 'reg_lambda': 48.6720763583193, 'reg_alpha': 86.74772156527455, 'colsample_bytree': 0.39136400808983374, 'scale_pos_weight': 9.645484062705986, 'depth': 3, 'min_data_in_leaf': 35, 'subsample': 0.3995795830399238, 'bagging_fraction': 0.6620230348788513, 'min_sum_hessian_in_leaf': 0.11595423301334273}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:58,435]\u001b[0m Trial 249 finished with value: 0.569620253164557 and parameters: {'n_estimators': 226, 'importance_type': 'split', 'num_leaves': 68, 'learning_rate': 0.8159540828908576, 'reg_lambda': 3.5034765510731187, 'reg_alpha': 86.64738377411985, 'colsample_bytree': 0.3475230226869824, 'scale_pos_weight': 9.822319122211523, 'depth': 3, 'min_data_in_leaf': 35, 'subsample': 0.3871525076713888, 'bagging_fraction': 0.6562854518040067, 'min_sum_hessian_in_leaf': 0.11062266577122874}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11595423301334273, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11595423301334273\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6620230348788513, subsample=0.3995795830399238 will be ignored. Current value: bagging_fraction=0.6620230348788513\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.20818\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.942541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11062266577122874, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11062266577122874\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6562854518040067, subsample=0.3871525076713888 will be ignored. Current value: bagging_fraction=0.6562854518040067\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.2248\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.959892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:58,537]\u001b[0m Trial 250 finished with value: 0.0 and parameters: {'n_estimators': 221, 'importance_type': 'split', 'num_leaves': 60, 'learning_rate': 0.8333265871544363, 'reg_lambda': 3.350632447631104, 'reg_alpha': 89.7639362613859, 'colsample_bytree': 0.3027680593008233, 'scale_pos_weight': 9.301664879983914, 'depth': 3, 'min_data_in_leaf': 36, 'subsample': 0.35821464122904006, 'bagging_fraction': 0.7385742267921688, 'min_sum_hessian_in_leaf': 0.5501864960823829}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:58,639]\u001b[0m Trial 251 finished with value: 0.569620253164557 and parameters: {'n_estimators': 175, 'importance_type': 'split', 'num_leaves': 80, 'learning_rate': 0.7625440261738574, 'reg_lambda': 5.071770581021795, 'reg_alpha': 83.64977165625116, 'colsample_bytree': 0.5680647701415891, 'scale_pos_weight': 9.45536227794243, 'depth': 4, 'min_data_in_leaf': 58, 'subsample': 0.4948933702584449, 'bagging_fraction': 0.7506048602508691, 'min_sum_hessian_in_leaf': 0.12430387944414388}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.5501864960823829, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.5501864960823829\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7385742267921688, subsample=0.35821464122904006 will be ignored. Current value: bagging_fraction=0.7385742267921688\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.12430387944414388, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.12430387944414388\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7506048602508691, subsample=0.4948933702584449 will be ignored. Current value: bagging_fraction=0.7506048602508691\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.918187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:58,754]\u001b[0m Trial 252 finished with value: 0.0 and parameters: {'n_estimators': 164, 'importance_type': 'split', 'num_leaves': 67, 'learning_rate': 0.7471084265353991, 'reg_lambda': 63.236641012060396, 'reg_alpha': 91.84248310951402, 'colsample_bytree': 0.5848441468899593, 'scale_pos_weight': 9.596984194965465, 'depth': 3, 'min_data_in_leaf': 180, 'subsample': 0.3608986683539643, 'bagging_fraction': 0.7458250749306461, 'min_sum_hessian_in_leaf': 0.11773632746576002}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:58,854]\u001b[0m Trial 253 finished with value: 0.569620253164557 and parameters: {'n_estimators': 242, 'importance_type': 'split', 'num_leaves': 61, 'learning_rate': 0.8281944143027764, 'reg_lambda': 60.10446351878391, 'reg_alpha': 88.61981037892362, 'colsample_bytree': 0.40111052195748126, 'scale_pos_weight': 10.090683441643206, 'depth': 3, 'min_data_in_leaf': 41, 'subsample': 0.3430075342892678, 'bagging_fraction': 0.5141300954219796, 'min_sum_hessian_in_leaf': 0.03935832566947123}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=180, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=180\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11773632746576002, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11773632746576002\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7458250749306461, subsample=0.3608986683539643 will be ignored. Current value: bagging_fraction=0.7458250749306461\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.03935832566947123, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.03935832566947123\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5141300954219796, subsample=0.3430075342892678 will be ignored. Current value: bagging_fraction=0.5141300954219796\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.22942\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.955929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:58,942]\u001b[0m Trial 254 finished with value: 0.569620253164557 and parameters: {'n_estimators': 92, 'importance_type': 'gain', 'num_leaves': 88, 'learning_rate': 0.8749322949100469, 'reg_lambda': 2.3291106615063626, 'reg_alpha': 87.39328887524587, 'colsample_bytree': 0.47691573831663914, 'scale_pos_weight': 7.589847027285312, 'depth': 2, 'min_data_in_leaf': 30, 'subsample': 0.5241011092973908, 'bagging_fraction': 0.6034881484283952, 'min_sum_hessian_in_leaf': 0.16046037409705158}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:59,021]\u001b[0m Trial 255 finished with value: 0.569620253164557 and parameters: {'n_estimators': 91, 'importance_type': 'split', 'num_leaves': 84, 'learning_rate': 0.8565458110487011, 'reg_lambda': 0.14112711824188873, 'reg_alpha': 81.70812900807476, 'colsample_bytree': 0.7081889838866678, 'scale_pos_weight': 7.607182984450624, 'depth': 2, 'min_data_in_leaf': 29, 'subsample': 0.5405136149361243, 'bagging_fraction': 0.6115213853381594, 'min_sum_hessian_in_leaf': 0.14588196201797574}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.16046037409705158, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.16046037409705158\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6034881484283952, subsample=0.5241011092973908 will be ignored. Current value: bagging_fraction=0.6034881484283952\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.953043\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.14588196201797574, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.14588196201797574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6115213853381594, subsample=0.5405136149361243 will be ignored. Current value: bagging_fraction=0.6115213853381594\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.943763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.18508422466979577, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.18508422466979577\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5904438255569195, subsample=0.5581888112354504 will be ignored. Current value: bagging_fraction=0.5904438255569195\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.912163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:59,111]\u001b[0m Trial 256 finished with value: 0.569620253164557 and parameters: {'n_estimators': 116, 'importance_type': 'split', 'num_leaves': 85, 'learning_rate': 0.890206961528318, 'reg_lambda': 81.47665331488092, 'reg_alpha': 85.98629076325322, 'colsample_bytree': 0.5028431589144117, 'scale_pos_weight': 6.813110829730193, 'depth': 2, 'min_data_in_leaf': 21, 'subsample': 0.5581888112354504, 'bagging_fraction': 0.5904438255569195, 'min_sum_hessian_in_leaf': 0.18508422466979577}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:59,210]\u001b[0m Trial 257 finished with value: 0.569620253164557 and parameters: {'n_estimators': 104, 'importance_type': 'split', 'num_leaves': 81, 'learning_rate': 0.9355997556926648, 'reg_lambda': 88.0289027848888, 'reg_alpha': 78.17183936745157, 'colsample_bytree': 0.6555182938335647, 'scale_pos_weight': 7.276375716896763, 'depth': 2, 'min_data_in_leaf': 26, 'subsample': 0.5130641554415288, 'bagging_fraction': 0.5320744337500257, 'min_sum_hessian_in_leaf': 0.19524093171268314}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:59,298]\u001b[0m Trial 258 finished with value: 0.569620253164557 and parameters: {'n_estimators': 124, 'importance_type': 'split', 'num_leaves': 77, 'learning_rate': 0.9148135030850968, 'reg_lambda': 71.13353769232972, 'reg_alpha': 79.75493364068481, 'colsample_bytree': 0.517421574808099, 'scale_pos_weight': 7.983608932681463, 'depth': 2, 'min_data_in_leaf': 20, 'subsample': 0.5132974198350604, 'bagging_fraction': 0.5290766850929142, 'min_sum_hessian_in_leaf': 0.16613477395287837}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.19524093171268314, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.19524093171268314\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5320744337500257, subsample=0.5130641554415288 will be ignored. Current value: bagging_fraction=0.5320744337500257\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.952066\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.16613477395287837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.16613477395287837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5290766850929142, subsample=0.5132974198350604 will be ignored. Current value: bagging_fraction=0.5290766850929142\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.965913\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.14217701322089588, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.14217701322089588\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5510949019231965, subsample=0.5414380074197763 will be ignored. Current value: bagging_fraction=0.5510949019231965\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.05272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:59,393]\u001b[0m Trial 259 finished with value: 0.569620253164557 and parameters: {'n_estimators': 91, 'importance_type': 'split', 'num_leaves': 83, 'learning_rate': 0.8836969455629896, 'reg_lambda': 2.3193537987086317, 'reg_alpha': 73.71186820479144, 'colsample_bytree': 0.4536238169780391, 'scale_pos_weight': 12.494167783456321, 'depth': 3, 'min_data_in_leaf': 25, 'subsample': 0.5414380074197763, 'bagging_fraction': 0.5510949019231965, 'min_sum_hessian_in_leaf': 0.14217701322089588}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:59,479]\u001b[0m Trial 260 finished with value: 0.569620253164557 and parameters: {'n_estimators': 104, 'importance_type': 'split', 'num_leaves': 82, 'learning_rate': 0.9795803386398887, 'reg_lambda': 78.06246728237538, 'reg_alpha': 70.82107073248446, 'colsample_bytree': 0.4776201741915433, 'scale_pos_weight': 13.549689258210584, 'depth': 2, 'min_data_in_leaf': 31, 'subsample': 0.587071411913382, 'bagging_fraction': 0.5760199390640964, 'min_sum_hessian_in_leaf': 0.132906361771264}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:59,577]\u001b[0m Trial 261 finished with value: 0.569620253164557 and parameters: {'n_estimators': 161, 'importance_type': 'split', 'num_leaves': 79, 'learning_rate': 0.8538194612281992, 'reg_lambda': 97.21845834641225, 'reg_alpha': 81.4628051959474, 'colsample_bytree': 0.568229690641442, 'scale_pos_weight': 13.349707345232291, 'depth': 2, 'min_data_in_leaf': 38, 'subsample': 0.3718890760439105, 'bagging_fraction': 0.548579109858704, 'min_sum_hessian_in_leaf': 0.09951156657088095}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.132906361771264, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.132906361771264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5760199390640964, subsample=0.587071411913382 will be ignored. Current value: bagging_fraction=0.5760199390640964\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.1249\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09951156657088095, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09951156657088095\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.548579109858704, subsample=0.3718890760439105 will be ignored. Current value: bagging_fraction=0.548579109858704\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.01111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:59,707]\u001b[0m Trial 262 finished with value: 0.569620253164557 and parameters: {'n_estimators': 156, 'importance_type': 'split', 'num_leaves': 77, 'learning_rate': 0.8516625453981382, 'reg_lambda': 98.60000668223414, 'reg_alpha': 80.58646535528776, 'colsample_bytree': 0.584306703568932, 'scale_pos_weight': 13.554226814176037, 'depth': 2, 'min_data_in_leaf': 35, 'subsample': 0.5359918561446353, 'bagging_fraction': 0.5419089827195757, 'min_sum_hessian_in_leaf': 0.109115703043244}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:59,804]\u001b[0m Trial 263 finished with value: 0.569620253164557 and parameters: {'n_estimators': 112, 'importance_type': 'split', 'num_leaves': 85, 'learning_rate': 0.9562591715829325, 'reg_lambda': 74.59868975313618, 'reg_alpha': 84.96317885802856, 'colsample_bytree': 0.4587925668156725, 'scale_pos_weight': 12.16829135551869, 'depth': 4, 'min_data_in_leaf': 32, 'subsample': 0.501402613483358, 'bagging_fraction': 0.5590890008292893, 'min_sum_hessian_in_leaf': 0.1618607153562488}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.109115703043244, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.109115703043244\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419089827195757, subsample=0.5359918561446353 will be ignored. Current value: bagging_fraction=0.5419089827195757\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.01157\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.1618607153562488, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.1618607153562488\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5590890008292893, subsample=0.501402613483358 will be ignored. Current value: bagging_fraction=0.5590890008292893\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.08276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:05:59,911]\u001b[0m Trial 264 finished with value: 0.569620253164557 and parameters: {'n_estimators': 129, 'importance_type': 'split', 'num_leaves': 87, 'learning_rate': 0.43701002089712837, 'reg_lambda': 70.89683287601255, 'reg_alpha': 85.91993210688719, 'colsample_bytree': 0.4474558662596162, 'scale_pos_weight': 12.081215852551331, 'depth': 4, 'min_data_in_leaf': 25, 'subsample': 0.5722279434941574, 'bagging_fraction': 0.4869869720485538, 'min_sum_hessian_in_leaf': 0.13450340045115616}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:05:59,995]\u001b[0m Trial 265 finished with value: 0.569620253164557 and parameters: {'n_estimators': 125, 'importance_type': 'split', 'num_leaves': 83, 'learning_rate': 0.9201145806245565, 'reg_lambda': 86.06049479343149, 'reg_alpha': 82.56194992230068, 'colsample_bytree': 0.48304542083756247, 'scale_pos_weight': 12.61191835942762, 'depth': 4, 'min_data_in_leaf': 32, 'subsample': 0.584294769814881, 'bagging_fraction': 0.5172847021340323, 'min_sum_hessian_in_leaf': 0.13430884090462963}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.13450340045115616, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.13450340045115616\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4869869720485538, subsample=0.5722279434941574 will be ignored. Current value: bagging_fraction=0.4869869720485538\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.755696\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.13430884090462963, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.13430884090462963\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5172847021340323, subsample=0.584294769814881 will be ignored. Current value: bagging_fraction=0.5172847021340323\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 1.05687\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10131016979346111, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10131016979346111\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5658738344475186, subsample=0.6971242084910536 will be ignored. Current value: bagging_fraction=0.5658738344475186\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:00,094]\u001b[0m Trial 266 finished with value: 0.569620253164557 and parameters: {'n_estimators': 136, 'importance_type': 'gain', 'num_leaves': 76, 'learning_rate': 0.7525936185816212, 'reg_lambda': 80.62252982638773, 'reg_alpha': 83.42536447546199, 'colsample_bytree': 0.4660963322925187, 'scale_pos_weight': 11.88489174509906, 'depth': 4, 'min_data_in_leaf': 26, 'subsample': 0.6971242084910536, 'bagging_fraction': 0.5658738344475186, 'min_sum_hessian_in_leaf': 0.10131016979346111}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:00,182]\u001b[0m Trial 267 finished with value: 0.569620253164557 and parameters: {'n_estimators': 105, 'importance_type': 'split', 'num_leaves': 90, 'learning_rate': 0.41027521699648384, 'reg_lambda': 61.5736689581873, 'reg_alpha': 87.27505587440926, 'colsample_bytree': 0.44921157428518566, 'scale_pos_weight': 14.47593956336988, 'depth': 4, 'min_data_in_leaf': 20, 'subsample': 0.5093458600078556, 'bagging_fraction': 0.5842064471224625, 'min_sum_hessian_in_leaf': 0.09635356840034046}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:00,278]\u001b[0m Trial 268 finished with value: 0.569620253164557 and parameters: {'n_estimators': 139, 'importance_type': 'split', 'num_leaves': 86, 'learning_rate': 0.43139543303974026, 'reg_lambda': 71.48957545648335, 'reg_alpha': 85.41200055150017, 'colsample_bytree': 0.4898605502056717, 'scale_pos_weight': 12.533901302324482, 'depth': 7, 'min_data_in_leaf': 25, 'subsample': 0.6750115974591642, 'bagging_fraction': 0.5782884398498649, 'min_sum_hessian_in_leaf': 0.11493332526121704}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.924742\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09635356840034046, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09635356840034046\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5842064471224625, subsample=0.5093458600078556 will be ignored. Current value: bagging_fraction=0.5842064471224625\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.752579\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11493332526121704, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11493332526121704\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5782884398498649, subsample=0.6750115974591642 will be ignored. Current value: bagging_fraction=0.5782884398498649\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.755005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:00,375]\u001b[0m Trial 269 finished with value: 0.569620253164557 and parameters: {'n_estimators': 117, 'importance_type': 'split', 'num_leaves': 75, 'learning_rate': 0.4695385191810947, 'reg_lambda': 65.10492943481245, 'reg_alpha': 80.9380510701821, 'colsample_bytree': 0.46848402716890253, 'scale_pos_weight': 12.880602251007504, 'depth': 4, 'min_data_in_leaf': 28, 'subsample': 0.5585340309002857, 'bagging_fraction': 0.6923300808666506, 'min_sum_hessian_in_leaf': 0.10114817112048248}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:00,465]\u001b[0m Trial 270 finished with value: 0.0 and parameters: {'n_estimators': 127, 'importance_type': 'split', 'num_leaves': 73, 'learning_rate': 0.9159482236766577, 'reg_lambda': 12.356006903867653, 'reg_alpha': 78.63370106357345, 'colsample_bytree': 0.4420041664554928, 'scale_pos_weight': 4.992668259911376, 'depth': 4, 'min_data_in_leaf': 33, 'subsample': 0.5990399987509741, 'bagging_fraction': 0.7131009048838973, 'min_sum_hessian_in_leaf': 0.14922441176582493}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10114817112048248, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10114817112048248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6923300808666506, subsample=0.5585340309002857 will be ignored. Current value: bagging_fraction=0.6923300808666506\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.773377\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.14922441176582493, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.14922441176582493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7131009048838973, subsample=0.5990399987509741 will be ignored. Current value: bagging_fraction=0.7131009048838973\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0937232915524489, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0937232915524489\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5994084255376609, subsample=0.47646947914489757 will be ignored. Current value: bagging_fraction=0.5994084255376609\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:00,570]\u001b[0m Trial 271 finished with value: 0.569620253164557 and parameters: {'n_estimators': 144, 'importance_type': 'split', 'num_leaves': 71, 'learning_rate': 0.38500766369063816, 'reg_lambda': 15.219103812059975, 'reg_alpha': 89.51047217423084, 'colsample_bytree': 0.6152318390528912, 'scale_pos_weight': 8.926559215134588, 'depth': 4, 'min_data_in_leaf': 42, 'subsample': 0.47646947914489757, 'bagging_fraction': 0.5994084255376609, 'min_sum_hessian_in_leaf': 0.0937232915524489}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:00,660]\u001b[0m Trial 272 finished with value: 0.569620253164557 and parameters: {'n_estimators': 135, 'importance_type': 'split', 'num_leaves': 72, 'learning_rate': 0.35654776632842, 'reg_lambda': 12.338858038356147, 'reg_alpha': 36.06379173295249, 'colsample_bytree': 0.4128752402552896, 'scale_pos_weight': 13.10716660634257, 'depth': 4, 'min_data_in_leaf': 20, 'subsample': 0.5193210815725219, 'bagging_fraction': 0.5007270355227209, 'min_sum_hessian_in_leaf': 0.11223513183782252}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:00,750]\u001b[0m Trial 273 finished with value: 0.569620253164557 and parameters: {'n_estimators': 146, 'importance_type': 'split', 'num_leaves': 74, 'learning_rate': 0.6060184859921992, 'reg_lambda': 10.025485254309608, 'reg_alpha': 31.444806997093757, 'colsample_bytree': 0.4248157678208675, 'scale_pos_weight': 11.773548566698434, 'depth': 4, 'min_data_in_leaf': 38, 'subsample': 0.46121272411723946, 'bagging_fraction': 0.6142134520379406, 'min_sum_hessian_in_leaf': 0.08923400038359308}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.72833\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11223513183782252, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11223513183782252\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5007270355227209, subsample=0.5193210815725219 will be ignored. Current value: bagging_fraction=0.5007270355227209\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.732775\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.08923400038359308, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.08923400038359308\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6142134520379406, subsample=0.46121272411723946 will be ignored. Current value: bagging_fraction=0.6142134520379406\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.848897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:00,854]\u001b[0m Trial 274 finished with value: 0.569620253164557 and parameters: {'n_estimators': 90, 'importance_type': 'split', 'num_leaves': 75, 'learning_rate': 0.6349104828707673, 'reg_lambda': 13.846410131703141, 'reg_alpha': 33.05296723716559, 'colsample_bytree': 0.5583758379260718, 'scale_pos_weight': 11.835568035050514, 'depth': 4, 'min_data_in_leaf': 39, 'subsample': 0.4663782001653375, 'bagging_fraction': 0.6334279076170694, 'min_sum_hessian_in_leaf': 0.08964219499763114}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:00,948]\u001b[0m Trial 275 finished with value: 0.569620253164557 and parameters: {'n_estimators': 119, 'importance_type': 'split', 'num_leaves': 79, 'learning_rate': 0.6727932348773993, 'reg_lambda': 12.27852475044321, 'reg_alpha': 42.3553193307339, 'colsample_bytree': 0.538882346574183, 'scale_pos_weight': 13.025852417781357, 'depth': 4, 'min_data_in_leaf': 31, 'subsample': 0.10565910607504139, 'bagging_fraction': 0.4615323210834799, 'min_sum_hessian_in_leaf': 0.22270625158507878}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.08964219499763114, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.08964219499763114\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6334279076170694, subsample=0.4663782001653375 will be ignored. Current value: bagging_fraction=0.6334279076170694\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.866171\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.22270625158507878, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.22270625158507878\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4615323210834799, subsample=0.10565910607504139 will be ignored. Current value: bagging_fraction=0.4615323210834799\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.89904\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.12862864102509416, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.12862864102509416\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5112278176110745, subsample=0.5284037517005274 will be ignored. Current value: bagging_fraction=0.5112278176110745\n",
            "Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:01,047]\u001b[0m Trial 276 finished with value: 0.569620253164557 and parameters: {'n_estimators': 102, 'importance_type': 'split', 'num_leaves': 88, 'learning_rate': 0.6020044735405593, 'reg_lambda': 14.045874269408092, 'reg_alpha': 87.83967374583679, 'colsample_bytree': 0.519455789725631, 'scale_pos_weight': 14.751674404260982, 'depth': 4, 'min_data_in_leaf': 31, 'subsample': 0.5284037517005274, 'bagging_fraction': 0.5112278176110745, 'min_sum_hessian_in_leaf': 0.12862864102509416}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:01,133]\u001b[0m Trial 277 finished with value: 0.0 and parameters: {'n_estimators': 145, 'importance_type': 'split', 'num_leaves': 83, 'learning_rate': 0.6351859884736881, 'reg_lambda': 10.61000108723282, 'reg_alpha': 27.25489473917109, 'colsample_bytree': 0.4869883153795971, 'scale_pos_weight': 12.393122644741059, 'depth': 4, 'min_data_in_leaf': 126, 'subsample': 0.10760520394350395, 'bagging_fraction': 0.5354668840694229, 'min_sum_hessian_in_leaf': 0.11117719155279086}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:01,235]\u001b[0m Trial 278 finished with value: 0.0 and parameters: {'n_estimators': 200, 'importance_type': 'split', 'num_leaves': 69, 'learning_rate': 0.6098419010265766, 'reg_lambda': 15.43432846696514, 'reg_alpha': 34.16027560536532, 'colsample_bytree': 0.4057662767000743, 'scale_pos_weight': 6.045110408676012, 'depth': 4, 'min_data_in_leaf': 45, 'subsample': 0.13090174491141265, 'bagging_fraction': 0.5931192488105176, 'min_sum_hessian_in_leaf': 0.0745984336660864}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.859059\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=126, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=126\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.11117719155279086, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.11117719155279086\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5354668840694229, subsample=0.10760520394350395 will be ignored. Current value: bagging_fraction=0.5354668840694229\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0745984336660864, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0745984336660864\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5931192488105176, subsample=0.13090174491141265 will be ignored. Current value: bagging_fraction=0.5931192488105176\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:01,343]\u001b[0m Trial 279 finished with value: 0.0 and parameters: {'n_estimators': 192, 'importance_type': 'split', 'num_leaves': 100, 'learning_rate': 0.5771348246451724, 'reg_lambda': 10.811382816386253, 'reg_alpha': 28.576010336890935, 'colsample_bytree': 0.4273067751618052, 'scale_pos_weight': 6.7110751361916074, 'depth': 5, 'min_data_in_leaf': 45, 'subsample': 0.136028450062603, 'bagging_fraction': 0.6354177030720968, 'min_sum_hessian_in_leaf': 0.0471105495485583}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:01,442]\u001b[0m Trial 280 finished with value: 0.0 and parameters: {'n_estimators': 196, 'importance_type': 'split', 'num_leaves': 78, 'learning_rate': 0.6834072079276238, 'reg_lambda': 14.748462385684556, 'reg_alpha': 21.008785417588395, 'colsample_bytree': 0.4041071934220515, 'scale_pos_weight': 13.970851043075472, 'depth': 5, 'min_data_in_leaf': 207, 'subsample': 0.4854681355951678, 'bagging_fraction': 0.6175421096225981, 'min_sum_hessian_in_leaf': 0.07736757872252559}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0471105495485583, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0471105495485583\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6354177030720968, subsample=0.136028450062603 will be ignored. Current value: bagging_fraction=0.6354177030720968\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=207, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=207\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.07736757872252559, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.07736757872252559\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6175421096225981, subsample=0.4854681355951678 will be ignored. Current value: bagging_fraction=0.6175421096225981\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04556929291776058, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04556929291776058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7188708748347121, subsample=0.49793556806111333 will be ignored. Current value: bagging_fraction=0.7188708748347121\n",
            "Training until validation scores don't improve for 200 rounds"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:01,554]\u001b[0m Trial 281 finished with value: 0.569620253164557 and parameters: {'n_estimators': 233, 'importance_type': 'gain', 'num_leaves': 98, 'learning_rate': 0.581751920806505, 'reg_lambda': 10.597601361209598, 'reg_alpha': 39.98922019838608, 'colsample_bytree': 0.4008739589973402, 'scale_pos_weight': 10.24080835599427, 'depth': 5, 'min_data_in_leaf': 48, 'subsample': 0.49793556806111333, 'bagging_fraction': 0.7188708748347121, 'min_sum_hessian_in_leaf': 0.04556929291776058}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:01,657]\u001b[0m Trial 282 finished with value: 0.569620253164557 and parameters: {'n_estimators': 101, 'importance_type': 'split', 'num_leaves': 47, 'learning_rate': 0.6525252832229564, 'reg_lambda': 56.503653151716996, 'reg_alpha': 25.01278579031563, 'colsample_bytree': 0.38795054412760643, 'scale_pos_weight': 12.356167454089471, 'depth': 5, 'min_data_in_leaf': 37, 'subsample': 0.13684529733553638, 'bagging_fraction': 0.55574320331855, 'min_sum_hessian_in_leaf': 0.10873010214201523}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[200]\tvalid_0's binary_logloss: 1.20225\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.823124\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.10873010214201523, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.10873010214201523\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.55574320331855, subsample=0.13684529733553638 will be ignored. Current value: bagging_fraction=0.55574320331855\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.874326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:01,760]\u001b[0m Trial 283 finished with value: 0.569620253164557 and parameters: {'n_estimators': 113, 'importance_type': 'split', 'num_leaves': 72, 'learning_rate': 0.6029624133249459, 'reg_lambda': 13.484689665945112, 'reg_alpha': 40.08704137523704, 'colsample_bytree': 0.4182639187107623, 'scale_pos_weight': 12.714090631608437, 'depth': 6, 'min_data_in_leaf': 33, 'subsample': 0.12530337345471396, 'bagging_fraction': 0.6763305233580448, 'min_sum_hessian_in_leaf': 0.13082653355507617}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:01,861]\u001b[0m Trial 284 finished with value: 0.569620253164557 and parameters: {'n_estimators': 133, 'importance_type': 'split', 'num_leaves': 74, 'learning_rate': 0.6341622378233446, 'reg_lambda': 12.870404835735881, 'reg_alpha': 31.67269207520422, 'colsample_bytree': 0.3914468631201787, 'scale_pos_weight': 12.119340758648285, 'depth': 5, 'min_data_in_leaf': 27, 'subsample': 0.16132641578901988, 'bagging_fraction': 0.525772904475353, 'min_sum_hessian_in_leaf': 0.09926644703398405}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.13082653355507617, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.13082653355507617\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6763305233580448, subsample=0.12530337345471396 will be ignored. Current value: bagging_fraction=0.6763305233580448\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.851914\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09926644703398405, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09926644703398405\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.525772904475353, subsample=0.16132641578901988 will be ignored. Current value: bagging_fraction=0.525772904475353\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.868069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:01,971]\u001b[0m Trial 285 finished with value: 0.0 and parameters: {'n_estimators': 171, 'importance_type': 'gain', 'num_leaves': 71, 'learning_rate': 0.6019891640539917, 'reg_lambda': 12.76501564325247, 'reg_alpha': 29.914590402307688, 'colsample_bytree': 0.4954249879622527, 'scale_pos_weight': 13.265149528203658, 'depth': 5, 'min_data_in_leaf': 36, 'subsample': 0.14388948799727327, 'bagging_fraction': 0.6648373089803061, 'min_sum_hessian_in_leaf': 0.632669554598027}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:02,078]\u001b[0m Trial 286 finished with value: 0.569620253164557 and parameters: {'n_estimators': 233, 'importance_type': 'split', 'num_leaves': 38, 'learning_rate': 0.49992807981376175, 'reg_lambda': 9.854756010097912, 'reg_alpha': 22.215641020067604, 'colsample_bytree': 0.4215158055091002, 'scale_pos_weight': 10.427701516520923, 'depth': 4, 'min_data_in_leaf': 55, 'subsample': 0.18590698002298242, 'bagging_fraction': 0.7211347032815856, 'min_sum_hessian_in_leaf': 0.03946242650898541}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.632669554598027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.632669554598027\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6648373089803061, subsample=0.14388948799727327 will be ignored. Current value: bagging_fraction=0.6648373089803061\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.03946242650898541, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.03946242650898541\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7211347032815856, subsample=0.18590698002298242 will be ignored. Current value: bagging_fraction=0.7211347032815856\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.15428\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.784491\n",
            "[LightGBM] [Warning] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:02,191]\u001b[0m Trial 287 finished with value: 0.0 and parameters: {'n_estimators': 160, 'importance_type': 'split', 'num_leaves': 85, 'learning_rate': 0.5855655606479747, 'reg_lambda': 16.42029332465259, 'reg_alpha': 22.585038660184605, 'colsample_bytree': 0.4124185600624197, 'scale_pos_weight': 16.580623592601004, 'depth': 4, 'min_data_in_leaf': 46, 'subsample': 0.21478737897944802, 'bagging_fraction': 0.5680404308462927, 'min_sum_hessian_in_leaf': 0.37212662393619367}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:02,301]\u001b[0m Trial 288 finished with value: 0.569620253164557 and parameters: {'n_estimators': 246, 'importance_type': 'split', 'num_leaves': 32, 'learning_rate': 0.5148577403489656, 'reg_lambda': 26.67133982012108, 'reg_alpha': 49.259249281469316, 'colsample_bytree': 0.43476960592669817, 'scale_pos_weight': 11.388734086918092, 'depth': 3, 'min_data_in_leaf': 66, 'subsample': 0.3132116180896008, 'bagging_fraction': 0.7030508658254105, 'min_sum_hessian_in_leaf': 0.04486602067197442}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.37212662393619367, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.37212662393619367\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5680404308462927, subsample=0.21478737897944802 will be ignored. Current value: bagging_fraction=0.5680404308462927\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.04486602067197442, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.04486602067197442\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7030508658254105, subsample=0.3132116180896008 will be ignored. Current value: bagging_fraction=0.7030508658254105\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.26202\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.793406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:02,417]\u001b[0m Trial 289 finished with value: 0.0 and parameters: {'n_estimators': 183, 'importance_type': 'split', 'num_leaves': 87, 'learning_rate': 0.6615181620423652, 'reg_lambda': 16.024054727084586, 'reg_alpha': 31.740627785441045, 'colsample_bytree': 0.38772420653201234, 'scale_pos_weight': 12.227695043421667, 'depth': 5, 'min_data_in_leaf': 50, 'subsample': 0.5375881425633765, 'bagging_fraction': 0.6467252371166368, 'min_sum_hessian_in_leaf': 0.13671485398576003}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:02,518]\u001b[0m Trial 290 finished with value: 0.0 and parameters: {'n_estimators': 215, 'importance_type': 'split', 'num_leaves': 77, 'learning_rate': 0.5346258745264586, 'reg_lambda': 28.85042818270007, 'reg_alpha': 56.83887933263266, 'colsample_bytree': 0.2598440039751093, 'scale_pos_weight': 11.088244625609347, 'depth': 1, 'min_data_in_leaf': 58, 'subsample': 0.17595912564491778, 'bagging_fraction': 0.8807335103463282, 'min_sum_hessian_in_leaf': 0.0356411641597858}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.13671485398576003, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.13671485398576003\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6467252371166368, subsample=0.5375881425633765 will be ignored. Current value: bagging_fraction=0.6467252371166368\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0356411641597858, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0356411641597858\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8807335103463282, subsample=0.17595912564491778 will be ignored. Current value: bagging_fraction=0.8807335103463282\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.28033\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:02,628]\u001b[0m Trial 291 finished with value: 0.0 and parameters: {'n_estimators': 210, 'importance_type': 'split', 'num_leaves': 79, 'learning_rate': 0.5573753718679634, 'reg_lambda': 17.36815410273674, 'reg_alpha': 58.21782997354022, 'colsample_bytree': 0.4331960630994109, 'scale_pos_weight': 11.194018051886625, 'depth': 1, 'min_data_in_leaf': 189, 'subsample': 0.3017236806693741, 'bagging_fraction': 0.7151262589628186, 'min_sum_hessian_in_leaf': 0.05941714024070052}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:02,730]\u001b[0m Trial 292 finished with value: 0.0 and parameters: {'n_estimators': 226, 'importance_type': 'split', 'num_leaves': 44, 'learning_rate': 0.5077136801447358, 'reg_lambda': 22.90038979902528, 'reg_alpha': 54.76702673470565, 'colsample_bytree': 0.23501974039040685, 'scale_pos_weight': 10.889920026373156, 'depth': 1, 'min_data_in_leaf': 52, 'subsample': 0.26115269447262174, 'bagging_fraction': 0.8643038889866873, 'min_sum_hessian_in_leaf': 0.053181610999811696}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=189, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=189\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.05941714024070052, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.05941714024070052\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7151262589628186, subsample=0.3017236806693741 will be ignored. Current value: bagging_fraction=0.7151262589628186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=52, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=52\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.053181610999811696, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.053181610999811696\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8643038889866873, subsample=0.26115269447262174 will be ignored. Current value: bagging_fraction=0.8643038889866873\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.27632\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:02,849]\u001b[0m Trial 293 finished with value: 0.569620253164557 and parameters: {'n_estimators': 254, 'importance_type': 'split', 'num_leaves': 41, 'learning_rate': 0.5495685005974117, 'reg_lambda': 23.016057382614008, 'reg_alpha': 36.91317896720594, 'colsample_bytree': 0.30330665309833366, 'scale_pos_weight': 11.145047771938678, 'depth': 1, 'min_data_in_leaf': 63, 'subsample': 0.2847480068115318, 'bagging_fraction': 0.9017329155209941, 'min_sum_hessian_in_leaf': 0.06050063086617453}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:02,945]\u001b[0m Trial 294 finished with value: 0.569620253164557 and parameters: {'n_estimators': 258, 'importance_type': 'split', 'num_leaves': 41, 'learning_rate': 0.554175307261568, 'reg_lambda': 22.10342804032829, 'reg_alpha': 47.27313017222529, 'colsample_bytree': 0.2859036829221137, 'scale_pos_weight': 10.071598243473249, 'depth': 1, 'min_data_in_leaf': 61, 'subsample': 0.2794671657570017, 'bagging_fraction': 0.919830724316599, 'min_sum_hessian_in_leaf': 0.030216608967302924}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.06050063086617453, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.06050063086617453\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9017329155209941, subsample=0.2847480068115318 will be ignored. Current value: bagging_fraction=0.9017329155209941\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.28013\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.810828\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.030216608967302924, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.030216608967302924\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.919830724316599, subsample=0.2794671657570017 will be ignored. Current value: bagging_fraction=0.919830724316599\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.24215\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.805287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:03,049]\u001b[0m Trial 295 finished with value: 0.0 and parameters: {'n_estimators': 278, 'importance_type': 'split', 'num_leaves': 48, 'learning_rate': 0.5854296211106657, 'reg_lambda': 8.007579461281399, 'reg_alpha': 18.025500726051334, 'colsample_bytree': 0.38342692497677244, 'scale_pos_weight': 15.626760531733154, 'depth': 5, 'min_data_in_leaf': 292, 'subsample': 0.14972165468823573, 'bagging_fraction': 0.4720404242060455, 'min_sum_hessian_in_leaf': 0.09159108004930447}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:03,159]\u001b[0m Trial 296 finished with value: 0.569620253164557 and parameters: {'n_estimators': 261, 'importance_type': 'split', 'num_leaves': 44, 'learning_rate': 0.4663259473024004, 'reg_lambda': 23.92623160528887, 'reg_alpha': 51.579776170289755, 'colsample_bytree': 0.290170298445914, 'scale_pos_weight': 10.598351287525658, 'depth': 1, 'min_data_in_leaf': 55, 'subsample': 0.31484528563639036, 'bagging_fraction': 0.7374918898308622, 'min_sum_hessian_in_leaf': 0.015863534539331724}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=292, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=292\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.09159108004930447, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.09159108004930447\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4720404242060455, subsample=0.14972165468823573 will be ignored. Current value: bagging_fraction=0.4720404242060455\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 0.702674\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.702674\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.015863534539331724, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.015863534539331724\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7374918898308622, subsample=0.31484528563639036 will be ignored. Current value: bagging_fraction=0.7374918898308622\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.26522\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.767164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:03,274]\u001b[0m Trial 297 finished with value: 0.569620253164557 and parameters: {'n_estimators': 243, 'importance_type': 'split', 'num_leaves': 58, 'learning_rate': 0.4787651443868317, 'reg_lambda': 20.05651014565372, 'reg_alpha': 51.431631785985054, 'colsample_bytree': 0.28348632367850146, 'scale_pos_weight': 10.735662497674802, 'depth': 1, 'min_data_in_leaf': 56, 'subsample': 0.3212386505585786, 'bagging_fraction': 0.734790622341816, 'min_sum_hessian_in_leaf': 0.0017314032025078606}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n",
            "\u001b[32m[I 2021-09-22 19:06:03,385]\u001b[0m Trial 298 finished with value: 0.569620253164557 and parameters: {'n_estimators': 271, 'importance_type': 'split', 'num_leaves': 54, 'learning_rate': 0.5264194013622541, 'reg_lambda': 20.0161934982498, 'reg_alpha': 51.051841395035154, 'colsample_bytree': 0.32584586357699624, 'scale_pos_weight': 10.789525336230222, 'depth': 1, 'min_data_in_leaf': 57, 'subsample': 0.3164268712394581, 'bagging_fraction': 0.7221074966169765, 'min_sum_hessian_in_leaf': 0.019210537880167834}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017314032025078606, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017314032025078606\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.734790622341816, subsample=0.3212386505585786 will be ignored. Current value: bagging_fraction=0.734790622341816\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.27291\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.773693\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.019210537880167834, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.019210537880167834\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7221074966169765, subsample=0.3164268712394581 will be ignored. Current value: bagging_fraction=0.7221074966169765\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.27261\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.79637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-22 19:06:03,504]\u001b[0m Trial 299 finished with value: 0.569620253164557 and parameters: {'n_estimators': 252, 'importance_type': 'split', 'num_leaves': 36, 'learning_rate': 0.6309004964103724, 'reg_lambda': 11.240585885144107, 'reg_alpha': 25.32833594818119, 'colsample_bytree': 0.40768438905641874, 'scale_pos_weight': 11.537013691459789, 'depth': 5, 'min_data_in_leaf': 44, 'subsample': 0.12013962111261825, 'bagging_fraction': 0.5450391213851564, 'min_sum_hessian_in_leaf': 0.08056808655353781}. Best is trial 14 with value: 0.569620253164557.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.08056808655353781, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.08056808655353781\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5450391213851564, subsample=0.12013962111261825 will be ignored. Current value: bagging_fraction=0.5450391213851564\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's binary_logloss: 1.21664\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's binary_logloss: 0.862565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo4IXBeRzKK3",
        "outputId": "c5f612cf-bd96-4406-8648-1e8b86eab125"
      },
      "source": [
        "# print(f\"Best Trial: {study.best_trial.value}\")\n",
        "# print(f\"Best Params: {study.best_trial.params}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: 0.569620253164557\n",
            "Best Params: {'n_estimators': 548, 'importance_type': 'split', 'num_leaves': 71, 'learning_rate': 0.5451820431683637, 'reg_lambda': 0.18982147693285611, 'reg_alpha': 65.58618060010909, 'colsample_bytree': 0.5718965752147983, 'scale_pos_weight': 9.722381028559631, 'depth': 9, 'min_data_in_leaf': 66, 'subsample': 0.8780495139659923, 'bagging_fraction': 0.37946033709168714, 'min_sum_hessian_in_leaf': 0.11449230117536044}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUDcKMQk0_uu"
      },
      "source": [
        "# H_params = study.best_trial.params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxJWDDLO1dUq"
      },
      "source": [
        "# H_params = {'n_estimators': 586, 'objective': 'binary', 'importance_type': 'gain', 'num_leaves': 82, 'learning_rate': 0.41490608340120194, 'reg_lambda': 5.708408942536359, 'reg_alpha': 5.517693129732991, 'colsample_bytree': 0.84460849025194, 'scale_pos_weight': 3.6213684221040014, 'max_depth': 14, 'min_data_in_leaf': 56, 'subsample': 0.28937062760787574, 'bagging_fraction': 0.3376651043328511, 'min_sum_hessian_in_leaf': 0.9208910356602873}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvvvahey0MNJ",
        "outputId": "d449285f-b32c-4e0a-c646-a2e5a7724c7a"
      },
      "source": [
        "# #Here the cross validation by using the StratifiedKfold used to split the data into train,test and validation and repeatedly and Using the LGBMClassifier as Algorithm for building the model \n",
        "# skf =StratifiedKFold(n_splits=10, shuffle=True,random_state=2021) # for cross validation by StratifiedKfold\n",
        "# scores = [] #list to store the sores obtained in training the model \n",
        "# preds= [] #list to store the predictions \n",
        "\n",
        "# X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "# y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "# test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "# test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "# #creating a for loop for the stratified k fold to perform the cross validation \n",
        "# i = 1\n",
        "# for train, test in skf.split(X, y):\n",
        "#     x_train, x_test= X.iloc[train], X.iloc[test] #spliting the data for x \n",
        "#     y_train, y_test = y.iloc[train],y.iloc[test] #spliting the data for y \n",
        "#     model = lgb.LGBMClassifier(**H_params) #Creating the model and tuning it with the different parameter \n",
        "#     model.fit(x_train, y_train)# fitting  the model on train data\n",
        "#     print(i,'Split Trained') #print the splits that trained \n",
        "#     score = f1_score(y_test,model.predict(x_test)) # checking the accuracy of the model \n",
        "#     pred = model.predict_proba(test_new)[:,1] # making prediction\n",
        "#     scores.append(score)\n",
        "#     preds.append(pred)\n",
        "#     i += 1\n",
        "# print('Total Mean Score Obtained :',np.mean(scores))\n",
        "\n",
        "# preds_mean = np.mean(preds, axis=0)# mean of all the predictions\n",
        "# final = [] #list to store the final results \n",
        "# for x in preds_mean:\n",
        "#     if x >= 0.51:\n",
        "#         final.append(1)\n",
        "#     else:\n",
        "#         final.append(0)\n",
        "\n",
        "# submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "# submit['Potability'] = final\n",
        "# submit[['region_area_','Potability']].to_csv('001xviibaseline.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.3376651043328511, subsample=0.28937062760787574 will be ignored. Current value: bagging_fraction=0.3376651043328511\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9208910356602873, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9208910356602873\n",
            "1 Split Trained\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3376651043328511, subsample=0.28937062760787574 will be ignored. Current value: bagging_fraction=0.3376651043328511\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9208910356602873, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9208910356602873\n",
            "2 Split Trained\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3376651043328511, subsample=0.28937062760787574 will be ignored. Current value: bagging_fraction=0.3376651043328511\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9208910356602873, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9208910356602873\n",
            "3 Split Trained\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3376651043328511, subsample=0.28937062760787574 will be ignored. Current value: bagging_fraction=0.3376651043328511\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9208910356602873, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9208910356602873\n",
            "4 Split Trained\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3376651043328511, subsample=0.28937062760787574 will be ignored. Current value: bagging_fraction=0.3376651043328511\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9208910356602873, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9208910356602873\n",
            "5 Split Trained\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3376651043328511, subsample=0.28937062760787574 will be ignored. Current value: bagging_fraction=0.3376651043328511\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9208910356602873, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9208910356602873\n",
            "6 Split Trained\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3376651043328511, subsample=0.28937062760787574 will be ignored. Current value: bagging_fraction=0.3376651043328511\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9208910356602873, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9208910356602873\n",
            "7 Split Trained\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3376651043328511, subsample=0.28937062760787574 will be ignored. Current value: bagging_fraction=0.3376651043328511\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9208910356602873, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9208910356602873\n",
            "8 Split Trained\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3376651043328511, subsample=0.28937062760787574 will be ignored. Current value: bagging_fraction=0.3376651043328511\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9208910356602873, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9208910356602873\n",
            "9 Split Trained\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3376651043328511, subsample=0.28937062760787574 will be ignored. Current value: bagging_fraction=0.3376651043328511\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.9208910356602873, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.9208910356602873\n",
            "10 Split Trained\n",
            "Total Mean Score Obtained : 0.5538555455801005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaXk9_yI1NAc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cLBAdLR2MRz",
        "outputId": "97bab04f-3b3a-42e5-ca94-81c6de050a05"
      },
      "source": [
        "# #Here the cross validation by using the StratifiedKfold used to split the data into train,test and validation and repeatedly and Using the LGBMClassifier as Algorithm for building the model \n",
        "# skf =StratifiedKFold(n_splits=10, shuffle=True,random_state=2021) # for cross validation by StratifiedKfold\n",
        "# scores = [] #list to store the sores obtained in training the model \n",
        "# preds= [] #list to store the predictions \n",
        "\n",
        "# X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "# y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "# test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "# test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "# #creating a for loop for the stratified k fold to perform the cross validation \n",
        "# i = 1\n",
        "# for train, test in skf.split(X, y):\n",
        "#     x_train, x_test= X.iloc[train], X.iloc[test] #spliting the data for x \n",
        "#     y_train, y_test = y.iloc[train],y.iloc[test] #spliting the data for y \n",
        "#     model = lgb.LGBMClassifier(learning_rate=0.08, n_estimators = 96,cat_smooth=10,metrics='binary_error',\n",
        "#                                scale_pos_weight= 3.6,max_depth=16, seed =2021,\n",
        "#                                num_leaves=49,reg_lambda=0.3) #Creating the model and tuning it with the different parameter \n",
        "#     model.fit(x_train, y_train)# fitting  the model on train data\n",
        "#     print(i,'Split Trained') #print the splits that trained \n",
        "#     score = f1_score(y_test,model.predict(x_test)) # checking the accuracy of the model \n",
        "#     pred = model.predict_proba(test_new)[:,1] # making prediction\n",
        "#     scores.append(score)\n",
        "#     preds.append(pred)\n",
        "#     i += 1\n",
        "# print('Total Mean Score Obtained :',np.mean(scores))\n",
        "\n",
        "# preds_mean = np.mean(preds, axis=0)*0.5 + preds_mean*0.5# mean of all the predictions\n",
        "# final = [] #list to store the final results \n",
        "# for x in preds_mean:\n",
        "#     if x >= 0.51:\n",
        "#         final.append(1)\n",
        "#     else:\n",
        "#         final.append(0)\n",
        "\n",
        "# submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "# submit['Potability'] = final\n",
        "# submit[['region_area_','Potability']].to_csv('001xviibaseline2.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Split Trained\n",
            "2 Split Trained\n",
            "3 Split Trained\n",
            "4 Split Trained\n",
            "5 Split Trained\n",
            "6 Split Trained\n",
            "7 Split Trained\n",
            "8 Split Trained\n",
            "9 Split Trained\n",
            "10 Split Trained\n",
            "Total Mean Score Obtained : 0.5389573339467848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3yjk3n92kl3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWG-Wato26Jv"
      },
      "source": [
        "# # POWER ENSEMBLE\n",
        "\n",
        "# #Here the cross validation by using the StratifiedKfold used to split the data into train,test and validation and repeatedly and Using the LGBMClassifier as Algorithm for building the model \n",
        "# skf =StratifiedKFold(n_splits=10, shuffle=True,random_state=2021) # for cross validation by StratifiedKfold\n",
        "# scores = [] #list to store the sores obtained in training the model \n",
        "# preds2= [] #list to store the predictions \n",
        "\n",
        "# X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "# y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "# test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "# test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "# #creating a for loop for the stratified k fold to perform the cross validation \n",
        "# i = 1\n",
        "# for train, test in skf.split(X, y):\n",
        "#     x_train, x_test= X.iloc[train], X.iloc[test] #spliting the data for x \n",
        "#     y_train, y_test = y.iloc[train],y.iloc[test] #spliting the data for y \n",
        "#     model = lgb.LGBMClassifier(learning_rate=0.08, n_estimators = 96,cat_smooth=10,metrics='binary_error',\n",
        "#                                scale_pos_weight= 3.6,max_depth=16, seed =2021,\n",
        "#                                num_leaves=49,reg_lambda=0.3) #Creating the model and tuning it with the different parameter \n",
        "#     model.fit(x_train, y_train)# fitting  the model on train data\n",
        "#     print(i,'Split Trained') #print the splits that trained \n",
        "#     score = f1_score(y_test,model.predict(x_test)) # checking the accuracy of the model \n",
        "#     pred = model.predict_proba(test_new)[:,1] # making prediction\n",
        "#     scores.append(score)\n",
        "#     preds2.append(pred)\n",
        "#     i += 1\n",
        "# print('Total Mean Score Obtained :',np.mean(scores))\n",
        "\n",
        "# preds_mean = (np.mean(preds2, axis=0)**4 + np.mean(preds ,axis=0) **4 )/2 # mean of all the predictions\n",
        "# final = [] #list to store the final results \n",
        "# for x in preds_mean:\n",
        "#     if x >= 0.51:\n",
        "#         final.append(1)\n",
        "#     else:\n",
        "#         final.append(0)\n",
        "\n",
        "# submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "# submit['Potability'] = final\n",
        "# submit[['region_area_','Potability']].to_csv('001xviibaseline3.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSREvcnx4atT"
      },
      "source": [
        "## 001 SUBS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBF1XTfD4h7_",
        "outputId": "38f4a204-aadd-408e-9dce-a80a15b63d4a"
      },
      "source": [
        "#Here the cross validation by using the StratifiedKfold used to split the data into train,test and validation and repeatedly and Using the LGBMClassifier as Algorithm for building the model \n",
        "skf =StratifiedKFold(n_splits=10, shuffle=True,random_state=2021) # for cross validation by StratifiedKfold\n",
        "scores = [] #list to store the sores obtained in training the model \n",
        "preds= [] #list to store the predictions \n",
        "\n",
        "X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "#creating a for loop for the stratified k fold to perform the cross validation \n",
        "i = 1\n",
        "for train, test in skf.split(X, y):\n",
        "    x_train, x_test= X.iloc[train], X.iloc[test] #spliting the data for x \n",
        "    y_train, y_test = y.iloc[train],y.iloc[test] #spliting the data for y \n",
        "    model = lgb.LGBMClassifier(learning_rate=0.08, n_estimators = 96,cat_smooth=10,metrics='binary_error',\n",
        "                               scale_pos_weight= 10.6 ,max_depth=16, seed =2021,\n",
        "                               num_leaves=49,reg_lambda=0.3) #Creating the model and tuning it with the different parameter \n",
        "    model.fit(x_train, y_train)# fitting  the model on train data\n",
        "    print(i,'Split Trained') #print the splits that trained \n",
        "    score = f1_score(y_test,model.predict(x_test)) # checking the accuracy of the model \n",
        "    pred = model.predict_proba(test_new)[:,1] # making prediction\n",
        "    scores.append(score)\n",
        "    preds.append(pred)\n",
        "    i += 1\n",
        "print('Total Mean Score Obtained :',np.mean(scores))\n",
        "\n",
        "preds_mean = np.mean(preds, axis=0) # mean of all the predictions\n",
        "final = [] #list to store the final results \n",
        "for x in preds_mean:\n",
        "    if x >= 0.51:\n",
        "        final.append(1)\n",
        "    else:\n",
        "        final.append(0)\n",
        "\n",
        "submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "submit['Potability'] = final\n",
        "submit[['region_area_','Potability']].to_csv('001xviibaseline4.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Split Trained\n",
            "2 Split Trained\n",
            "3 Split Trained\n",
            "4 Split Trained\n",
            "5 Split Trained\n",
            "6 Split Trained\n",
            "7 Split Trained\n",
            "8 Split Trained\n",
            "9 Split Trained\n",
            "10 Split Trained\n",
            "Total Mean Score Obtained : 0.5808120490570688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9ChcO5T4oRY",
        "outputId": "ac687d49-2a94-42b8-e217-cdc0e8ba2131"
      },
      "source": [
        "#Here the cross validation by using the StratifiedKfold used to split the data into train,test and validation and repeatedly and Using the LGBMClassifier as Algorithm for building the model \n",
        "skf =StratifiedKFold(n_splits=10, shuffle=True,random_state=2021) # for cross validation by StratifiedKfold\n",
        "scores = [] #list to store the sores obtained in training the model \n",
        "preds= [] #list to store the predictions \n",
        "\n",
        "X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "#creating a for loop for the stratified k fold to perform the cross validation \n",
        "i = 1\n",
        "for train, test in skf.split(X, y):\n",
        "    x_train, x_test= X.iloc[train], X.iloc[test] #spliting the data for x \n",
        "    y_train, y_test = y.iloc[train],y.iloc[test] #spliting the data for y \n",
        "    model = lgb.LGBMClassifier(learning_rate=0.08, n_estimators = 96,cat_smooth=10,metrics='binary_error',\n",
        "                               scale_pos_weight= 10.6 ,max_depth=16, seed =2021,\n",
        "                               num_leaves=21,reg_lambda=0.3,) #Creating the model and tuning it with the different parameter \n",
        "    model.fit(x_train, y_train)# fitting  the model on train data\n",
        "    print(i,'Split Trained') #print the splits that trained \n",
        "    score = f1_score(y_test,model.predict(x_test)) # checking the accuracy of the model \n",
        "    pred = model.predict_proba(test_new)[:,1] # making prediction\n",
        "    scores.append(score)\n",
        "    preds.append(pred)\n",
        "    i += 1\n",
        "print('Total Mean Score Obtained :',np.mean(scores))\n",
        "\n",
        "preds_mean = np.mean(preds, axis=0) # mean of all the predictions\n",
        "final = [] #list to store the final results \n",
        "for x in preds_mean:\n",
        "    if x >= 0.51:\n",
        "        final.append(1)\n",
        "    else:\n",
        "        final.append(0)\n",
        "\n",
        "submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "submit['Potability'] = final\n",
        "submit[['region_area_','Potability']].to_csv('001xviibaseline5.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Split Trained\n",
            "2 Split Trained\n",
            "3 Split Trained\n",
            "4 Split Trained\n",
            "5 Split Trained\n",
            "6 Split Trained\n",
            "7 Split Trained\n",
            "8 Split Trained\n",
            "9 Split Trained\n",
            "10 Split Trained\n",
            "Total Mean Score Obtained : 0.5818348138833179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bBt20kM53p5",
        "outputId": "269b1462-1d7e-4048-84af-2e0d50448724"
      },
      "source": [
        "#Here the cross validation by using the StratifiedKfold used to split the data into train,test and validation and repeatedly and Using the LGBMClassifier as Algorithm for building the model \n",
        "skf =StratifiedKFold(n_splits=10, shuffle=True,random_state=2021) # for cross validation by StratifiedKfold\n",
        "scores = [] #list to store the sores obtained in training the model \n",
        "preds= [] #list to store the predictions \n",
        "\n",
        "X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "#creating a for loop for the stratified k fold to perform the cross validation \n",
        "i = 1\n",
        "for train, test in skf.split(X, y):\n",
        "    x_train, x_test= X.iloc[train], X.iloc[test] #spliting the data for x \n",
        "    y_train, y_test = y.iloc[train],y.iloc[test] #spliting the data for y \n",
        "    model = lgb.LGBMClassifier(learning_rate=0.08, n_estimators = 96,cat_smooth=10,metrics='binary_error',\n",
        "                               scale_pos_weight= 11.6 ,max_depth=16, seed =2021,\n",
        "                               num_leaves=21,reg_lambda=0.3,) #Creating the model and tuning it with the different parameter \n",
        "    model.fit(x_train, y_train)# fitting  the model on train data\n",
        "    print(i,'Split Trained') #print the splits that trained \n",
        "    score = f1_score(y_test,model.predict(x_test)) # checking the accuracy of the model \n",
        "    pred = model.predict_proba(test_new)[:,1] # making prediction\n",
        "    scores.append(score)\n",
        "    preds.append(pred)\n",
        "    i += 1\n",
        "print('Total Mean Score Obtained :',np.mean(scores))\n",
        "\n",
        "preds_mean = np.mean(preds, axis=0) # mean of all the predictions\n",
        "final = [] #list to store the final results \n",
        "for x in preds_mean:\n",
        "    if x >= 0.51:\n",
        "        final.append(1)\n",
        "    else:\n",
        "        final.append(0)\n",
        "\n",
        "submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "submit['Potability'] = final\n",
        "submit[['region_area_','Potability']].to_csv('001xviibaseline6.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Split Trained\n",
            "2 Split Trained\n",
            "3 Split Trained\n",
            "4 Split Trained\n",
            "5 Split Trained\n",
            "6 Split Trained\n",
            "7 Split Trained\n",
            "8 Split Trained\n",
            "9 Split Trained\n",
            "10 Split Trained\n",
            "Total Mean Score Obtained : 0.5831910378244277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTAZFB7Ug9G3"
      },
      "source": [
        "# SUBS 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Iia5Q2hDxF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR419GAgj1mT",
        "outputId": "1719fc45-7a04-4bcc-a537-2ba76b3f8059"
      },
      "source": [
        "#Here the cross validation by using the StratifiedKfold used to split the data into train,test and validation and repeatedly and Using the LGBMClassifier as Algorithm for building the model \n",
        "skf =StratifiedKFold(n_splits=10, shuffle=True,random_state=2021) # for cross validation by StratifiedKfold\n",
        "scores = [] #list to store the sores obtained in training the model \n",
        "preds= [] #list to store the predictions \n",
        "\n",
        "X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "#creating a for loop for the stratified k fold to perform the cross validation \n",
        "i = 1\n",
        "for train, test in skf.split(X, y):\n",
        "    x_train, x_test= X.iloc[train], X.iloc[test] #spliting the data for x \n",
        "    y_train, y_test = y.iloc[train],y.iloc[test] #spliting the data for y \n",
        "    model = lgb.LGBMClassifier(learning_rate=0.08, n_estimators = 96,cat_smooth=10,metrics='binary_error',\n",
        "                               scale_pos_weight= 10.6 ,max_depth=16, seed =2021,\n",
        "                               num_leaves=21,reg_lambda=0.3,) #Creating the model and tuning it with the different parameter \n",
        "    model.fit(x_train, y_train)# fitting  the model on train data\n",
        "    print(i,'Split Trained') #print the splits that trained \n",
        "    score = f1_score(y_test,model.predict(x_test)) # checking the accuracy of the model \n",
        "    pred = model.predict_proba(test_new)[:,1] # making prediction\n",
        "    scores.append(score)\n",
        "    preds.append(pred)\n",
        "    i += 1\n",
        "print('Total Mean Score Obtained :',np.mean(scores))\n",
        "\n",
        "preds_mean = np.mean(preds, axis=0) # mean of all the predictions\n",
        "final = [] #list to store the final results \n",
        "for x in preds_mean:\n",
        "    if x >= 0.51:\n",
        "        final.append(1)\n",
        "    else:\n",
        "        final.append(0)\n",
        "\n",
        "submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "submit['Potability'] = final\n",
        "submit[['region_area_','Potability']].to_csv('001xviibaseline5.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Split Trained\n",
            "2 Split Trained\n",
            "3 Split Trained\n",
            "4 Split Trained\n",
            "5 Split Trained\n",
            "6 Split Trained\n",
            "7 Split Trained\n",
            "8 Split Trained\n",
            "9 Split Trained\n",
            "10 Split Trained\n",
            "Total Mean Score Obtained : 0.5818348138833179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "croAXxpJ7BaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1725e141-3478-4d05-fbc9-496ccbc37af2"
      },
      "source": [
        "#Here the cross validation by using the StratifiedKfold used to split the data into train,test and validation and repeatedly and Using the LGBMClassifier as Algorithm for building the model \n",
        "skf =StratifiedKFold(n_splits=10, shuffle=True,random_state=2021) # for cross validation by StratifiedKfold\n",
        "scores = [] #list to store the sores obtained in training the model \n",
        "preds= [] #list to store the predictions \n",
        "\n",
        "X = train_df.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "y = train_df['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "test_new = test_df.drop(columns=['region_area_']) #config_.preprocess.to_drop)\n",
        "test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "#creating a for loop for the stratified k fold to perform the cross validation \n",
        "i = 1\n",
        "for train, test in skf.split(X, y):\n",
        "    x_train, x_test= X.iloc[train], X.iloc[test] #spliting the data for x \n",
        "    y_train, y_test = y.iloc[train],y.iloc[test] #spliting the data for y \n",
        "    model = lgb.LGBMClassifier(learning_rate=0.08, n_estimators = 96,cat_smooth=10,metrics='binary_error',\n",
        "                              #  neg_bagging_fraction=0.8,pos_bagging_fraction=0.7,\n",
        "                               scale_pos_weight= 10.6 ,max_depth=16, seed =2021,\n",
        "                               num_leaves=49,reg_lambda=0.3) #Creating the model and tuning it with the different parameter \n",
        "    model.fit(x_train, y_train)# fitting  the model on train data\n",
        "    print(i,'Split Trained') #print the splits that trained \n",
        "    score = f1_score(y_test,model.predict(x_test)) # checking the accuracy of the model \n",
        "    pred = model.predict_proba(test_new)[:,1] # making prediction\n",
        "    scores.append(score)\n",
        "    preds.append(pred)\n",
        "    i += 1\n",
        "print('Total Mean Score Obtained :',np.mean(scores))\n",
        "\n",
        "preds_mean = np.mean(preds, axis=0) # mean of all the predictions\n",
        "final = [] #list to store the final results \n",
        "for x in preds_mean:\n",
        "    if x >= 0.51:\n",
        "        final.append(1)\n",
        "    else:\n",
        "        final.append(0)\n",
        "\n",
        "# submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "# submit['Potability'] = final\n",
        "# submit[['region_area_','Potability']].to_csv('003xviibaseline4.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Split Trained\n",
            "2 Split Trained\n",
            "3 Split Trained\n",
            "4 Split Trained\n",
            "5 Split Trained\n",
            "6 Split Trained\n",
            "7 Split Trained\n",
            "8 Split Trained\n",
            "9 Split Trained\n",
            "10 Split Trained\n",
            "Total Mean Score Obtained : 0.5808120490570688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTRIL6Xxl4Qt"
      },
      "source": [
        "test_df['Potability'] = final\n",
        "\n",
        "new_train = pd.concat([train_df,test_df]).reset_index(drop=True)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEPD5xexkqMf",
        "outputId": "171f1caa-06da-43a8-b2d2-c3136f8e0a10"
      },
      "source": [
        "#Here the cross validation by using the StratifiedKfold used to split the data into train,test and validation and repeatedly and Using the LGBMClassifier as Algorithm for building the model \n",
        "skf =StratifiedKFold(n_splits=10, shuffle=True,random_state=2021) # for cross validation by StratifiedKfold\n",
        "scores = [] #list to store the sores obtained in training the model \n",
        "preds= [] #list to store the predictions \n",
        "\n",
        "X = new_train.drop(columns=['region_area_','Potability']) #config_.preprocess.to_drop+config_.preprocess.target)\n",
        "y = new_train['Potability'] #[config_.preprocess.target[0]].astype(int)\n",
        "\n",
        "test_new = test_df.drop(columns=['region_area_', 'Potability']) #config_.preprocess.to_drop)\n",
        "test_fields = test_df['region_area_'] #[config_.preprocess.to_drop[0]]  #field\n",
        "\n",
        "#creating a for loop for the stratified k fold to perform the cross validation \n",
        "i = 1\n",
        "for train, test in skf.split(X, y):\n",
        "    x_train, x_test= X.iloc[train], X.iloc[test] #spliting the data for x \n",
        "    y_train, y_test = y.iloc[train],y.iloc[test] #spliting the data for y \n",
        "    model = lgb.LGBMClassifier(learning_rate=0.08, n_estimators = 96,cat_smooth=10,metrics='binary_error',\n",
        "                              #  neg_bagging_fraction=0.8,pos_bagging_fraction=0.7,\n",
        "                               scale_pos_weight= 10.6 ,max_depth=16, seed =2021,\n",
        "                               num_leaves=49,reg_lambda=0.3, reg_alpha=0.3) #Creating the model and tuning it with the different parameter \n",
        "    model.fit(x_train, y_train)# fitting  the model on train data\n",
        "    print(i,'Split Trained') #print the splits that trained \n",
        "    score = f1_score(y_test,model.predict(x_test)) # checking the accuracy of the model \n",
        "    pred = model.predict_proba(test_new)[:,1] # making prediction\n",
        "    scores.append(score)\n",
        "    preds.append(pred)\n",
        "    i += 1\n",
        "print('Total Mean Score Obtained :',np.mean(scores))\n",
        "\n",
        "preds_mean = np.mean(preds, axis=0) # mean of all the predictions\n",
        "final = [] #list to store the final results \n",
        "for x in preds_mean:\n",
        "    if x >= 0.51:\n",
        "        final.append(1)\n",
        "    else:\n",
        "        final.append(0)\n",
        "\n",
        "submit = test_df.copy() #Copy the submission file to the variable submit \n",
        "submit['Potability'] = final\n",
        "submit[['region_area_','Potability']].to_csv('003xviibaseline7.csv',index=False) #creating and naming the file ready for submission"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Split Trained\n",
            "2 Split Trained\n",
            "3 Split Trained\n",
            "4 Split Trained\n",
            "5 Split Trained\n",
            "6 Split Trained\n",
            "7 Split Trained\n",
            "8 Split Trained\n",
            "9 Split Trained\n",
            "10 Split Trained\n",
            "Total Mean Score Obtained : 0.7032938196522149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnIwtHR9lSaP"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}
